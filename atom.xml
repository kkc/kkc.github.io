<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kakashi&#39;s Notes</title>
  <icon>https://www.gravatar.com/avatar/a78f6cc4fc127a344343983280674d46</icon>
  <subtitle>修其本而末自應</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kkc.github.io/"/>
  <updated>2019-04-08T14:10:06.095Z</updated>
  <id>http://kkc.github.io/</id>
  
  <author>
    <name>Kakashi</name>
    <email>kakashi1000@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>透過 IAM access advisor API 來幫 IAM permission 做大掃除</title>
    <link href="http://kkc.github.io/2019/04/08/analyze-iam-permission-using-iam-access-advisor-api/"/>
    <id>http://kkc.github.io/2019/04/08/analyze-iam-permission-using-iam-access-advisor-api/</id>
    <published>2019-04-08T09:37:08.000Z</published>
    <updated>2019-04-08T14:10:06.095Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>隨著組織慢慢變大，在 AWS 上面常常會遇到一個問題就是，我的 IAM entity 的 permission 是不是開的太大了，這個問題常常發生在 developer 想要快速驗證自己的 application 能不能 work，而作為 admin 的我們有時會給予太大的權限，等到該專案開展到一定程度的時候，其實需要使用到的權限應該是穩定下來了，但又難以找每個專案負責人慢慢 review 權限，這樣一來，其實違反了 least privilege 的原則，也就是只給於需要的權限就好。</p><h2 id="IAM-access-advisor-API"><a href="#IAM-access-advisor-API" class="headerlink" title="IAM access advisor API"></a>IAM access advisor API</h2><p>AWS 其實有推出一組用來分析 IAM 權限管理的 API，而 AWS 官方的 <a href="https://aws.amazon.com/blogs/security/automate-analyzing-permissions-using-iam-access-advisor/" target="_blank" rel="noopener">blog</a> 也有幾篇介紹，完全可以符合我們的需求，把一些用不到的權限限縮。</p><ul><li><code>generate-service-last-accessed-details</code> 針對 IAM ser, role, group, or policy 產生最後存取 (last accessed data) 的資訊，呼叫這個 API 後會拿到一組 <code>JobId</code>，接著要等待一陣子，才能透過 <code>get-service-last-accessed-details</code> 得到資料。</li><li><code>get-service-last-accessed-details</code> 透過這個 API 輸入 JobId 去得到 last accessed 的資料</li><li><code>get-service-last-accessed-details-with-entities</code> 其實跟上面的 API 很類似，只是可以指定 –service-namespaces 去看特定的 service</li><li><code>list-policies-granting-service-access</code> 可以看到這個權限（針對 service) 是從哪個 policy 來的</li></ul><p>有了以上這幾組 API 我們就可以實作一個簡單的 script 去掃出是否有全縣太大的 IAM entity。 </p><h2 id="Simple-Example"><a href="#Simple-Example" class="headerlink" title="Simple Example"></a>Simple Example</h2><p>這個範例很大一部分是參考 trek10inc 的 <a href="https://github.com/trek10inc/config-excess-access-exorcism/blob/734fecde2f02dd448e0439f366d5400d4413a6d0/IAM_ALLOWS_UNUSED_SERVICES/iam_rule_helpers.py" target="_blank" rel="noopener">config-excess-access-exorcism</a> 來的，不過有做一些簡單的修改，有了這個程式可以幫我們快速定位，那個 IAM role 開的權限太大，而這個 repo 其實想做到的事情更潮，是將其設定為 AWS config 的 rule，由此一來就可以讓 AWS 幫我們定期去掃 IAM entities。</p><p>先透過下面這個 function 拿到該 IAM entity 所有的 service 權限，這邊要注意的是要把 paginate 的資料也拿回來，因為有些權限太多需要好幾個 API call 才拿得齊。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_iam_last_access_details</span><span class="params">(iam, arn)</span>:</span></span><br><span class="line">    job = iam.generate_service_last_accessed_details(Arn=arn)</span><br><span class="line">    job_id = job[<span class="string">'JobId'</span>]</span><br><span class="line">    service_results = []</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        result = iam.get_service_last_accessed_details(JobId=job_id)</span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">'JobStatus'</span>] == <span class="string">'IN_PROGRESS'</span>:</span><br><span class="line">            print(<span class="string">"Awaiting job"</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">elif</span> result[<span class="string">'JobStatus'</span>] == <span class="string">'FAILED'</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">f"Could not get access information for <span class="subst">&#123;arn&#125;</span>"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            service_results.extend(paginate_access_details(job_id, result))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">return</span> service_results</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">paginate_access_details</span><span class="params">(job_id, result)</span>:</span></span><br><span class="line">    more_data, marker = result[<span class="string">'IsTruncated'</span>], result.get(<span class="string">'Marker'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> more_data:</span><br><span class="line">        <span class="keyword">return</span> result[<span class="string">'ServicesLastAccessed'</span>]</span><br><span class="line"></span><br><span class="line">    all_service_info = result[<span class="string">'ServicesLastAccessed'</span>][:]</span><br><span class="line">    <span class="keyword">while</span> more_data:</span><br><span class="line">        page = iam.get_service_last_accessed_details(JobId=job_id, Marker=marker)</span><br><span class="line">        more_data, marker = page[<span class="string">'IsTruncated'</span>], page[<span class="string">'Marker'</span>]</span><br><span class="line">        all_service_info.extend(page[<span class="string">'ServicesLastAccessed'</span>])</span><br><span class="line">    <span class="keyword">return</span> all_service_info</span><br></pre></td></tr></table></figure></p><p>來個簡單的測試<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">detail = get_iam_last_access_details(<span class="name">iam</span>, <span class="string">"arn:aws:iam::AWS_ACCOUNT:role/service-role/AmazonEC2RunCommandRoleForManagedInstances"</span>)</span><br><span class="line">pprint(<span class="name">detail</span>)</span><br></pre></td></tr></table></figure></p><p>Output 會長得像這樣:<br><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[&#123;   <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'Amazon</span> CloudWatch',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'cloudwatch</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;   <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'AWS</span> Directory Service',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'ds</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;   <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'Amazon</span> EC2',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'ec2</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;   <span class="symbol">'LastAuthenticated</span><span class="symbol">':</span> datetime.datetime(<span class="name">2019</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">41</span>, tzinfo=tzutc()),</span><br><span class="line">        <span class="symbol">'LastAuthenticatedEntity</span><span class="symbol">':</span> <span class="symbol">'arn:aws:iam::774915305292:role/service-role/AmazonEC2RunCommandRoleForManagedInstances</span>',</span><br><span class="line">        <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'Amazon</span> Message Delivery Service',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'ec2messages</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">1</span>&#125;,</span><br><span class="line">        ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>有了這個 output 我們就可以來開心的來分析啦，主要就是看 <code>LastAuthenticated</code> 這個欄位，如果沒有這個欄位就代表根本沒使用過，這個權限就該被剷除，另外也可以檢查是否這個使用的日期是不是在 180 天前，太久沒用也代表可能不需要了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">never_accessed_services_check</span><span class="params">(iam, arn)</span>:</span></span><br><span class="line">    service_results = get_iam_last_access_details(iam, arn)</span><br><span class="line">    never_accessed = [</span><br><span class="line">        x <span class="keyword">for</span> x <span class="keyword">in</span> service_results <span class="keyword">if</span> <span class="string">'LastAuthenticated'</span> <span class="keyword">not</span> <span class="keyword">in</span> x</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">if</span> len(never_accessed) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            <span class="string">'NON_COMPLIANT'</span>,</span><br><span class="line">            <span class="string">"Services"</span> + <span class="string">','</span>.join(<span class="string">f"'<span class="subst">&#123;x[<span class="string">'ServiceNamespace'</span>]&#125;</span>'"</span> <span class="keyword">for</span> x <span class="keyword">in</span> never_accessed) + <span class="string">"have never been accessed"</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'COMPLIANT'</span>, <span class="string">'IAM entity has accessed all allowed services'</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">no_access_in_180_days_check</span><span class="params">(iam, arn)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pytz</span><br><span class="line"></span><br><span class="line">    service_results = get_iam_last_access_details(iam, arn)</span><br><span class="line"></span><br><span class="line">    pp = pprint.PrettyPrinter(indent=<span class="number">4</span>)</span><br><span class="line">    pp.pprint(service_results)</span><br><span class="line"></span><br><span class="line">    utc_now = datetime.datetime.utcnow().replace(tzinfo=pytz.UTC)</span><br><span class="line"></span><br><span class="line">    older_than_180_days = [</span><br><span class="line">        x <span class="keyword">for</span> x <span class="keyword">in</span> service_results</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'LastAuthenticated'</span> <span class="keyword">in</span> x <span class="keyword">and</span> (utc_now - x[<span class="string">'LastAuthenticated'</span>]) &gt; datetime.timedelta(days=<span class="number">180</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">if</span> len(older_than_180_days) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            <span class="string">'NON_COMPLIANT'</span>,</span><br><span class="line">            <span class="string">"Services"</span> + <span class="string">','</span>.join(<span class="string">f"'<span class="subst">&#123;x[<span class="string">'ServiceNamespace'</span>]&#125;</span>'"</span> <span class="keyword">for</span> x <span class="keyword">in</span> older_than_180_days) + <span class="string">"have not been accessed in the last 180 days"</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'COMPLIANT'</span>, <span class="string">'IAM entity has accessed all allowed services in the last 180 days'</span></span><br></pre></td></tr></table></figure><p>在知道是哪個 service 有問題後，還可以用 <code>aws iam list-policies-granting-service-access --arn arn:aws:iam::AWS_ACCOUNT:role/service-role/AmazonEC2RunCommandRoleForManagedInstances --service-namespaces s3</code> 去看這個 service 的權限是從哪個 policy 來的。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"PoliciesGrantingServiceAccess"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"ServiceNamespace"</span>: <span class="string">"s3"</span>,</span><br><span class="line">            <span class="attr">"Policies"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">"PolicyName"</span>: <span class="string">"AmazonEC2RoleforSSM"</span>,</span><br><span class="line">                    <span class="attr">"PolicyType"</span>: <span class="string">"MANAGED"</span>,</span><br><span class="line">                    <span class="attr">"PolicyArn"</span>: <span class="string">"arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM"</span></span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"IsTruncated"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>sample code 可以用下列的程式碼</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def get_policies(iam, arn, service_namespace_list):</span><br><span class="line">    policies = []</span><br><span class="line">    <span class="built_in">result</span> = iam.list_policies_granting_service_access(Arn=arn, ServiceNamespaces=service_namespace_list)</span><br><span class="line">    policies.extend(paginate_policies(arn, service_namespace_list, <span class="built_in">result</span>))</span><br><span class="line">    <span class="literal">return</span> policies</span><br><span class="line"></span><br><span class="line">def paginate_policies(arn, service_namespace_list, <span class="built_in">result</span>):</span><br><span class="line">    more_data, marker = <span class="built_in">result</span>[<span class="string">'IsTruncated'</span>], <span class="built_in">result</span>.<span class="built_in">get</span>(<span class="string">'Marker'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> more_data:</span><br><span class="line">        <span class="literal">return</span> <span class="built_in">result</span>[<span class="string">'PoliciesGrantingServiceAccess'</span>]</span><br><span class="line"></span><br><span class="line">    all_service_info = <span class="built_in">result</span>[<span class="string">'PoliciesGrantingServiceAccess'</span>][:]</span><br><span class="line">    <span class="keyword">while</span> more_data:</span><br><span class="line">        page = iam.list_policies_granting_service_access(Arn=arn, ServiceNamespaces=service_namespace_list, Marker=marker)</span><br><span class="line">        more_data, marker = page[<span class="string">'IsTruncated'</span>], page[<span class="string">'Marker'</span>]</span><br><span class="line">        all_service_info.extend(page[<span class="string">'PoliciesGrantingServiceAccess'</span>])</span><br><span class="line">    <span class="literal">return</span> all_service_info</span><br></pre></td></tr></table></figure><p>就可以找出需要修正的 policy 像是這樣</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">   &#123;  </span><br><span class="line">      <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span><span class="symbol">'s3</span>',</span><br><span class="line">      <span class="symbol">'Policies</span><span class="symbol">':</span>[</span><br><span class="line">         &#123;  </span><br><span class="line">            <span class="symbol">'PolicyName</span><span class="symbol">':</span><span class="symbol">'AmazonEC2RoleforSSM</span>',</span><br><span class="line">            <span class="symbol">'PolicyType</span><span class="symbol">':</span><span class="symbol">'MANAGED</span>',</span><br><span class="line">            <span class="symbol">'PolicyArn</span><span class="symbol">':</span><span class="symbol">'arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM</span>'</span><br><span class="line">         &#125;</span><br><span class="line">      ]</span><br><span class="line">   &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="心得"><a href="# 心得" class="headerlink" title="心得"></a>心得 </h2><p> 管理 IAM 其實需要相當的心力，透過一些 AWS 的 cli 加上 python boto lib，可以讓我們事倍功半，很推薦大家多試試看這些 API 掃掃看，我也有蠻多意外的發現 XD</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.trek10.com/blog/excess-access-exorcism-with-aws-config/" target="_blank" rel="noopener">https://www.trek10.com/blog/excess-access-exorcism-with-aws-config/</a></li><li><a href="https://aws.amazon.com/blogs/security/remove-unnecessary-permissions-in-your-iam-policies-by-using-service-last-accessed-data/" target="_blank" rel="noopener">remove unnecessary permissions in your iam policies by using service last accessed data</a></li><li><p><a href="https://aws.amazon.com/blogs/security/automate-analyzing-permissions-using-iam-access-advisor/" target="_blank" rel="noopener">automate-analyzing-permissions-using-iam-access-advisor</a></p></li><li><p>header image credit<a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@jbriscoe?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Jason Briscoe"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Jason Briscoe</span></a></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;p&gt;隨著組織慢慢變大，在 AWS 上面常常會遇到一個問題就是，我的 IAM entity 的 permi
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="IAM" scheme="http://kkc.github.io/tags/IAM/"/>
    
  </entry>
  
  <entry>
    <title>透過 loop invariant 學習怎麼寫正確的 binary search</title>
    <link href="http://kkc.github.io/2019/03/28/learn-loop-invariant-from-binary-search/"/>
    <id>http://kkc.github.io/2019/03/28/learn-loop-invariant-from-binary-search/</id>
    <published>2019-03-28T09:12:32.000Z</published>
    <updated>2019-04-01T16:08:54.556Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>Binary search 記得是我剛入門寫程式的時候，前幾個回家作業，當時寫出來時，覺得整個程式就很直覺，對這個也不太有什麼疑問，直到最近看到 Programming Pearls 這本書裡面，有寫到大概 90% 的 binary search 都是錯誤的，甚至第一版的 binary search (1946 的版本)，直到 1962 年才發現有 Bug。</p><blockquote><p>I’ve assigned this problem in courses at Bell Labs and IBM.  Professional programmers had a couple of hours to convert the above description into a program in the language of their choice; a high-level pseudocode was fine.  At the end of the specified time, almost all the programmers reported that they had correct code for the task.  We would then take thirty minutes to examine their code, which the programmers did with test cases.  In several classes and with over a hundred programmers, the results varied little: ninety percent of the programmers found bugs in their programs (and I wasn’t always convinced of the correctness of the code in which no bugs were found).</p></blockquote><blockquote><p>I was amazed: given ample time, only about ten percent of professional programmers were able to get this small program right.  But they aren’t the only ones to find this task difficult: in the history in Section 6.2.1 of his Sorting and Searching, Knuth points out that while the first binary search was published in 1946, the first published binary search without bugs did not appear until 1962.</p></blockquote><p>其實 google 也有一篇 <a href="https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html" target="_blank" rel="noopener"> 文章 </a> 在探討 binary search，先來看下面這個 binary search 的程式。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(input_arr []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    s := <span class="number">0</span></span><br><span class="line">    e := <span class="built_in">len</span>(input_arr) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> s &lt;= e &#123;</span><br><span class="line">        m := (s + e) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> input_arr[m] &lt; target &#123;</span><br><span class="line">            s = m</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            e = m - <span class="number">1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>這個範例明眼人一看就知道 <code>m := (s + e) / 2</code> 會有溢位的問題，而通常會有兩種改法:</p><ol><li><code>m := s + (e - s)/2</code></li><li><code>m := int(uint(s+e) &gt;&gt; 1)</code></li></ol><p>但是除了這個之外，其實我寫的這個例子還有其他問題，最主要的就是 <a href="https://en.wikipedia.org/wiki/Off-by-one_error" target="_blank" rel="noopener">Off-by-one errors</a> 這個問題，如果把 [1,2,3,4] 當作 input，然後 target 為 3 的情況，其實會跑進無窮迴圈：</p><ol><li>s=0, e=3, m=1 且 input_arr[1] = 2 &lt; 3，所以 s = m</li><li>s=1, e=3, m=2 且 input_arr[2] = 3 &gt;= 3 ， 所以 e = m - 1</li><li>s=1, e=1, m=1 此時這個程式，因為一直維持 s &lt;= e 就會跑進無窮迴圈</li></ol><p>而這個邊界條件，就是要調整 +1, -1 的問題，非常的難搞，這裡有好幾個地方要配合才行</p><ol><li>e 的邊界是 <code>len(input_arr)</code> or <code>len(input_arr) - 1</code></li><li>s &lt;= e or s &lt; e</li><li>s = m or s = m + 1</li><li>e = m or e = m - 1</li></ol><p>網路上甚至可以找到範本，專門拿來對付 leetcode 上面的問題，雖然也是有人講可以直接在迴圈中判斷 if input_arr[m] == target 做跳出就行了，但是這樣的寫法顯然無法解決從找出 sorted array 中找出 lower_bound or upper_bound，這就讓我想知道是否有更科學的方法可以幫助我們。</p><h2 id="Loop-invariant-to-the-rescue"><a href="#Loop-invariant-to-the-rescue" class="headerlink" title="Loop invariant to the rescue"></a>Loop invariant to the rescue</h2><p>很幸運的，在網路上找到幾篇文章 (都列在 reference 了) 幫助我理解怎麼使用 loop invariant 去解決這個問題，我也查了下 Introduction to Algorithm 裡面的 loop invariant 定義:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">We <span class="keyword">use</span> <span class="keyword">loop</span> invariants <span class="keyword">to</span> <span class="keyword">help</span> us understand why an algorithm <span class="keyword">is</span> correct. We must <span class="keyword">show</span> three things about a <span class="keyword">loop</span> invariant:</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> Initialization: It <span class="keyword">is</span> <span class="literal">true</span> <span class="keyword">prior</span> <span class="keyword">to</span> the <span class="keyword">first</span> iteration <span class="keyword">of</span> the loop.</span><br><span class="line"><span class="number">2.</span> Maintenance: <span class="keyword">If</span> it <span class="keyword">is</span> <span class="literal">true</span> <span class="keyword">before</span> an iteration <span class="keyword">of</span> the <span class="keyword">loop</span>, it remains <span class="literal">true</span> <span class="keyword">before</span> the <span class="keyword">next</span> iteration.</span><br><span class="line"><span class="number">3.</span> Termination: <span class="keyword">When</span> the <span class="keyword">loop</span> terminates, the invariant gives us a useful property that helps <span class="keyword">show</span> that the algorithm <span class="keyword">is</span> correct.</span><br></pre></td></tr></table></figure><p>整個看下來有點歸納法的意味，就是定義一個性質，在 loop 開始前，執行完一次 loop interation，和結束時都可以保證這個性質成立，這樣就可以得到正確的程式結果。</p><p>先看看下面這個簡單的例子</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">find_max</span><span class="params">(a []int)</span></span> &#123;</span><br><span class="line">    <span class="built_in">max</span> = -<span class="type">INF</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i:=<span class="number">0</span>; i &lt; len(a); i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (a[i] &gt; <span class="built_in">max</span>)</span><br><span class="line">            <span class="built_in">max</span> = a[i]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以這個例子來說，我們的 loop invariant condition 可以設定為 max 總是在給予的 a array 前 i 個元素中，然後去驗證每次跑迴圈的時候，都符合這個條件，就可以確定這個演算法是正確的。</p><h2 id="透過 -loop-invariant- 寫 -binary-search"><a href="# 透過 -loop-invariant- 寫 -binary-search" class="headerlink" title="透過 loop invariant 寫 binary search"></a>透過 loop invariant 寫 binary search</h2><p>前面提的那個例子，大家一定會覺得有點太簡單，實在不知道對我們寫程式有什麼幫助，接下來透過 binary search 的例子，相信大家可以有更不一樣的感受。</p><p>首先要來定義我們的問題:</p><ul><li><p>Pre condition:<br>在 binary search 中，我們會有一個 sorted list，然後從中找到 target。</p><p>sorted list = [3, 5, 6, 13, 18, 21, 23]<br>target = 18</p></li><li><p>Post condition:<br>找出 key 是否在 list 中</p></li></ul><p>而定義 list 的區間其實有四種方法<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. A<span class="string">[low]</span> &lt;  A<span class="string">[i]</span> &lt;  A<span class="string">[high]</span></span><br><span class="line"><span class="number">2</span>. A<span class="string">[low]</span> &lt;= A<span class="string">[i]</span> &lt;  A<span class="string">[high]</span></span><br><span class="line"><span class="number">3</span>. A<span class="string">[low]</span> &lt;  A<span class="string">[i]</span> &lt;= A<span class="string">[high]</span></span><br><span class="line"><span class="number">4</span>. A<span class="string">[low]</span> &lt;= A<span class="string">[i]</span> &lt;= A<span class="string">[high]</span></span><br></pre></td></tr></table></figure></p><p>看過許多資料後了解方法二是比較好的選擇， <code>i ∈ [low,high)</code>，也就是左閉右開這個方法，也就是右邊的值並沒有包含在這個區間內，其實也是最直覺的方法，這邊很推薦大家看這份知乎的文章: <a href="https://www.zhihu.com/question/36132386" target="_blank" rel="noopener">二分找查有幾種寫法?</a>去了解為什麼要取這個區間，其實我以下很多內容也是看這篇文章而通透的。</p><p>而選擇了這個區間後，我們先來個基本版的 binary search 實做，才容易解釋 loop invaraint<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(input_arr []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    low := <span class="number">0</span></span><br><span class="line">    high := <span class="built_in">len</span>(input_arr)  <span class="comment">// 符合 i ∈ [low,high)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> low &lt; high &#123;</span><br><span class="line">        mid := low + (high - low) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> input_arr[mid] == target &#123;</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> input_arr[mid] &lt; target &#123;  <span class="comment">// target 在 mid 右側</span></span><br><span class="line">            low = mid + <span class="number">1</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                           <span class="comment">// target 在 mid 左側</span></span><br><span class="line">            high = mid</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我們這裡設定的 loop invariant 性質，跟區間很有關係</p><ol><li>搜索區間 <code>[low, high)</code> 不為空的話，low &lt; high 才會成立，反之為空的話，low == high 會離開迴圈</li><li>找出來的 sub range 搜索區間都是 <code>[low, high)</code></li></ol><p>有了這些條件後，我們可以分析下迴圈結束的 boundary condition，來先個比較小的測資，來模擬測試區間變小的情況。</p><h3 id="範例 -1"><a href="# 範例 -1" class="headerlink" title="範例 1"></a>範例 1</h3><p>如果我們有個 array 裡面只有一個元素 [0]，然後我們要找的 target 為 1 時，透過以下的 step</p><ol><li>我們的初始搜索區間為 [0, 1)，low = 0, high = 1, mid = 0</li><li>因為 input_arr[mid] = 0 &lt; 1，所以 low = mid + 1 ，此時 high &amp; low 皆為 1 且重合，搜索區間為空集合，離開迴圈。</li><li>回傳 -1 代表這個 array 沒有我們要的值 </li></ol><p>已上面這個例子，我們可以得知，如果把跳出的條件寫成 <code>low &lt;= high</code> 或是 low 寫成 mid 都會出問題，因為會不符合 loop invaraint ，這邊要理解的就是搜索區間變成空集合在這個程式中，是怎麼表示才是正確的。 </p><h3 id="範例 -2"><a href="# 範例 -2" class="headerlink" title="範例 2"></a>範例 2</h3><p>在了解怎麼離開迴圈後，讓我們再看看比較長的測資，[3, 5, 6, 13, 18, 21, 23]，從中間找 18 這個值</p><div style="width: 300px; margin: auto"><img src="./binary_search_1.png" alt="example"></div><p>從這個過程中我們可以看到，不管是找右區間還是左區間，我們的 L &amp; H 的移動法則都是要保持搜索區間為 [L, H)，然後慢慢把搜索區間變小。</p><div style="width: 300px; margin: auto"><img src="./binary_search_2.png" alt="example"></div><p>再看一下這個例子，如果我把 18 改成 19，一樣是搜索 18 這個值，會發現結束時，我們的 low == high 並且跳出回圈回傳 1，就跟範例 1 的情況一樣，這時我們的 [low, high) 就成為空集合了。</p><h2 id="透過 -loop-invariant- 寫 -lower-bound"><a href="# 透過 -loop-invariant- 寫 -lower-bound" class="headerlink" title="透過 loop invariant 寫 lower bound"></a>透過 loop invariant 寫 lower bound</h2><p>以上我們的 binary search 的例子，只能找出 target 是否在 sorted array 或是不在 sorted array，但是如果要找 lower bound or upper bound 就無法使用了，下面給個例子什麼是 lower bound &amp; upper bound。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">            upper bound</span><br><span class="line">                +</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">       ^</span><br><span class="line">       lower bound</span><br></pre></td></tr></table></figure><p>如果要找 lower bound 其實就是稍微改寫下我們的 binary search </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(input_arr []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    low := <span class="number">0</span></span><br><span class="line">    high := <span class="built_in">len</span>(input_arr)  <span class="comment">// 符合 i ∈ [low,high)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> low &lt; high &#123;</span><br><span class="line">        mid := low + (high - low) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> input_arr[mid] &lt; target &#123;  </span><br><span class="line">            low = mid + <span class="number">1</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                     </span><br><span class="line">            high = mid</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> low</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>這邊的 loop invariant 跟之前的很相似，不過有些小變形</p><ol><li>搜索區間 <code>[low, high)</code> 不為空的話，low &lt; high 才會成立，反之為空的話，low == high 會離開迴圈</li><li>找出來的 sub range 搜索區間都是 <code>[low, high)</code><ul><li>右邊的區間 <code>[high&#39;, high)</code> 都是 &gt;= target 的值</li><li>左邊的區間 <code>[low, low&#39;)</code> 都是 &lt; target 的值</li></ul></li></ol><p>接著直接看圖說故事:</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_3.png" alt="example"></div><br>一樣維持搜索區間為 [L, H) (藍色)</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_4.png" alt="example"></div><br>因為 array[mid] &gt;= target，所以走到 H = mid，這裡其實產生了右邊的區間 <code>[high&#39;, high)</code> (粉色)，我們可以知道這個區間其實有著 &gt;= target 的特性，所以 target 也有可能落在這個區間內，到最後要找答案的時候這個區間很重要。</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_5.png" alt="example"></div><br>接著看到 array[mid] &lt; target，這代表了 <code>[low, mid]</code> 的這個區間都是小於 target 的，所以我們選擇讓 L = mid + 1，這樣產生出來的 <code>[low, low&#39;）</code>的區間 (綠色) 才符合我們所定義的特性，但是可以發現藍色區間還是 <code>[Low&#39;, high&#39;)</code>，我們的目標是要讓藍色區間縮小到不見，並保持 loop invariant。</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_6.png" alt="example"></div></p><p><div style="width: 400px; margin: auto"><img src="./binary_search_7.png" alt="example"></div><br>因為 array[mid] == target 所以繼續拓展右邊的區間，記得這個區間內的值都是 &gt;= target 的</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_8.png" alt="example"></div><br>結束時跟之前的例子一樣 L=H 會重合，這邊我們要的答案其實不管回傳 L 或是 H 的 index 都是一樣的結果，但是其實可以想成是取出粉紅色的第一個值，就會是我們要找的 lower bound。</p><h2 id="心得"><a href="# 心得" class="headerlink" title="心得"></a>心得 </h2><p> 其實 binary search 的變化真的很多，但是只要了解自己要搜索的區間長怎麼樣，就比較不會卡來卡去在那邊 +1, -1, 而最後寫的 lower bound 的方法其實也適用於一般的 binary search，可說是比較簡單又不容易錯的版本，不過要了解這個 loop invariant 怎麼定義區間，怎麼移動 low, high 去產生新的搜索區間，我還是建議大家用紙筆自己畫畫看，其實會比較有感覺，也可以拿 <code>A[low] &lt;= A[i] &lt;= A[high]</code> 這個為例子看看程式要怎麼寫才對，這篇文章的圖文寫得比較快，如果有不清楚或是錯誤的地方在請大家指正 :)</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://www.eecs.yorku.ca/course_archive/2013-14/W/2011/lectures/09%20Loop%20Invariants%20and%20Binary%20Search.pdf" target="_blank" rel="noopener">binary search and loop invariant</a></li><li><a href="https://zhu45.org/posts/2018/Jan/12/how-to-write-binary-search-correctly/" target="_blank" rel="noopener">How to write binary search correctly</a></li><li><a href="https://www.zhihu.com/question/36132386" target="_blank" rel="noopener">https://www.zhihu.com/question/36132386</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;p&gt;Binary search 記得是我剛入門寫程式的時候，前幾個回家作業，當時寫出來時，覺得整個程式就
      
    
    </summary>
    
    
      <category term="algorithm" scheme="http://kkc.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>AWS Shuffle Sharding</title>
    <link href="http://kkc.github.io/2019/03/04/AWS-Shuffle-Sharding/"/>
    <id>http://kkc.github.io/2019/03/04/AWS-Shuffle-Sharding/</id>
    <published>2019-03-04T01:37:42.000Z</published>
    <updated>2019-03-04T15:37:25.722Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>Colm MacCárthaigh 是 AWS 的 Senior Principal Engineer，如果常在追他的 Twitter <a href="https://twitter.com/colmmacc" target="_blank" rel="noopener">帳號 </a> 會看到很多有趣的 AWS 內部的 architecture 設計，像是最近有人在 og-aws.slack.com 的討論區問到為什麼 AWS 的 <a href="https://status.aws.amazon.com/" target="_blank" rel="noopener">status alert</a> 不一定會影響到該 region 的全部 customer 呢? 我隨機找了一個 alert 的內容:</p><blockquote><p>Beginning at 11:54 AM PST some Amazon Aurora clusters experienced increased database create times and cluster unavailability in the AP-SOUTHEAST-2 Region. Elevated create times were resolved at 2:27 PM PST, at which point some existing clusters continued to experience availability issues. As of 5:35 PM PST both issues have been resolved and the service is operating normally. In total, the event impacted a little less than <code>3%</code> of the Aurora databases in the region.</p></blockquote><p>可以看得出來，這個問題只影響了 3% 的 Aurora database，然後 AWS 這邊會建議每個用戶使用 Personal Health Dashboard 去看是否真的有受影響，這邊就讓很多人好奇 AWS 的底層，到底是怎麼去做 isolation 且提供 multi-tenancy 的服務，不讓一些故障的 servers 影響到全部人，而我這篇文章就是從 Colm MacCárthaigh 的 tweet 展開，有興趣的人也可以直接去看他的 tweet。</p><p><blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">It&#39;s no good sharing everything if a single &quot;noisy neighbor&quot; can cause everyone to have a bad experience. We want the opposite!  At AWS we are super into compartmentalization and isolation, and mature remediation procedures. Shuffle Sharding is one of our best techniques. O.k. ..</p>&mdash; Colm MacCárthaigh (@colmmacc) <a href="https://twitter.com/colmmacc/status/1034494834172604416?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">August 28, 2018</a></blockquote></p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><h1 id="Shuffle-Sharding"><a href="#Shuffle-Sharding" class="headerlink" title="Shuffle Sharding"></a>Shuffle Sharding</h1><p>其實 Colm MacCarthaigh 早在 2014 年的時候，就在 <a href="https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/" target="_blank" rel="noopener">AWS architecture blog</a> 上面揭露過 Shuffle Sharding 這個概念，而下面的例子我是從 reinvent 2018 的 <a href="https://www.slideshare.net/AmazonWebServices/how-aws-minimizes-the-blast-radius-of-failures-arc338-aws-reinvent-2018" target="_blank" rel="noopener">slides</a> 裡面擷取出來的。</p><h2 id="Basic-architecture"><a href="#Basic-architecture" class="headerlink" title="Basic architecture"></a>Basic architecture</h2><p>假設你有一組 service，裡面共有八個 nodes，這些 nodes 都接在一組 LB 後面，此時有八組不同的 customer 上門， 如果 Diamond 這個 request 進到系統後，因為某些原因，也許是剛好碰到系統的某個 Bug 或是某種 workload 不小心把一組 node 打垮了，又好巧不巧的，它因為沒有接受到想要的回應，不斷的 retry 也把其他的 nodes 也打垮了，這時候我們要討論的 Term 叫做 <code>Blast Radius</code>，也就是針對 customers 的爆炸範圍，以我們這個例子來看 </p><p><img src="./0.png" alt="0.png"><br><img src="./1.png" alt="1.png"></p><p>也就是全部的 customer 都被炸翻了！ 這也是最糟糕的狀況，AWS 在建構它們的服務時極力的避免這種情況。</p><h2 id="Cell-based-architecture"><a href="#Cell-based-architecture" class="headerlink" title="Cell-based architecture"></a>Cell-based architecture</h2><p>為了避免 Diamond 直接把全部 nodes 都弄爛，其實簡單一點的方法可以直接把 nodes 分組，切成不同的 cell，兩兩成群，而針對不同的 cells，我們也會分配兩個 customer，這樣 Diamond 頂多把其中兩台給弄掛掉，而以這個例子來看頂多愛心這個倒霉的 customer 一起中招，這樣一來針對 <code>Blast Radis</code> 就可以得到 4x 的改進，從 100% 下降到 25%，也就是只有 25% 的 customer 受到影響。</p><p><img src="./2.png" alt="2.png"></p><p>這個方法在 AWS 內部稱作 <code>cellularization</code>，其實套用在很多不同的服務上面，像是 isolated regions 還有 availability zones。</p><h2 id="Shuffle-Sharding-1"><a href="#Shuffle-Sharding-1" class="headerlink" title="Shuffle Sharding"></a>Shuffle Sharding</h2><p>有了以上概念後，可以再回到 Shuffle Sharding，其實非常的簡單，我們不一定要讓 customer 在固定的 cell 裡面，其實目標只是要分配 customer 的 requests 到不同的兩個 node 上面，而通過 random 的分配不同的 nodes 上面，透過下面這張圖我們可以發現，這個方法的威力真的很大，Diamond 雖然也是讓兩個 nodes 直接掛掉，但是在上面的 customer 其實分別是愛心和梅花，而他們的 request 還有其他的 node 可以服務，所以愛心和梅花，還是可以通過 retry 去達到 fault tolerance，所以整體的 Blast Radius 降低到只影響一個 customer。</p><p><img src="./3.png" alt="3.png"></p><p>這個圖是比較簡化的，其實 8 個 的 nodes 去隨機選出 2 個 node 的 combination 是 28 組，也就是有 28 種分配方式，而 Blast Radius 的算法是像下面這樣去考慮某一組 combination 壞掉的機率:</p><p>slides 中也提供了一個 table 告訴我們，採取了 Suffle sharding 會讓 % customer impacted 降到 3% ! 這也是為什麼 AWS 的 service 有問題時，會推薦你看 personal health dashboard ，因為爆炸範圍真的沒那麼廣。</p><table><thead><tr><th>Overlap</th><th>% customer impacted</th></tr></thead><tbody><tr><td>0</td><td>53.6%</td></tr><tr><td>1</td><td>42.8%</td></tr><tr><td>2</td><td>3.6%</td></tr></tbody></table><p>講到這邊，其實已經覺得很厲害了，不過 AWS 因為客戶非常的多，所以還是無法容忍這麼高的影響率，所以 AWS 設計了 100 個 Nodes，shard size 為 5 的架構，這邊再來算個數學</p><table><thead><tr><th>Overlap</th><th>% customer impacted</th></tr></thead><tbody><tr><td>0</td><td>77%</td></tr><tr><td>1</td><td>21%</td></tr><tr><td>2</td><td>1.8%</td></tr><tr><td>3</td><td>0.06%</td></tr><tr><td>4</td><td>0.0006%</td></tr><tr><td>5</td><td>0.0000013%</td></tr></tbody></table><p>整體的數字下降到 <code>0.0000013%</code>!</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>在使用 Shuffle Sharding 中，Client 端的 retry 也是很重要的，然後可以透過數學知道 Node &amp; Shard 的數量產生的機率，再去設計你的架構，從 Shuffle Sharding 再來看 AWS 怎麼處理自身內部的 deployment，就變得異常合理和安全，AWS 的部署方式是先從某個 region 中的一個 AZ 來部署，如果 monitoring 的結果都沒問題，在慢慢 rollout 到不同 AZ 接著到不同的 region，這樣一但有問題，受到影響的 customer 數量也是極少，透過瞭解 AWS 底層也可以讓我們了解，為什麼 Multi-AZ 的部署那麼重要，因為透過 AWS 底層的這種技術，再加上 application 有做到良好的 retry，其實是可以提昇整體 service 的 reliability 的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.youtube.com/watch?v=swQbA4zub20" target="_blank" rel="noopener">AWS re:Invent 2018: How AWS Minimizes the Blast Radius of Failures (ARC338)</a></li><li><a href="https://www.slideshare.net/AmazonWebServices/how-aws-minimizes-the-blast-radius-of-failures-arc338-aws-reinvent-2018" target="_blank" rel="noopener">https://www.slideshare.net/AmazonWebServices/how-aws-minimizes-the-blast-radius-of-failures-arc338-aws-reinvent-2018</a></li><li><a href="https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;Colm MacCárthaigh 是 AWS 的 Senior Principal Enginee
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="Operation" scheme="http://kkc.github.io/tags/Operation/"/>
    
  </entry>
  
  <entry>
    <title>利用 Helm 在 EKS 上安裝 Prometheus</title>
    <link href="http://kkc.github.io/2019/02/25/install-prometheus-on-EKS/"/>
    <id>http://kkc.github.io/2019/02/25/install-prometheus-on-EKS/</id>
    <published>2019-02-25T08:39:36.000Z</published>
    <updated>2019-02-25T14:11:02.180Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>最近把玩了 EKS 一陣子，基本上 EKS 就是 AWS 提供的 Managed Kubernetes，主要是幫你管理 Kubernetes 的 master node，我們只需要管理 worker node 就好了，所以很多的服務還是可以用原本的 helm chart 裝起來，這篇文章會介紹怎麼在 EKS 上面利用 helm 安裝 Prometheus 相關的套件，還有一些簡單的設定。</p><p>這篇文章會包含以下內容</p><ul><li>利用 helm 安裝 Prometheus-operator 再透過 Operator 去部署 prometheus &amp; alertmanager</li><li>如何設定 helm value 去避免一些 EKS 上面的錯誤問題</li><li>Troubleshooting 的一些 tips</li></ul><h1 id="利用 -helm- 安裝 -prometheus"><a href="# 利用 -helm- 安裝 -prometheus" class="headerlink" title="利用 helm 安裝 prometheus"></a>利用 helm 安裝 prometheus</h1><p>因為 <code>coreos/prometheus-operator</code> 的 helm chart 已經被 deprecated 掉了，所以我們這邊會使用 <code>stable/prometheus-operator</code> 去做安裝，而這包 chart 其實有包含蠻多 components 像是 <code>prometheus</code> &amp; <code>alertmanager</code> ，還會幫你裝好 prometheus 需要監控用的 <code>node-exporter</code> 等等東西，所以非常大一包，很建議大家裝好後，可以回過頭來看看到底被安裝了哪些東西。</p><h2 id="確認 -stable-prometheus-operator- 版本"><a href="# 確認 -stable-prometheus-operator- 版本" class="headerlink" title="確認 stable/prometheus-operator 版本"></a>確認 stable/prometheus-operator 版本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm search -l stable/prometheus-operator</span></span><br></pre></td></tr></table></figure><p>可以看到目前最新的 Chart 版本是 <code>4.0.0</code><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                             CHART VERSION   APP VERSION     DESCRIPTION</span><br><span class="line">stable/prometheus-operator      <span class="number">4.0</span><span class="number">.0</span>           <span class="number">0.29</span><span class="number">.0</span>          Provides easy monitoring definitions for Kubernetes servi...</span><br><span class="line">stable/prometheus-operator      <span class="number">3.0</span><span class="number">.0</span>           <span class="number">0.29</span><span class="number">.0</span>          Provides easy monitoring definitions for Kubernetes servi...</span><br><span class="line">stable/prometheus-operator      <span class="number">2.6</span><span class="number">.0</span>           <span class="number">0.27</span><span class="number">.0</span>          Provides easy monitoring definitions for Kubernetes servi...</span><br></pre></td></tr></table></figure></p><p>安裝，這邊我們把安裝的名字取作 <code>prom-op</code><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install --name prom-op --<span class="keyword">namespace</span> monitoring stable/prometheus-<span class="keyword">operator</span></span><br></pre></td></tr></table></figure></p><p>透過以下的指令可以得知安裝了些什麼東西<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl --<span class="keyword">namespace</span> monitoring <span class="keyword">get</span> pods</span><br></pre></td></tr></table></figure></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">NAME                                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">alertmanager-prom-op-prometheus-operato-alertmanager<span class="number">-0</span>   <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">1</span>m</span><br><span class="line">prom-op-grafana<span class="number">-5</span>c59ddfb9d-zqfqt                         <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-kube-<span class="section">state</span>-metrics<span class="number">-76786</span>cc9b4<span class="number">-8</span>q4bj              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter<span class="number">-6</span>jclc                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter-bxr49                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter-mxtht                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter-xd54m                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-operato-operator<span class="number">-6</span>cbf5d5cfd-z6fz4     <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prometheus-prom-op-prometheus-operato-prometheus<span class="number">-0</span>       <span class="number">3</span>/<span class="number">3</span>     Running   <span class="number">1</span>          <span class="number">1</span>m</span><br></pre></td></tr></table></figure><p>因為我這台 k8s cluster 有起了 4 個 node，所以會安裝 4 個 node operator，然後還會安裝 prometheus-operator, alertmanager, grafana 和 kube-state-metrics。</p><h2 id="Customizing-the-Chart"><a href="#Customizing-the-Chart" class="headerlink" title="Customizing the Chart"></a>Customizing the Chart</h2><p>透過 port forward 讀取 localhost:9090 可以看到 prometheus 裡面的資訊<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl port-forward svc/prom-op-prometheus-operato-prometheus -n monitoring 9090</span></span><br></pre></td></tr></table></figure></p><p>其中我們會看到以下這些錯誤<br><img src="./prometheus-error.png" alt="prometheus-error"><br><img src="./prometheus-error-2.png" alt="prometheus-error-2"></p><p>因為我們無法監控到 EKS 的 master node，所以關於 master 上面的 services 像是 etcd, kube-apiserver, controller-manager, kube-schedule 都會在 prometheus 中發生錯誤，這也是為什麼我們需要客製化我們的 chart file。<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">cp</span> http<span class="variable">s:</span>//raw.githubusercontent.<span class="keyword">com</span>/helm/charts/master/stable/prometheus-operator/<span class="built_in">values</span>.yaml <span class="built_in">values</span>.yaml</span><br></pre></td></tr></table></figure></p><p>修改完後可以使用以下指令去覆寫<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm<span class="built_in"> upgrade </span>--install prom-op stable/prometheus-operator --namespace monitoring -f values.yaml</span><br></pre></td></tr></table></figure></p><p>這邊筆記下我有更改的部分，master 上面的 services 像是 etcd, kube-apiserver, controller-manager, kube-schedule 等等的 monitoring 機制需要被關閉<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kubeApiServer</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubeControllerManager</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubeEtcd</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubeScheduler</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></p><p>kubelet 的話根據這個 <a href="https://github.com/coreos/prometheus-operator/issues/926" target="_blank" rel="noopener">issue</a>，在 EKS 上面使用的話，我們需要把 https 的部分 enable 起來</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kubelet:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  serviceMonitor:</span></span><br><span class="line"><span class="attr">    https:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>EKS 上面的 coreDns 的 label 有點怪，還是用 k8s-app:kube-dns 而不是 coredns<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">coreDns:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  service:</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">9153</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="number">9153</span></span><br><span class="line"><span class="attr">    selector:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">kube-dns</span></span><br></pre></td></tr></table></figure></p><p>還有一些 resource 的部分記得要調整下</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">resources:</span></span><br><span class="line"><span class="symbol">  requests:</span></span><br><span class="line"><span class="symbol">    memory:</span> <span class="number">400</span>Mi</span><br></pre></td></tr></table></figure><h1 id="設定 -addtional-scrape-config"><a href="# 設定 -addtional-scrape-config" class="headerlink" title="設定 addtional scrape config"></a>設定 addtional scrape config</h1><p>Prometheus 除了可以用來 monitor Kubernetes 內部的 service 外，其實也有提供一些方法去 scrape 外面的 service，像是有一些程式跑在既有的 EC2 上面，我們可以透過相對應的 EC2 service discovery 的方法去拉取資料，要達成相關的任務，則需要去設定 addtional config。</p><p>方法很簡單，需要先在 chart 的 value 中把原本的 additionalScrapeConfigs</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">additionalScrapeConfigs: <span class="string">[]</span></span><br></pre></td></tr></table></figure><p>改寫為需要另外掛上去的 config</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">additionalScrapeConfigs</span>:</span><br><span class="line">  - <span class="attribute">job_name</span>: placeholder</span><br><span class="line">    <span class="attribute">metrics_path</span>: /probe</span><br><span class="line">    <span class="attribute">params</span>:</span><br><span class="line">    <span class="attribute">module</span>: [http_2xx]</span><br><span class="line">    <span class="attribute">static_configs</span>:</span><br><span class="line">      - <span class="attribute">targets</span>:</span><br><span class="line">        - <span class="attribute">https</span>:<span class="comment">//sentry.umbocv.com/_health/?full</span></span><br></pre></td></tr></table></figure><p>但是這種做法需要一直更改 helm chart 的 value，而這邊也提供另外一種方法可以直接更改 config，讓 prometheus config reloader 去讀取，使用<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="builtin-name">get</span><span class="built_in"> secret </span>-n monitoring</span><br></pre></td></tr></table></figure></p><p>會看到有</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                                          <span class="built_in"> TYPE </span>                                 DATA   AGE</span><br><span class="line">prom-op-prometheus-scrape-confg                Opaque                                1      30s</span><br></pre></td></tr></table></figure><p>我們可以透過直接更改這個 secret 的內容而改動 addtional-scrape-config，而以下這個 addtional-scrape-configs.yaml 以上面的例子會長成這樣</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- job_name:</span> <span class="string">placeholder</span></span><br><span class="line"><span class="attr">  metrics_path:</span> <span class="string">/probe</span></span><br><span class="line"><span class="attr">  params:</span></span><br><span class="line"><span class="attr">  module:</span> <span class="string">[http_2xx]</span></span><br><span class="line"><span class="attr">  static_configs:</span></span><br><span class="line"><span class="attr">    - targets:</span></span><br><span class="line"><span class="attr">      - https:</span><span class="string">//sentry.umbocv.com/_health/?full</span></span><br></pre></td></tr></table></figure><p>接著透過這行指令把這個 <code>addtional-scrape-configs.yaml</code> 轉成 k8s 認得的 secret yaml，在 apply 上去<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create<span class="built_in"> secret </span>generic prom-op-prometheus-scrape-confg <span class="attribute">--from-file</span>=additional-scrape-configs.yaml --dry-<span class="builtin-name">run</span> -oyaml &gt; prometheus-additional-scrape-configs.yaml</span><br><span class="line">$ kubectl apply -f prometheus-additional-scrape-configs.yaml -n monitoring</span><br></pre></td></tr></table></figure></p><h1 id="設定 -alert-manager-template"><a href="# 設定 -alert-manager-template" class="headerlink" title="設定 alert manager template"></a>設定 alert manager template</h1><p>在使用完 prometheus-operator 的 helm 部署完後，其實可以從 UI 中的 status -&gt; rules 中看到許多內建好的 prometheus 的 rule，而如果想要把這個警告發到 slack 上面還需要設定 alertmanager 的 route config，而內建的 config 其實沒做任何事情，都是導到 null 而已</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">config</span>:</span><br><span class="line">  <span class="attribute">global</span>:</span><br><span class="line">    <span class="attribute">resolve_timeout</span>: <span class="number">5</span>m</span><br><span class="line">  <span class="attribute">route</span>:</span><br><span class="line">    <span class="attribute">group_by</span>: [<span class="string">'job'</span>]</span><br><span class="line">    <span class="attribute">group_wait</span>: <span class="number">30s</span></span><br><span class="line">    <span class="attribute">group_interval</span>: <span class="number">5</span>m</span><br><span class="line">    <span class="attribute">repeat_interval</span>: <span class="number">12</span>h</span><br><span class="line">    <span class="attribute">receiver</span>: <span class="string">'null'</span></span><br><span class="line">    <span class="attribute">routes</span>:</span><br><span class="line">    - <span class="attribute">match</span>:</span><br><span class="line">        <span class="attribute">alertname</span>: Watchdog</span><br><span class="line">      <span class="attribute">receiver</span>: <span class="string">'null'</span></span><br><span class="line">  <span class="attribute">receivers</span>:</span><br><span class="line">  - <span class="attribute">name</span>: <span class="string">'null'</span></span><br></pre></td></tr></table></figure><p>而這邊我們可以參考 Monza 的 <a href="https://gist.github.com/milesbxf/e2744fc90e9c41b47aa47925f8ff6512" target="_blank" rel="noopener">alertmanager slack template</a> ，這個 template 的好處就是可以幫 alert 都合併為一個發出來，然後也有吃內建的 rule 的 format，舉個例子像下面的這個 rule，裡面用到的 labels 是 <code>serverity: critical</code>，然後 annotations 裡面是 <code>message</code> &amp; <code>runbook_url</code></p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">alert</span>: KubeAPIDown</span><br><span class="line"><span class="attribute">expr</span>: absent(up&#123;job=<span class="string">"apiserver"</span>&#125;</span><br><span class="line">  == <span class="number">1</span>)</span><br><span class="line"><span class="attribute">for</span>: <span class="number">15</span>m</span><br><span class="line"><span class="attribute">labels</span>:</span><br><span class="line">  <span class="attribute">severity</span>: critical</span><br><span class="line"><span class="attribute">annotations</span>:</span><br><span class="line">  <span class="attribute">message</span>: KubeAPI has disappeared from Prometheus target discovery.</span><br><span class="line">  <span class="attribute">runbook_url</span>: <span class="attribute">https</span>:<span class="comment">//github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown</span></span><br></pre></td></tr></table></figure><p>而透過 Monza 的 template 我們可以先設定 alertmanager 的 endpoint</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">receivers:</span><br><span class="line">###################################################</span><br><span class="line">## Slack Receivers</span><br><span class="line">- name: slack-<span class="keyword">code</span>-owners</span><br><span class="line">  slack_configs:</span><br><span class="line">  - channel: <span class="string">'#&#123;&#123;- template"slack.monzo.code_owner_channel". -&#125;&#125;'</span></span><br><span class="line">    send_resolved: true</span><br><span class="line">    title: <span class="string">'&#123;&#123; template"slack.monzo.title". &#125;&#125;'</span></span><br><span class="line">    icon_emoji: <span class="string">'&#123;&#123; template"slack.monzo.icon_emoji". &#125;&#125;'</span></span><br><span class="line">    color: <span class="string">'&#123;&#123; template"slack.monzo.color". &#125;&#125;'</span></span><br><span class="line">    text: <span class="string">'&#123;&#123; template"slack.monzo.text". &#125;&#125;'</span></span><br><span class="line">    actions:</span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Runbook :green_book:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; (index .Alerts 0).Annotations.runbook_url &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Query :mag:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; (index .Alerts 0).GeneratorURL &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Dashboard :grafana:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; (index .Alerts 0).Annotations.dashboard &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Silence :no_bell:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; template"__alert_silence_link". &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'&#123;&#123; template"slack.monzo.link_button_text". &#125;&#125;'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; .CommonAnnotations.link_url &#125;&#125;'</span></span><br></pre></td></tr></table></figure><p>在透過定義好的 template 中，我們可以看到已經有確認收到的警告是 <code>.Annotations.message</code> 會被顯示出來，這樣一來就可以把相關的 rule alert 打到 slack 上了。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This builds the silence URL.  We exclude the alertname in the range</span></span><br><span class="line"><span class="comment"># to avoid the issue of having trailing comma separator (%2C) at the end</span></span><br><span class="line"><span class="comment"># of the generated URL</span></span><br><span class="line">&#123;&#123; define <span class="string">"__alert_silence_link"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; .ExternalURL &#125;&#125;/<span class="comment">#/silences/new?filter=%7B</span></span><br><span class="line">    &#123;&#123;- range .CommonLabels.SortedPairs -&#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">if</span> ne .Name <span class="string">"alertname"</span> -&#125;&#125;</span><br><span class="line">            &#123;&#123;- .Name &#125;&#125;%<span class="number">3</span>D<span class="string">"&#123;&#123;- .Value -&#125;&#125;"</span>%<span class="number">2</span>C%<span class="number">20</span></span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    alertname%<span class="number">3</span>D<span class="string">"&#123;&#123; .CommonLabels.alertname &#125;&#125;"</span>%<span class="number">7</span>D</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">"__alert_severity_prefix"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> ne .Status <span class="string">"firing"</span> -&#125;&#125;</span><br><span class="line">    :lgtm:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .Labels.severity <span class="string">"critical"</span> -&#125;&#125;</span><br><span class="line">    :fire:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .Labels.severity <span class="string">"warning"</span> -&#125;&#125;</span><br><span class="line">    :warning:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">    :question:</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">"__alert_severity_prefix_title"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> ne .Status <span class="string">"firing"</span> -&#125;&#125;</span><br><span class="line">    :lgtm:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"critical"</span> -&#125;&#125;</span><br><span class="line">    :fire:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"warning"</span> -&#125;&#125;</span><br><span class="line">    :warning:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"info"</span> -&#125;&#125;</span><br><span class="line">    :information_source:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">    :question:</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;/* First line <span class="keyword">of</span> Slack alerts */&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.title"</span> -&#125;&#125;</span><br><span class="line">    [&#123;&#123; .Status | toUpper -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> eq .Status <span class="string">"firing"</span> &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    ] &#123;&#123; template <span class="string">"__alert_severity_prefix_title"</span> . &#125;&#125; &#123;&#123; .CommonLabels.alertname &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Color <span class="keyword">of</span> Slack attachment (appears <span class="keyword">as</span> line next <span class="keyword">to</span> alert )*/&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.color"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> eq .Status <span class="string">"firing"</span> -&#125;&#125;</span><br><span class="line">        &#123;&#123; <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"warning"</span> -&#125;&#125;</span><br><span class="line">            warning</span><br><span class="line">        &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"critical"</span> -&#125;&#125;</span><br><span class="line">            danger</span><br><span class="line">        &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">            <span class="comment">#439FE0</span></span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">    good</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Emoji <span class="keyword">to</span> display <span class="keyword">as</span> user icon (custom emoji supported!) */&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.icon_emoji"</span> &#125;&#125;:prometheus:&#123;&#123; <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* The test <span class="keyword">to</span> display <span class="keyword">in</span> <span class="keyword">the</span> alert */&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.text"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; range .Alerts &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">if</span> .Annotations.message &#125;&#125;</span><br><span class="line">            &#123;&#123; .Annotations.message &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">if</span> .Annotations.description &#125;&#125;</span><br><span class="line">            &#123;&#123; .Annotations.description &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;- /* If none <span class="keyword">of</span> <span class="keyword">the</span> <span class="keyword">below</span> matches, send <span class="keyword">to</span> <span class="comment">#monitoring-no-owner, and we </span></span><br><span class="line">can <span class="keyword">then</span> assign <span class="keyword">the</span> expected code_owner <span class="keyword">to</span> <span class="keyword">the</span> alert <span class="keyword">or</span> map <span class="keyword">the</span> code_owner</span><br><span class="line"><span class="keyword">to</span> <span class="keyword">the</span> correct channel */ -&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"__get_channel_for_code_owner"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">if</span> eq . <span class="string">"platform-team"</span> -&#125;&#125;</span><br><span class="line">        platform-alerts</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq . <span class="string">"security-team"</span> -&#125;&#125;</span><br><span class="line">        security-alerts</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">        monitoring-no-owner</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- /* Select <span class="keyword">the</span> channel based <span class="keyword">on</span> <span class="keyword">the</span> code_owner. We only expect <span class="keyword">to</span> <span class="keyword">get</span></span><br><span class="line"><span class="keyword">into</span> this template function <span class="keyword">if</span> <span class="keyword">the</span> code_owners label <span class="keyword">is</span> present <span class="keyword">on</span> an alert.</span><br><span class="line">This <span class="keyword">is</span> <span class="keyword">to</span> defend <span class="keyword">against</span> us accidentally breaking <span class="keyword">the</span> routing logic. */ -&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.code_owner_channel"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">if</span> .CommonLabels.code_owner &#125;&#125;</span><br><span class="line">        &#123;&#123; template <span class="string">"__get_channel_for_code_owner"</span> .CommonLabels.code_owner &#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">        monitoring</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.link_button_text"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">if</span> .CommonAnnotations.link_text -&#125;&#125;</span><br><span class="line">        &#123;&#123;- .CommonAnnotations.link_text -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">        Link</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125; :link:</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br></pre></td></tr></table></figure><p>這邊還有一個很重要的步驟，讓我卡了蠻久的，其實 template 也是一樣定義在 prometheus-operator 的 helm chart value.yaml 裡面，在定義完 template 後，一定要加上<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">templates:</span></span><br><span class="line">    - <span class="string">'/etc/alertmanager/config/*.tmpl'</span></span><br></pre></td></tr></table></figure></p><p>大概的範例長得像這樣</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">config</span><br><span class="line">  <span class="keyword">global</span>:</span><br><span class="line">    resolve_timeout: <span class="number">5</span>m</span><br><span class="line">  ... 略</span><br><span class="line"></span><br><span class="line">templates:</span><br><span class="line">  - '/etc/alertmanager/config/*.tmpl'</span><br><span class="line">   </span><br><span class="line">templateFiles:</span><br><span class="line">    template_monzo.tmpl: |-</span><br><span class="line"></span><br><span class="line">       &#123;&#123; <span class="keyword">define</span> <span class="string">"__alert_silence_link"</span> -&#125;&#125;</span><br><span class="line">          &#123;&#123; .ExternalURL &#125;&#125;/#/silences/new?<span class="keyword">filter</span>=<span class="symbol">%7</span>B</span><br><span class="line">          &#123;&#123;- range .CommonLabels.SortedPairs -&#125;&#125;</span><br><span class="line">              &#123;&#123;- if <span class="keyword">ne</span> .Name <span class="string">"alertname"</span> -&#125;&#125;</span><br><span class="line">                  &#123;&#123;- .Name &#125;&#125;<span class="symbol">%3</span>D<span class="string">"&#123;&#123;- .Value -&#125;&#125;"</span><span class="symbol">%2</span>C<span class="symbol">%20</span></span><br><span class="line">              &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">          &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">          alertname<span class="symbol">%3</span>D<span class="string">"&#123;&#123; .CommonLabels.alertname &#125;&#125;"</span><span class="symbol">%7</span>D</span><br><span class="line">      &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">      ... 略</span><br></pre></td></tr></table></figure><h1 id="Troubleshoot"><a href="#Troubleshoot" class="headerlink" title="Troubleshoot"></a>Troubleshoot</h1><ol><li><p>如果一直沒收到 alert 的話，有可能是 alertmanager 的 template 寫錯，可以透過 <code>kubectl logs -f po/&lt;alertmanager_pod_name&gt; -n monitoring -c alertmanager</code> 去確認下是不是有產生一些 error log。</p></li><li><p>想要確認 alertmanager template 的語法的話，可以使用下面這個 script 去測試，主要是從這個 <a href="https://gist.github.com/cherti/61ec48deaaab7d288c9fcf17e700853a" target="_blank" rel="noopener">gist</a> 看來的，這樣就可以邊改 template 邊驗證，不用真的去產生一些錯誤條件出來。</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">name=<span class="formula">$RANDOM</span></span><br><span class="line"><span class="formula">url='http://localhost:9093/api/v1/alerts'</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo "firing up alert $</span>name" </span><br><span class="line"></span><br><span class="line"># change url o</span><br><span class="line">curl -XPOST <span class="formula">$url -d "[&#123; </span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>status<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>firing<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>labels<span class="tag">\<span class="name">"</span></span>: &#123;</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>alertname<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>$</span>name<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>service<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>my-service<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>severity<span class="tag">\<span class="name">"</span></span>:<span class="tag">\<span class="name">"</span></span>warning<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>instance<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span><span class="formula">$name.example.net<span class="tag">\<span class="name">"</span></span></span></span><br><span class="line"><span class="formula">&#125;,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>annotations<span class="tag">\<span class="name">"</span></span>: &#123;</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>summary<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>High latency is high!<span class="tag">\<span class="name">"</span></span></span></span><br><span class="line"><span class="formula">&#125;,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>generatorURL<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>http://prometheus.int.example.net/&lt;generating_expression&gt;<span class="tag">\<span class="name">"</span></span></span></span><br><span class="line"><span class="formula">&#125;]"</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo ""</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo"press enter to resolve alert"</span></span><br><span class="line"><span class="formula">read</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo"sending resolve"</span></span><br><span class="line"><span class="formula">curl -XPOST $</span>url -d"[&#123; </span><br><span class="line"><span class="tag">\<span class="name">"</span></span>status<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>resolved<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>labels<span class="tag">\<span class="name">"</span></span>: &#123;</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>alertname<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span><span class="formula">$name<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>service<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>my-service<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>severity<span class="tag">\<span class="name">"</span></span>:<span class="tag">\<span class="name">"</span></span>warning<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>instance<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>$</span>name.example.net<span class="tag">\<span class="name">"</span></span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>annotations<span class="tag">\<span class="name">"</span></span>: &#123;</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>summary<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>High latency is high!<span class="tag">\<span class="name">"</span></span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>generatorURL<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>http://prometheus.int.example.net/&lt;generating_expression&gt;<span class="tag">\<span class="name">"</span></span></span><br><span class="line">&#125;]"</span><br></pre></td></tr></table></figure></li></ol><p>或是用</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">alerts='[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">"labels"</span>: &#123;</span><br><span class="line">       <span class="string">"alertname"</span>: <span class="string">"instance_down"</span>,</span><br><span class="line">       <span class="string">"instance"</span>: <span class="string">"example1"</span></span><br><span class="line">     &#125;,</span><br><span class="line">     <span class="string">"annotations"</span>: &#123;</span><br><span class="line">        <span class="string">"info"</span>: <span class="string">"The instance example1 is down"</span>,</span><br><span class="line">        <span class="string">"summary"</span>: <span class="string">"instance example1 is down"</span></span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">]'</span><br><span class="line"></span><br><span class="line">URL=<span class="string">"https://alertmanager.mydomain.com"</span></span><br><span class="line"></span><br><span class="line">curl -XPOST -d<span class="string">"$alerts"</span> $URL/api/v1/alerts</span><br></pre></td></tr></table></figure><ol start="3"><li><p>可以使用看看是否自己的 secret 內容是正確的</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="builtin-name">get</span><span class="built_in"> secret </span>-n monitoring alertmanager-prom-op-alertmanager -o <span class="attribute">go-template</span>=<span class="string">'&#123;&#123; index .data"alertmanager.yaml"&#125;&#125;'</span> | base64</span><br></pre></td></tr></table></figure></li></ol><h1 id="完整移除 -prometheus-operator"><a href="# 完整移除 -prometheus-operator" class="headerlink" title="完整移除 prometheus-operator"></a>完整移除 prometheus-operator</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ helm delete --purge &lt;name&gt;</span><br><span class="line">$ kubectl delete crd prometheuses<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br><span class="line">$ kubectl delete crd prometheusrules<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br><span class="line">$ kubectl delete crd servicemonitors<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br><span class="line">$ kubectl delete crd alertmanagers<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure><h1 id="後記"><a href="# 後記" class="headerlink" title="後記"></a>後記 </h1><p> 原本使用 prometheus-operator 其實還有個雷就是 servicemonitor 需要打上 <code>release: &lt;deploy_name&gt;</code>，這樣 operator 才真的會去吃這個 service monitor，但是隨著 4.0.0 的更新也把這個惱人的東西修掉了，所以建議大家常常去看下到底更新了什麼，其實 prometheus &amp; alertmanager 的版本也是一直推進很快的，而接下來有想到什麼更多的內容，還會繼續更新這篇。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/helm/charts/tree/master/stable/prometheus-operator" target="_blank" rel="noopener">https://github.com/helm/charts/tree/master/stable/prometheus-operator</a></li><li><a href="https://github.com/prometheus/alertmanager/issues/437" target="_blank" rel="noopener">https://github.com/prometheus/alertmanager/issues/437</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;最近把玩了 EKS 一陣子，基本上 EKS 就是 AWS 提供的 Managed Kubernete
      
    
    </summary>
    
    
      <category term="monitoring" scheme="http://kkc.github.io/tags/monitoring/"/>
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="EKS" scheme="http://kkc.github.io/tags/EKS/"/>
    
      <category term="prometheus" scheme="http://kkc.github.io/tags/prometheus/"/>
    
      <category term="kubernetes" scheme="http://kkc.github.io/tags/kubernetes/"/>
    
      <category term="helm" scheme="http://kkc.github.io/tags/helm/"/>
    
  </entry>
  
  <entry>
    <title>Deploy Prometheus Operator With Thanos</title>
    <link href="http://kkc.github.io/2019/02/10/prometheus-operator-with-thanos/"/>
    <id>http://kkc.github.io/2019/02/10/prometheus-operator-with-thanos/</id>
    <published>2019-02-10T13:53:12.000Z</published>
    <updated>2019-02-11T03:41:45.893Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>Prometheus is widely adopted as a standard monitoring tool with Kubernetes because it provides many useful features such as dynamic service discovery, powerful queries, and seamless alert notification integration. There are many applications and client libraries support Prometheus which makes the operation’s life easier. Although things are going pretty well with prometheus, the original prometheus deployment is not able to easily achieve High Availablity and long term storage.</p><h1 id="Thanos-comes-to-the-rescue"><a href="#Thanos-comes-to-the-rescue" class="headerlink" title="Thanos comes to the rescue"></a>Thanos comes to the rescue</h1><p><img src="./thanos.jpeg" alt="Thanos"></p><p>Thanos is developed by <a href="https://github.com/improbable-eng" target="_blank" rel="noopener">improbable</a> which can be integrated with prometheus transparently and solve HA and long term storage issues without hurting performance. The idea of Thanos is to run sidecar component of prometheus, therefore meaning that sidecar components can interact with prometheus to upload or query metrics. Also, prometheus operator supports thanos natively which make us easier to deploy our promtheus cluster along with thanos. This solution seems pretty elegant when you choose prometheus operator to provision prometheus cluster.</p><p>This article includes the following contents</p><ul><li>How to deploy the prometheus operator on the kubernetes</li><li>How to deploy the thanos sidecar w/ prometheus.</li><li>Achieve HA: using thanos querier</li><li>Query historical data: thanos store</li><li>Reduce data size: thanos compactor</li></ul><h1 id="Install-Prometheus-through-Prometheus-operator"><a href="#Install-Prometheus-through-Prometheus-operator" class="headerlink" title="Install Prometheus through Prometheus operator"></a>Install Prometheus through Prometheus operator</h1><p>There are tons of article introducing why we need to adopt prometheus-operator to provision prometheus. I recommend you read the following references[2] if you are not familiar with prometheus-operator.</p><h2 id="1-Install-Helm-in-your-environment"><a href="#1-Install-Helm-in-your-environment" class="headerlink" title="1. Install Helm in your environment"></a>1. Install Helm in your environment</h2><ul><li>MacOS: <code>brew install kubernetes-helm</code></li><li>Linux: <code>sudo snap install helm</code></li></ul><h2 id="2-Initialize-helm-and-install-tiller"><a href="#2-Initialize-helm-and-install-tiller" class="headerlink" title="2. Initialize helm and install tiller"></a>2. Initialize helm and install tiller</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm init</span></span><br></pre></td></tr></table></figure><h2 id="3-Install-coreos-prometheus-operator"><a href="#3-Install-coreos-prometheus-operator" class="headerlink" title="3. Install coreos prometheus operator"></a>3. Install coreos prometheus operator</h2><p>Note that we are using <code>stable/prometheus-operator</code> because <code>coreos/prometheus-operator</code> helm is going to be deprecated. We later need to modify chart value to provision prometheus cluster along with thanos sidecar. To install a stable helm chart with custom value, you need to download <code>values.yaml</code> from <a href="https://github.com/helm/charts/blob/master/stable/prometheus-operator/values.yaml" target="_blank" rel="noopener">github repo</a>.</p><p>In this example, we named our prometheus operator as <code>prom-op</code> and install it under <code>monitoring</code> namespace.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm<span class="built_in"> upgrade </span>--install prom-op stable/prometheus-operator --namespace monitoring -f values.yaml</span><br></pre></td></tr></table></figure><p>Use the following command to verify if prometheus-operator is provisioning successfully.</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl --<span class="keyword">namespace</span> monitoring <span class="keyword">get</span> pods -l <span class="string">"release=prom-op"</span></span><br></pre></td></tr></table></figure><h1 id="Thanos-Deployment"><a href="#Thanos-Deployment" class="headerlink" title="Thanos Deployment"></a>Thanos Deployment</h1><p><strong>NEED TO KNOW </strong><br>prometheus-operator should be greater than 0.28.0 to support Thanos 2.0</p><h2 id="Thanos-Architecture"><a href="#Thanos-Architecture" class="headerlink" title="Thanos Architecture"></a>Thanos Architecture</h2><p>Official Architecture of Thanos<br><img src="https://raw.githubusercontent.com/improbable-eng/thanos/master/docs/img/arch.jpg" alt="arch"></p><p>Our deployment steps<br><img src="https://user-images.githubusercontent.com/17483589/45601152-096aba80-ba11-11e8-8d46-20f666583386.jpg" alt="arch"></p><p>According to the above picture, there are several components of thanos:</p><ul><li>Sidecar</li><li>Querier</li><li>Store</li><li>Compactor</li></ul><p>The deployment steps:</p><ol><li>Prometheus should be deployed with thanos <code>Sidecar</code>.</li><li>Deploy Thanos <code>Querier</code> which is able to talks to prometheus <code>Sidecar</code> through gossip protocol.</li><li>Make sure Thanos <code>Sidecar</code> is able to upload prometheus metrics to the given S3 bucket.</li><li>Establish the Thanos <code>Store</code> for retrieving long term storage. </li><li>Set up the <code>Compactor</code> to shrink historical data.</li></ol><h2 id="Install-Thanos-sidecar"><a href="#Install-Thanos-sidecar" class="headerlink" title="Install Thanos sidecar"></a>Install Thanos sidecar</h2><p>To install Thanos sidecar along with prometheus-operator, we should specify thanos sidecar in the chart value as following:</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">thanos</span>:</span><br><span class="line">    <span class="attribute">baseImage</span>: improbable/thanos</span><br><span class="line">    <span class="attribute">version</span>: v0.<span class="number">2.1</span></span><br><span class="line">    <span class="attribute">peers</span>: thanos-peers.monitoring.<span class="attribute">svc</span>:<span class="number">10900</span></span><br><span class="line">    <span class="attribute">objectStorageConfig</span>:</span><br><span class="line">      <span class="attribute">key</span>: thanos.yaml</span><br><span class="line">      <span class="attribute">name</span>: thanos-objstore-config</span><br></pre></td></tr></table></figure><p><code>objectStorageConfig</code> can be configured through configuration file <code>thanos.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">type:</span> <span class="string">s3</span></span><br><span class="line"><span class="attr">config:</span></span><br><span class="line"><span class="attr">  bucket:</span> <span class="string">test-prometheus-thanos</span></span><br><span class="line"><span class="attr">  endpoint:</span> <span class="string">s3.us-west-2.amazonaws.com</span></span><br><span class="line"><span class="attr">  encryptsse:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Creating the kubernetes secret by applying following command</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n monitoring create<span class="built_in"> secret </span>generic thanos-objstore-config <span class="attribute">--from-file</span>=thanos.yaml=/tmp/thanos-config.yaml</span><br></pre></td></tr></table></figure><p><strong>Warn</strong>: <code>endpoint</code> needs to be set in order to specify bucket located in which region.</p><h2 id="Verify-Thanos-Sidecar"><a href="#Verify-Thanos-Sidecar" class="headerlink" title="Verify Thanos Sidecar"></a>Verify Thanos Sidecar</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span> po -n monitoring</span><br></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">describe</span> po/prometheus-prom-<span class="built_in">op</span>-prometheus-<span class="number">0</span> -n monitoring</span><br></pre></td></tr></table></figure><p>If everything goes well, we could find out there is thanos-sidecar in the prometheus pod</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">thanos-<span class="string">sidecar:</span></span><br><span class="line">  Container <span class="string">ID:</span>  <span class="string">docker:</span><span class="comment">//e52df9fda7b0c43eea297d273169cf33e4aa49780fd8d5192c23f497c78b2007</span></span><br><span class="line"><span class="symbol">  Image:</span>         improbable/<span class="string">thanos:</span>v0<span class="number">.2</span><span class="number">.1</span></span><br><span class="line">  Image <span class="string">ID:</span>      docker-<span class="string">pullable:</span><span class="comment">//improbable/thanos@sha256:4ee0774316a5d57f78d243fe4afb10e9e889670d3facfdda70aae76f7165a16b</span></span><br><span class="line"><span class="symbol">  Ports:</span>         <span class="number">10902</span><span class="regexp">/TCP, 10901/</span>TCP, <span class="number">10900</span>/TCP</span><br><span class="line">  Host <span class="string">Ports:</span>    <span class="number">0</span><span class="regexp">/TCP, 0/</span>TCP, <span class="number">0</span>/TCP</span><br><span class="line"><span class="symbol">  Args:</span></span><br><span class="line">    sidecar</span><br><span class="line">    --prometheus.url=<span class="string">http:</span><span class="comment">//127.0.0.1:9090</span></span><br><span class="line">    --tsdb.path=/prometheus</span><br><span class="line">    --cluster.address=[$(POD_IP)]:<span class="number">10900</span></span><br><span class="line">    --grpc-address=[$(POD_IP)]:<span class="number">10901</span></span><br><span class="line">    --cluster.peers=thanos-peers.monitoring.svc.cluster.<span class="string">local:</span><span class="number">10900</span></span><br><span class="line"><span class="symbol">  State:</span>          Running</span><br><span class="line"><span class="symbol">    Started:</span>      Fri, <span class="number">01</span> Feb <span class="number">2019</span> <span class="number">12</span>:<span class="number">24</span>:<span class="number">38</span> +<span class="number">0800</span></span><br><span class="line"><span class="symbol">  Ready:</span>          True</span><br><span class="line">  Restart <span class="string">Count:</span>  <span class="number">0</span></span><br><span class="line"><span class="symbol">  Environment:</span></span><br><span class="line"><span class="symbol">    POD_IP:</span>   (<span class="string">v1:</span>status.podIP)</span><br><span class="line"><span class="symbol">  Mounts:</span></span><br><span class="line">    /prometheus from prometheus-prom-op-prometheus-db (rw)</span><br><span class="line">    <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io/serviceaccount from prom-op-prometheus-token<span class="number">-7</span>gvcp (ro)</span><br></pre></td></tr></table></figure><p>and if you check the log of sidecar, you will see following messages.<br><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">log</span> -f  po/prometheus-prom-op-prometheus-<span class="number">0</span> -<span class="built_in">n</span> monitoring -c thanos-sidecar</span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:15.173007261Z <span class="attribute">caller</span>=flags.go:90 <span class="attribute">msg</span>=<span class="string">"StoreAPI address that will be propagated through gossip"</span> <span class="attribute">address</span>=10.11.29.191:10901</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.178094001Z <span class="attribute">caller</span>=main.go:256 <span class="attribute">component</span>=sidecar <span class="attribute">msg</span>=<span class="string">"disabled TLS, key and cert must be set to enable"</span></span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.178211091Z <span class="attribute">caller</span>=factory.go:39 <span class="attribute">msg</span>=<span class="string">"loading bucket configuration"</span></span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.17855779Z <span class="attribute">caller</span>=sidecar.go:280 <span class="attribute">msg</span>=<span class="string">"starting sidecar"</span> peer=</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.179145313Z <span class="attribute">caller</span>=sidecar.go:220 <span class="attribute">component</span>=sidecar <span class="attribute">msg</span>=<span class="string">"Listening for StoreAPI gRPC"</span> address=[10.11.29.191]:10901</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.179187469Z <span class="attribute">caller</span>=main.go:308 <span class="attribute">msg</span>=<span class="string">"Listening for metrics"</span> <span class="attribute">address</span>=0.0.0.0:10902</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T12:33:50.282222532Z <span class="attribute">caller</span>=shipper.go:201 <span class="attribute">msg</span>=<span class="string">"upload new block"</span> <span class="attribute">id</span>=01D2MGSADK1860F4APSD7CFZ7C</span><br></pre></td></tr></table></figure><h2 id="Install-Thanos-Querier"><a href="#Install-Thanos-Querier" class="headerlink" title="Install Thanos Querier"></a>Install Thanos Querier</h2><p>Thanos Querier Layer provides the ability to retrieve metrics from all prometheus instances at once. It’s fully compatible with original prometheus PromQL and HTTP APIs so that it can be used along with Grafana.</p><p>Since there are too many yaml files, I put everything in my <a href="https://github.com/kkc/prometheus-thanos" target="_blank" rel="noopener">github repo</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> thanos</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f querier-deployment.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f querier-service.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f querier-service-monitor.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-peers-svc.yaml</span></span><br></pre></td></tr></table></figure><h2 id="Install-Thanos-Store"><a href="#Install-Thanos-Store" class="headerlink" title="Install Thanos Store"></a>Install Thanos Store</h2><p>Thanos Store collaborates with <code>querier</code> for retrieving historical data from the given bucket. It will join the Thanos cluster on setup. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-store.yaml</span></span><br></pre></td></tr></table></figure><h2 id="Install-Thanos-Compactor"><a href="#Install-Thanos-Compactor" class="headerlink" title="Install Thanos Compactor"></a>Install Thanos Compactor</h2><p>Thanos Compactor will do downsampling for your all historical data. It’s a really useful component which can reduce file size. Recommend everyone read this well explained <a href="https://improbable.io/games/blog/thanos-prometheus-at-scale" target="_blank" rel="noopener">article</a>. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-compactor.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-compactor-service.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-compactor-service-monitor.yaml</span></span><br></pre></td></tr></table></figure><h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><h2 id="Peering-service-didn’t-set-up-properly"><a href="#Peering-service-didn’t-set-up-properly" class="headerlink" title="Peering service didn’t set up properly"></a>Peering service didn’t set up properly</h2><p>you will see this kind of message of thanos component<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">level</span>=error <span class="attribute">ts</span>=2019-02-01T05:11:40.805153721Z <span class="attribute">caller</span>=cluster.go:269 <span class="attribute">component</span>=cluster <span class="attribute">msg</span>=<span class="string">"Refreshing memberlist"</span> <span class="attribute">err</span>=<span class="string">"join peers thanos-peers.monitoring.svc.cluster.local:10900 : 1 error occurred:\n\t* Failed to resolve thanos-peers.monitoring.svc.cluster.local:10900: lookup thanos-peers.monitoring.svc.cluster.local on 172.20.0.10:53: no such host\n\n"</span></span><br></pre></td></tr></table></figure></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-peers-svc.yaml</span></span><br></pre></td></tr></table></figure><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li><a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md</a></li><li><a href="https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3/" target="_blank" rel="noopener">https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3/</a></li><li><a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/alerting.md" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/alerting.md</a></li><li><a href="https://fosdem.org/2019/schedule/event/thanos_transforming_prometheus_to_a_global_scale_in_a_seven_simple_steps/attachments/slides/3178/export/events/attachments/thanos_transforming_prometheus_to_a_global_scale_in_a_seven_simple_steps/slides/3178/Thanos___Transforming_Prometheus_to_a_Global_Scale_in_a_Seven_Simple_Steps_(FOSDEM" target="_blank" rel="noopener">Thanos___Transforming_Prometheus_to_a_Global_Scale_in_a_Seven_Simple_Steps_(FOSDEM).pdf</a>.pdf)</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;Prometheus is widely adopted as a standard monitor
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://kkc.github.io/tags/Kubernetes/"/>
    
      <category term="Prometheus" scheme="http://kkc.github.io/tags/Prometheus/"/>
    
      <category term="Thanos" scheme="http://kkc.github.io/tags/Thanos/"/>
    
  </entry>
  
  <entry>
    <title>FFmpeg libav decode 筆記</title>
    <link href="http://kkc.github.io/2019/01/12/ffmpeg-libav-decode-note/"/>
    <id>http://kkc.github.io/2019/01/12/ffmpeg-libav-decode-note/</id>
    <published>2019-01-12T03:24:06.000Z</published>
    <updated>2019-01-13T10:12:38.644Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>身處在一間做 Surveillance 的公司，一定要熟悉下 FFmpeg 怎麼使用，FFmpeg 真的是蠻偉大的，應該全世界大部分需要處理影音的公司都對他不陌生，FFmpeg 是一個跨平台免費又開源的影音處理方案，採用 LGPL 或是 GPL 的 License，單純使用 ffmpeg 或是 ffprobe command 就可以做到很多加解碼轉檔等等的事情，非常的方便！</p><p>FFmpeg 也有提供 library 給開發者呼叫並且整合在自己的程式中，這篇筆記基本上記錄了下怎麼使用它來做基本的解碼，FFmpeg 包含以下幾個 lib (只列了幾個我常用的)</p><p>Libavcodec: encode/decode 的 framework 包含很多影音的加解碼器<br>Libavformat: 對 video 的封裝<br>Libswscale: 圖像縮放，顏色空間轉換</p><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>基本上這篇心得，很多來自這篇文章 <a href="https://github.com/leandromoreira/ffmpeg-libav-tutorial" target="_blank" rel="noopener">https://github.com/leandromoreira/ffmpeg-libav-tutorial</a> 的內容，非常推薦想要學 FFmpeg 的同學作為參考，算是我找過網路上寫的最平易近人的說明。而這篇文章主要會紀錄 video 相關的心得，因為我對音訊還沒那麼熟。</p><h1 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h1><p>Video 其實可以視為一堆圖片的集合，小時候都有玩過一種東西，就是一本書上面有很多圖，在快速翻動的時候，就能感覺到上面的東西在移動。</p><h1 id="Codec"><a href="#Codec" class="headerlink" title="Codec"></a>Codec</h1><p>Codec 的工作就是把資料縮小，這邊給個概念，如果我們把數以百萬計的圖片放進一個電影檔裡面，那這個檔案勢必非常的大，來做個簡單的數學：</p><p>讓我們拿個高清的影片，解析度為 1080 x 1920，然後每個 pixel 都用 3 bytes 去記錄他的顏色資訊 (24 bit color，這裡可以表達 16,777,216 不同的顏色，我們的眼睛好厲害)，這個影片是 24 fps (frame per second)，然後長度為 30 分鐘，我們做個簡單的數學計算:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">toppf = <span class="number">1080</span> * <span class="number">1920</span> <span class="comment">//total_of_pixels_per_frame</span></span><br><span class="line">cpp = <span class="number">3</span>             <span class="comment">//cost_per_pixel</span></span><br><span class="line">tis = <span class="number">30</span> * <span class="number">60</span>       <span class="comment">//time_in_seconds</span></span><br><span class="line">fps = <span class="number">24</span>            <span class="comment">//frames_per_second</span></span><br></pre></td></tr></table></figure><p>需要的儲存空間 = <code>tis * fps * toppf * cpp</code></p><p>簡單的計算後發現，這個電影檔居然要花我們 <code>250.28GB</code> 的空間，還有 <code>1.11Gpbs</code> 的流量，這也是為什麼我們需要 codec 來幫助我們壓縮檔案。</p><h1 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h1><p>Container 可以視為一個 wrapper，裡面包含了不同的 stream (通常是 video 和 audio)，然後這個 container 通常也提供了 Metadata 像是 video title , resolution 之類的資訊，</p><p>這邊加點我個人的筆記，mp4 和 mpeg4 video data，就是一種 container 和 stream 的概念，也是瓶子和內容物，mp4 這個瓶子一般來說都是裝 standard mpeg4 video codec 的資料，但是如果硬拿來裝其他的東西也可以，只是應該沒人會這樣做。</p><h1 id="FFmpeg-Libav-Architecture"><a href="#FFmpeg-Libav-Architecture" class="headerlink" title="FFmpeg Libav Architecture"></a>FFmpeg Libav Architecture</h1><p>要知道怎麼 encode/decode 得先了解下 libav 的 architecture</p><p><img src="flow.png" alt="img"></p><ol><li>讀取 media file 到 <code>AVFormatContext</code> 這個 compoenent 裡面，基本上這個動作其實只會讀取檔案的 header 而已，而經由這個 header 我們可以知道這包 container 裡面有多少 stream 。</li><li>如果我們要讀取 Container 裡面的 stream 的話，libav 會把它封裝在 <code>AVStream</code> 這個 component 內，我們就可以經由這個 component 讀取到 stream 的資料。</li><li>假設我們的 Container 裡面有兩個 stream ，一個是 video (encoded by H264 CODEC) 另外一個是 audio (encoded by AAC CODEC)，我們可以從中讀取一小段資料進 <code>AVPacket</code> 這個 Compoenent。</li><li>資料在 <code>AVPacket</code> 中還是被 <em>encode</em> 的狀態，這時候我們會需要 <code>AVCodec</code> 的幫忙，將 packet 裡面的資料 decode 出來到 <code>AVFrame</code> 中，我們就可以拿到 uncompressed frame。</li></ol><h2 id="Detailed-Decoding-Flow"><a href="#Detailed-Decoding-Flow" class="headerlink" title="Detailed Decoding Flow"></a>Detailed Decoding Flow</h2><p>主要的範例程式可以參考<a href="https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/0_hello_world.c" target="_blank" rel="noopener">hello_world.c</a>，接下來我會對其中比較重要的幾個 step 做個簡單的筆記。</p><ol><li><p>一開始要先對 <code>AVFormatContext</code> 這個結構配置記憶體，經由這個結構我們才能得到 container 的 format。</p> <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AVFormatContext *pFormatContext = avformat_alloc_context()<span class="comment">;</span></span><br></pre></td></tr></table></figure></li><li><p>接著使用 <code>avformat_open_input</code> 去將檔案讀進到我們之前配置好的 <code>AVFormatContext</code>，這個 function 最後有兩個 arguments，第一個是 <code>AVInputFormat</code>，傳入 <code>NULL</code> 他會自動猜測格式，第二個是 <code>AVDictionary</code> 通常是拿來配置 demuxer 的參數。</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">avformat_open_input(&amp;pFormatContext,</span> <span class="string">filename,</span> <span class="literal">NULL</span><span class="string">,</span> <span class="literal">NULL</span><span class="string">);</span></span><br></pre></td></tr></table></figure></li><li><p>讀進 <code>AVFormatContext</code> 後，可以印出 container 的 format 和 duration。 </p> <figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">printf</span>("Format %s, duration %lld us", pFormatContext-&gt;</span><span class="function"><span class="title">iformat</span>-&gt;</span><span class="function"><span class="title">long_name</span>, pFormatContext-&gt;</span>duration);</span><br></pre></td></tr></table></figure></li><li><p>使用 <code>avformat_find_stream_info</code> 拿來讀取 media file 裡面的 data ， 在呼叫完 <code>avformat_find_stream_info(pFormatContext,  NULL);</code> 這個方法後， 才能從 <code>pFormatContext-&gt;nb_streams</code> 裡面得到 context 有多少個 stream，接著可以用 pFormatContext-&gt;streams[i] 得到不同的 stream (<code>AVStream</code>)。</p> <figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; pFormatContext-&gt;nb_streams; i++)</span><br><span class="line">&#123;</span><br><span class="line">  /<span class="regexp">/ pFormatContext-&gt;streams[i]</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>因為每個 stream 都有可能是用不同的 codec 壓縮的，我們可以經由 <code>AVCodecParameters *pLocalCodecParameters = pFormatContext-&gt;streams[i]-&gt;codecpar;</code> 從每個 stream 中取得對應的 <code>AVCodecParameters</code></p></li><li><p>利用剛剛取得的 parameter 和 <code>avcodec_find_decoder</code> function 找到對應的 <code>AVCodec</code></p> <figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AVCodec *pCodec = avcodec_find_decoder(<span class="name">pLocalCodecParameters-&gt;codec_id</span>)<span class="comment">;</span></span><br></pre></td></tr></table></figure></li><li><p>取得 Codec 後，我們需要配置記憶體給 <code>AVCodecContext</code>，這個結構是等等要拿來 encode/decode 用的，我們另外還需要將 codec 的 parameter 也複製到這個 context 中，在我們配置好 codec 的 context 後，還需要使用 <code>avcodec_open2</code> 才能真的在之後使用這個 context。 </p> <figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">AVCodecContext *pCodecContext = avcodec_alloc_context3(<span class="name">pCodec</span>)<span class="comment">;</span></span><br><span class="line">avcodec_parameters_to_context(<span class="name">pCodecContext</span>, pCodecParameters)<span class="comment">;</span></span><br><span class="line">avcodec_open2(<span class="name">pCodecContext</span>, pCodec, NULL)<span class="comment">;</span></span><br></pre></td></tr></table></figure></li><li><p>我們需要把 packet (<code>AVPacket</code>) 從 stream 讀出來後，然後 decode 成一張張的 frame (<code>AVFrame</code>)</p> <figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置記憶體</span></span><br><span class="line">AVPacket *pPacket = av_packet_alloc<span class="comment">()</span>;</span><br><span class="line">AVFrame *pFrame = av_frame_alloc<span class="comment">()</span>;</span><br></pre></td></tr></table></figure><p> 這邊我們要使用 <code>av_read_frame</code> 這個 function 將 video_streaming 的資料從 <code>AVFormatContext</code> 中讀出來到 packet 中</p> <figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">while</span> (av_read_frame(pFormatContext, pPacket) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="selector-tag">avcodec_send_packet</span>(pCodecContext, pPacket);</span><br><span class="line">    <span class="selector-tag">avcodec_receive_frame</span>(pCodecContext, pFrame)</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 接著將 raw packet (compressed frame) 送進 decoder，然後把 raw data frame (uncompressed frame) 取出來，這兩組 API <code>avcodec_send_packet</code> &amp; <code>avcodec_receive_frame</code> 需要互相搭配使用，使用 <code>avcodec_send_packet</code> 將 packet 送到 <code>AVCodecContext</code> 中，然後透過 <code>avcodec_receive_frame</code> 將解碼後的 frame 拿出來，然後要注意一點是 <code>avcodec_send_packet</code> 和 <code>avcodec_receive_frame</code> 並不一定是一對一的關係，有時候需要多送幾個 packet 讓 <code>AVCodecContext</code> 緩存幾張 frame 的 data，而這邊拿到的 <code>pFrame-&gt;data</code> 的格式是 (YCbCr)[<a href="https://en.wikipedia.org/wiki/YCbCr]，如果想要轉成" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/YCbCr]，如果想要轉成</a> RGB 的話還需要使用到 <code>SwsContext</code> 之類的方法。</p></li><li><p>接著我們就可以印出取得的資訓像是 frame_number 或是 pts 等等印出來驗證摟</p> <figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">printf(</span><br><span class="line">    <span class="string">"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]"</span>,</span><br><span class="line">    <span class="function"><span class="title">av_get_picture_type_char</span>(pFrame-&gt;</span>pict_type),</span><br><span class="line">    <span class="function"><span class="title">pCodecContext</span>-&gt;</span>frame_number,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>pts,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>pkt_dts,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>key_frame,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>coded_picture_number,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>display_picture_number</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li></ol><p>針對 AVPacket 和 AVFrame，我另外畫了一張流程圖</p><p><img src="./flow2.png" alt="flow2"></p><h1 id="心得"><a href="# 心得" class="headerlink" title="心得"></a>心得</h1><p>ffmpeg 經過多次改版，API 和文件其實變得比較人性化一點，網路上也不像之前資料那麼少了，經由這次的練習也找到了不少有用的資料，都列在底下的 Reference 供大家參考，如果有哪邊寫錯的，還請大家指正了。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://slhck.info/ffmpeg-encoding-course/" target="_blank" rel="noopener">ffmpeg-encoding-course</a></li><li><a href="https://github.com/leandromoreira/ffmpeg-libav-tutorial" target="_blank" rel="noopener">https://github.com/leandromoreira/ffmpeg-libav-tutorial</a></li><li><a href="http://leixiaohua1020.github.io/#ffmpeg-development-examples" target="_blank" rel="noopener">http://leixiaohua1020.github.io/#ffmpeg-development-examples</a></li><li><a href="https://ffmpeg.org/doxygen/4.0/group__lavf__decoding.html#details" target="_blank" rel="noopener">https://ffmpeg.org/doxygen/4.0/group__lavf__decoding.html#details</a></li><li><a href="https://ffmpeg.org/doxygen/4.0/group__lavc__decoding.html" target="_blank" rel="noopener">https://ffmpeg.org/doxygen/4.0/group__lavc__decoding.html</a> </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;身處在一間做 Surveillance 的公司，一定要熟悉下 FFmpeg 怎麼使用，FFmpeg 
      
    
    </summary>
    
    
      <category term="ffmpeg" scheme="http://kkc.github.io/tags/ffmpeg/"/>
    
  </entry>
  
  <entry>
    <title>EKS 的一些筆記</title>
    <link href="http://kkc.github.io/2018/10/04/EKS-notes/"/>
    <id>http://kkc.github.io/2018/10/04/EKS-notes/</id>
    <published>2018-10-04T15:34:12.000Z</published>
    <updated>2018-10-04T17:10:43.182Z</updated>
    
    <content type="html"><![CDATA[<p><img src="eks.png" alt="eks"></p><h2 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h2><p> 最近大量使用了 AWS 的 EKS ，並且也 migrate 了一些 workload 到 EKS 上面，為了更深入了解 EKS 也找了些文章和影片來看，所以就有了這篇筆記。相關的影片和文章我會列在下面的 Reference。</p><h2 id="為什麼需要 -EKS"><a href="# 為什麼需要 -EKS" class="headerlink" title="為什麼需要 EKS"></a>為什麼需要 EKS</h2><p>最主要是為了改善維護及升級 k8s cluster 的困難度，一般來說，自己維護的 k8s cluster 必需要很注意 master 的穩定性，而其他痛苦的地方像是升級 kubernetes version (master node)，etcd 的升級，etcd 的備份和還原，另外還有些問題像是有些人忘了更新 certificate ，超過了過期時間後，連不進 master node 的意外。所以在沒有一定大小程度的 kubernetes operation 團隊下，其實蠻推薦大家使用 managed k8s 像是 EKS, GKE, AKS 等等的 solution ，減少其心智負擔。</p><h2 id="使用 -EKS- 的好處"><a href="# 使用 -EKS- 的好處" class="headerlink" title="使用 EKS 的好處"></a>使用 EKS 的好處</h2><ul><li>EKS master node HA</li><li>自動升級 Kubernetes 版本</li><li>整合了 IAM user &amp; IAM role w/ kubernetes RBAC，基本上可以控管每個 AWS 的 IAM user 的權限，規範 kubernetes 裡面的那些 namespace 或是 operation 可以被使用</li><li>原生使用 AWS VPC CNI 改善了 flannel 網路的效能，另外 AWS VPC flowlog 才能夠有作用，看得懂 packet 的流向</li><li>可以使用 EC2 IAM role ，解決了跟 AWS managed service 的整合問題</li><li>EKS 會自動備份監控 etcd</li><li>可以使用 Cloudtrail audit EKS API</li></ul><h2 id="一些技術細節"><a href="# 一些技術細節" class="headerlink" title="一些技術細節"></a>一些技術細節</h2><ul><li>Master node 會被啟在 AWS 自己特殊的 VPC 內，且受 AWS 控制，所以不會佔用我們的 IP 數量</li><li>Master node 和 worker node 之間用 private link 連結，走的是內部網路，所以效率上面不太需要擔心，Master node 前面有 Loadbalacer，猜想後面的 Master node 有問題或是需要 scale 的時候，使用的是 AWS 自己的 scale 方法，增加 Master node 的穩定度。</li></ul><h3 id="AWS-VPC-CNI"><a href="#AWS-VPC-CNI" class="headerlink" title="AWS VPC CNI"></a>AWS VPC CNI</h3><p><img src="cni.jpg" alt="cni"></p><p>這算是蠻重要的一環，原本的 kubernetes 的網路架構使用的是 flannel ，但是其實 packet 在流動的過程中，被轉址了很多次，而 AWS VPC CNI 就是為了解決 network performance 的問題。</p><ul><li>每個 ENI 可以有數個 IP addresses，AWS VPC CNI 會負責 collect 這些 IP 將其分配到 ENI 上面</li><li>可以從 EC2 上面看到 2nd IP 的數量會增加</li><li>一個 pod 會佔用一組 IP</li><li>每個 Instance family 可以使用的 IP 數量有限，這點需要注意，有聽到人先遇到了 IP 數量不足的問題，而不是先遇到 CPU or Mem 不足。</li></ul><h3 id="iptable- 問題"><a href="#iptable- 問題" class="headerlink" title="iptable 問題"></a>iptable 問題</h3><ul><li>處理 5000 services == 40000 rules 需要 11mins</li><li>處理 20000 services == 160000 rules == 5 hours</li></ul><p>在跑大量 service 時會有問題<br>1.11 後會有 IPVS mode，不過還是要考量一下是否要使用，基本上 iptable 的功能還是比較強大</p><h3 id="ingress"><a href="#ingress" class="headerlink" title="ingress"></a>ingress</h3><ul><li>可以使用 annotations 配置 ELB &amp; NLB</li><li>可以設定的東西有<ul><li>Draining</li><li>Logging</li><li>SSL Certs</li><li>Tagging</li><li>Security Groups</li><li>Health Checks</li></ul></li><li>ALB ingress 需要另外安裝</li></ul><h3 id="Network-policy"><a href="#Network-policy" class="headerlink" title="Network policy"></a>Network policy</h3><ul><li>pod 與 pod 之間的 network 可以使用 Calico 的 Network Policy 去配置</li></ul><h3 id="Auto-scaling"><a href="#Auto-scaling" class="headerlink" title="Auto scaling"></a>Auto scaling</h3><ul><li>最新版的 eks.2 已經有支援 Horizontal Pod Autoscaler</li><li>Worker Node scale 可以使用 Auto scaling group 來做</li><li>Master Node 由 AWS 負責</li></ul><h2 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h2><ul><li>目前只有三個 region 有支援 US west (Oregon) &amp; Virginia &amp; Ireland</li></ul><h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><ul><li><p>需要注意 security group 是否設定正確</p><ul><li>master node <-> worker node</-></li><li>worker node <-> worker node</-></li><li>LB <-> worker node</-></li><li>worker node <-> other EC2 instances or managed services</-></li></ul></li><li><p>VPC 內的 ip 數量是否足夠</p></li><li>ENI 的 ip 數量是不是已經達到上限</li><li>worker node 上面的 IAM role 的權限是否充足</li></ul><h2 id="Pricing"><a href="#Pricing" class="headerlink" title="Pricing"></a>Pricing</h2><ul><li>$0.20 per hour per cluster ($144 per month)</li><li>worker node resource 都跟 AWS 原本的價錢一樣</li></ul><h2 id="推薦的安裝方式"><a href="# 推薦的安裝方式" class="headerlink" title="推薦的安裝方式"></a>推薦的安裝方式 </h2><p> 除了使用 <a href="https://github.com/weaveworks/eksctl" target="_blank" rel="noopener">eksctl</a> 來建立 EKS 外，也可以使用 <a href="https://twitter.com/pahudnet" target="_blank" rel="noopener">Pahud</a> 大寫的 <a href="https://github.com/pahud/amazon-eks-workshop" target="_blank" rel="noopener">https://github.com/pahud/amazon-eks-workshop</a> 來創建和操作 EKS，而 Pahud 大的 workshop 還包含了許多其他的東西像是 ingress 和 HPA 的創建，非常值得大家一讀。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://aws.amazon.com/blogs/opensource/networking-foundation-eks-aws-cni-calico/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/opensource/networking-foundation-eks-aws-cni-calico/</a></li><li><a href="https://www.youtube.com/watch?v=4ClszrpJQq8&amp;t=1631s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=4ClszrpJQq8&amp;t=1631s</a></li><li><a href="https://www.slideshare.net/sriram_rajan/elastic-kubernetes-services-eks?qid=e09780e3-f5b4-478c-90fd-9b74bcf02c6d&amp;v=&amp;b=&amp;from_search=6" target="_blank" rel="noopener">https://www.slideshare.net/sriram_rajan/elastic-kubernetes-services-eks?qid=e09780e3-f5b4-478c-90fd-9b74bcf02c6d&amp;v=&amp;b=&amp;from_search=6</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;eks.png&quot; alt=&quot;eks&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h2&gt;&lt;p&gt; 最近大量使用了 AWS 的 EKS ，並且也 migrate
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="Kubernetes" scheme="http://kkc.github.io/tags/Kubernetes/"/>
    
      <category term="EKS" scheme="http://kkc.github.io/tags/EKS/"/>
    
  </entry>
  
  <entry>
    <title>記一次 AWS EKS troubleshooting 的歷程</title>
    <link href="http://kkc.github.io/2018/09/11/EKS-troubleshooting/"/>
    <id>http://kkc.github.io/2018/09/11/EKS-troubleshooting/</id>
    <published>2018-09-11T07:33:58.000Z</published>
    <updated>2018-09-28T01:36:07.952Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h1><p> 千呼萬喚下，前陣子 AWS 版本的 Kubernetes 終於 <a href="https://aws.amazon.com/blogs/aws/amazon-eks-now-generally-available/" target="_blank" rel="noopener">GA</a> 了，但其實真正玩過後，跟之前用 CoreOS 跑起來的 Kubernetes 有不少的差別，主要是因為 AWS 需要把 IAM 及 Network 部分和 Kubernetes 做整合，因為權限和網路效能其實對於服務都是很重要的，而我也是在跑過 EKS 和經歷了這個除錯的過程，才更讓我了解到在不同平台上跑 Kubernetes 的差別，尤其要把 AWS IAM &amp; RBAC 怎麼連接搞懂，還有 packet 在 AWS &amp; k8s network 中怎麼流，都是很重要的，所以可想而知，在 AWS 上面疊一層 Kubernetes ，其實對 operation 來說，整體複雜度是上升的。</p><h1 id="問題"><a href="# 問題" class="headerlink" title="問題"></a>問題 </h1><p> 一開始把玩 EKS 是照著 Pahud 大的 <a href="https://github.com/pahud/amazon-eks-workshop" target="_blank" rel="noopener">workshop</a> step by step 跑起來，而使用 eksctl 其實是很舒服的，可以直接幫你把 worker node 架好，並且把 autoscaling group 和 cloudformation 都設定好，整體來說簡化了很多步驟，所以體驗還不錯，但是公司在管理 infrastructure as code 的部分，比較希望一致使用 terraform 而不是 cloudformation。 我的問題就發生在當我用同事改寫的 terraform template 啟 EKS 時 ，一直沒辦法用 kubectl get nodes 得到 node，另外就是起好的 node (AWS instance) 上面也一直沒看到 secondary ip 出現，這跟我一開始使用 eksctl 看到的結果有落差。</p><h1 id="除錯"><a href="# 除錯" class="headerlink" title="除錯"></a>除錯 </h1><p> 因為一直無法讓 worker node 加進去 k8s cluster，感覺是個不錯的機會，可以學習 k8s 是怎麼運作的，我想到的第一步是登入機器使用 <code>journalctl -u kubelet</code> 觀看 kubelet 是否有什麼有趣的 log ，立馬就發現有 <code>Unauthorized</code> 的 Error，後來查看 <a href="https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.html" target="_blank" rel="noopener">EKS User Guide Troubleshooting</a> 的 <strong>Worker Nodes Fail to Join Cluster</strong> 的章節 ，發現少做了 <code>kubectl apply -f aws-auth-cm.yaml</code> 這步，因為 AWS 的 node 要加進 cluster 內，也是需要把 Authorization 這塊設定起來，要不然 master 不會無緣無故的讓你呼叫，而其實 ekectl 有幫忙處理這塊，但使用 terraform deploy 時，就需要手動去執行這步，才能讓這個 nodes 註冊到 cluster 上面，而這之後也是我們的 script 可以改進的部分。</p><ol><li><p>Download the configuration map:</p> <figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -O https://amazon-eks.s3-us-west<span class="string">-2</span>.amazonaws.com/cloudformation/2018<span class="string">-08</span><span class="string">-30</span>/aws-auth-cm.yaml</span><br></pre></td></tr></table></figure></li><li><p>Open the file with your favorite text editor. Replace the <code>&lt;ARN of instance role (not instance profile)&gt;</code> snippet with the NodeInstanceRole value that you recorded in the previous procedure, and save the file.<br>這邊要把 rolearn 這邊填成正確的 ec2 instance role 的 ARN，如果填錯了就可能一直連不上喔</p> <figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: aws-auth</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  mapRoles: |</span><br><span class="line">    - rolearn: &lt;ARN of<span class="built_in"> instance </span>role (not<span class="built_in"> instance </span>profile)&gt;</span><br><span class="line">      username:<span class="keyword"> system</span>:node:&#123;&#123;EC2PrivateDNSName&#125;&#125;</span><br><span class="line">      groups:</span><br><span class="line">        -<span class="keyword"> system</span>:bootstrappers</span><br><span class="line">        -<span class="keyword"> system</span>:nodes</span><br></pre></td></tr></table></figure></li><li><p>Apply the configuration. This command may take a few minutes to finish.</p> <figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">apply</span> -f aws-auth-cm.yaml</span><br></pre></td></tr></table></figure></li></ol><p>在加完 worker node 後，還是發現 pod 還是無法開始成功得到 IP，所有的 container 都處在 <code>containerCreating</code> 的狀態中，這時就有點懷疑是不是 <code>AWS-VPC-CNI</code> 的問題，因為在 EKS 架構中，每一個 pod 都會被分配到一個 IP，CNI 基本上就在負責這件事，接著在後續的搜索中找到了 AWS 在 CNI GitHub Repo 上面放了一個很不錯的 <a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/troubleshooting.md" target="_blank" rel="noopener">Troubleshooting note</a>，透過這個 note，必須要檢查下列事項，就可以慢慢釐清問題是什麼。</p><ol><li>對應的 subnet 中能使用的 IP 數量是不是足夠<ul><li>這邊也提到有可能有 Leaked ENI 的問題，就是 EC2 關閉後但是沒有把 ENI 砍掉，之前被 attach 到這張 ENI 上面的 secondary ip 就不會被釋放出來。</li></ul></li><li>確認是不是該 instance 能使用的 ENIs &amp; IPs 是否足夠</li></ol><p>基本上就是要看 ENI 能不能分配到 IP，還有該 instance 上面的 pod 數量是不是大於分配到的 IP 數量</p><p>Debug 的流程</p><ol><li><p>Check <code>/var/log/aws-routed-eni</code><br>如果能看到</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2018-09-11T07:28:11Z [<span class="builtin-name">DEBUG</span>] Start increasing<span class="built_in"> IP Pool </span>size`</span><br><span class="line">2018-09-11T07:28:11Z [<span class="builtin-name">DEBUG</span>] Skipping increase IPPOOL due <span class="keyword">to</span> max ENI already attached <span class="keyword">to</span> the<span class="built_in"> instance </span>: 3</span><br><span class="line">2018-09-11T07:28:16Z [<span class="builtin-name">DEBUG</span>]<span class="built_in"> IP pool </span>stats: total = 15, used = 9, c.currentMaxAddrsPerENI = 6, c.maxAddrsPerENI = 6</span><br></pre></td></tr></table></figure><p>就代表沒什麼問題</p></li><li><p>而我在確認 log 後發現這行 <code>[ERROR] Failed to get eni limit due to unknown instance type t3.medium</code>，後續也查到了這張 ticket <a href="https://github.com/aws/amazon-vpc-cni-k8s/pull/145" target="_blank" rel="noopener">https://github.com/aws/amazon-vpc-cni-k8s/pull/145</a>，還需要等到下個版本 release 後才能使用 t3.medium 的 instance type.</p></li><li><p>在把 instance type 改回 t2.medium 後，的確整個網路就通了，pod 也可以成功跑起來。</p></li></ol><h1 id="後記"><a href="# 後記" class="headerlink" title="後記"></a>後記 </h1><p> 各家 cloud provider 都有提供 Managed k8s 的 service，除了 GKE 外，其他家 provider 為了讓 k8s 跟自己的系統整合的更好，都多少加了一些東西上去，像是 AWS 為了整合其 IAM 和 RBAC，還有開發 CNI 整合 VPC networking 去改善原生 Flannel 的效能問題，新增加上的東西往往也變成我們的知識負擔，不過 EKS 其實也是讓我們省下很多問題，像是 k8s 版本要升級，還有 master node &amp; etcd 的管理問題，都丟給 AWS 去管理，我們不用頭痛這塊，個人覺得 Kubernetes 最需要的就是 master node 要穩定，Managed k8s service 可以幫我們很好的解決這些問題，但是我們還是要懂原本 AWS 的架構，像是 IAM, security group, VPC subnet，也要了解 k8s node 或是 pod 有問題時，要從哪個方向去找解法，像是 pod &amp; pod 之間的 networking，或是 RBAC 是不是設定有誤，導致讀不到需要的東西，就算有了 EKS，還是得去了解這些底層的東西才會讓你管起來更有信心，接下來有機會會繼續寫一下 EKS 的一些筆記。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt" target="_blank" rel="noopener">https://github.com/awslabs/amazon-eks-ami/blob/master/files/eni-max-pods.txt</a> 不同的 instance family 能用的 pod 數量上限 (跟能 attach 的 ENI &amp; IP 有關)</li><li><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI" target="_blank" rel="noopener">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#AvailableIpPerENI</a></li><li><a href="https://github.com/awslabs/amazon-eks-ami/issues/27" target="_blank" rel="noopener">https://github.com/awslabs/amazon-eks-ami/issues/27</a></li><li><a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/troubleshooting.md" target="_blank" rel="noopener">https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/troubleshooting.md</a></li></ol>]]></content>
    
    <summary type="html">
    
      AWS 的 Kubernetes 蠻多東西要學的啊（抓頭)
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="Kubernetes" scheme="http://kkc.github.io/tags/Kubernetes/"/>
    
      <category term="EKS" scheme="http://kkc.github.io/tags/EKS/"/>
    
  </entry>
  
  <entry>
    <title>Build a better client</title>
    <link href="http://kkc.github.io/2018/08/26/build-a-better-client/"/>
    <id>http://kkc.github.io/2018/08/26/build-a-better-client/</id>
    <published>2018-08-26T12:36:29.000Z</published>
    <updated>2018-09-28T01:36:07.960Z</updated>
    
    <content type="html"><![CDATA[<div style="text-align:center"><br><iframe src="//www.slideshare.net/slideshow/embed_code/key/pF9d6lGQKScGHc" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/kakashiliu/build-a-better-client-111628081" title="Build a better client" target="_blank">Build a better client</a> </strong> from <strong><a href="https://www.slideshare.net/kakashiliu" target="_blank">cc liu</a></strong> </div><br></div><h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>This is a talk I presented at the internal company meeting. It mainly addresses how could we create better client behavior for modern software architecutre. We all know that microservices becomes more and more popular nowadays. Everybody notices about the benefit of microservices that each team can do development, deployment, and service scaling independently. It also makes each component becomes more understandable and maintainable. However, decomposing an application into different services introduces the reliability problems. Because these services usually are connected to each other by the computer network instead of in the single machine, we need to be more careful to handle network errors and service errors.</p><h1 id="Fallacies-of-distributed-computing"><a href="#Fallacies-of-distributed-computing" class="headerlink" title="Fallacies of distributed computing"></a>Fallacies of distributed computing</h1><p>According to the <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing" target="_blank" rel="noopener">wiki</a>, there are 8 fallacies of distributed computing. I think everyone design a system connected by networking should get familiar with this knowledge. It’s so important to understand that the computer network is not reliable and that’s the reason why we have TCP protocol. Even though TCP does lots of thing for us, we still need to take care of the effect of these fallacies.</p><ol><li>The network is reliable.</li><li>Latency is zero.</li><li>Bandwidth is infinite.</li><li>The network is secure.</li><li>Topology doesn’t change.</li><li>There is one administrator.</li><li>Transport cost is zero.</li><li>The network is homogeneous.</li></ol><h1 id="7-resilience-policies"><a href="#7-resilience-policies" class="headerlink" title="7 resilience policies"></a>7 resilience policies</h1><p>I suggest everyone can adopt these resilience policies for improving the client-side program.<br>Actually, each policy can be a big topic, here I only provide some notes.</p><h2 id="Retry"><a href="#Retry" class="headerlink" title="Retry"></a>Retry</h2><p>Basically we use retry to overcome transient failures which might be server side errors or networking errors.<br>Here I found out the awesome <a href="http://allyouneedisbackend.com/blog/2017/09/15/how-backend-software-should-retry-on-failures/" target="_blank" rel="noopener">article</a> to address different scenarios that we should take care of.</p><ul><li>DNS error</li><li>Connection error</li><li>Timeout</li></ul><p>If it’s an application error, we can perform retrying based on following status code.</p><ul><li>503 (Service unavailable)</li><li>429 (too many requests)</li><li>408 (request timeout)</li><li>500 (Internal server error)</li></ul><p>It’s also important to know if this call is idempotent so that retrying won’t cause data duplication and other side effects.<br>In addition, if server returns 400, you should probably fix your data instead of performing the retry.</p><h2 id="Retry-Back-off-jitter"><a href="#Retry-Back-off-jitter" class="headerlink" title="Retry + Back off + jitter"></a>Retry + Back off + jitter</h2><p>Although the retry mechanism makes client become more resilient, it also can hurt the server in certain situations. Consider a server is overloading and couldn’t deal with many requests at the same time, repetitive tries will make the situation worse. Back off and jitter can help server recovery from failing.</p><p>According to this <a href="https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/" target="_blank" rel="noopener">AWS article</a>:</p><p><img src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2017/10/03/exponential-backoff-and-jitter-blog-figure-4.png" alt="backoff"></p><ol><li><p>Adding backoff can slow clients down and reduce wasteful invocations. In addition, Server loading is decreased since the calls occur less and less frequently.</p></li><li><p>Adding jitter can resolve the issue that clusters of calls come to server and make server super busy within the certain time period. Adding randomness delay between each retry can spread out the server loading spikes.</p></li></ol><p><img src="/img/2018-08/jitter.png" alt="backoff"></p><h2 id="Circuit-Breaker"><a href="#Circuit-Breaker" class="headerlink" title="Circuit Breaker"></a>Circuit Breaker</h2><p>The circuit breaker is used between the client and server. When a server doesn’t response certain requests for a while (maybe after multiple retries with given timeout), we can adopt circuit breaker to stop client to call server wastefully.</p><h2 id="Timeout"><a href="#Timeout" class="headerlink" title="Timeout"></a>Timeout</h2><p>Set up the timeout of every invocation properly can save client resources efficiently. Don’t let an invocation without timeout occupied resources forever.</p><h2 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h2><p>Use cache to reduce the frequency of calls. It not only shortens latency of invocation but also reduces server-side loading. But don’t forget. There are 2 hard problems in computer science: cache invalidation, naming things. Design a proper cache invalidation is not easy.</p><h2 id="Bulkhead-isolation"><a href="#Bulkhead-isolation" class="headerlink" title="Bulkhead isolation"></a>Bulkhead isolation</h2><p>This is an interesting policy which saperating client resources for different purposes. For example, we can use different thread pools for different services. Once one of the remote server crushed or became abnormal, it won’t affect whole client performance. There is a famous implementation in the Netflix library Hystrix, you can refer to <a href="https://stackoverflow.com/questions/30391809/what-is-bulkhead-pattern-used-by-hystrix" target="_blank" rel="noopener">https://stackoverflow.com/questions/30391809/what-is-bulkhead-pattern-used-by-hystrix</a>.</p><h2 id="Fallback"><a href="#Fallback" class="headerlink" title="Fallback"></a>Fallback</h2><p>Return reasonable responses instead of showing error messages.</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Building a better client not only enhances your reliability of client-side application but also improves the stability of whole systems. It’s worth considering to adopt these policies in your client-side program.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing</a></li><li><a href="http://allyouneedisbackend.com/blog/2017/09/15/how-backend-software-should-retry-on-failures/" target="_blank" rel="noopener">http://allyouneedisbackend.com/blog/2017/09/15/how-backend-software-should-retry-on-failures/</a></li><li><a href="https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/</a></li><li><a href="https://stackoverflow.com/questions/30391809/what-is-bulkhead-pattern-used-by-hystrix" target="_blank" rel="noopener">https://stackoverflow.com/questions/30391809/what-is-bulkhead-pattern-used-by-hystrix</a></li><li><a href="https://dzone.com/articles/performance-patterns-in-microservices-based-integr-1" target="_blank" rel="noopener">https://dzone.com/articles/performance-patterns-in-microservices-based-integr-1</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div style=&quot;text-align:center&quot;&gt;&lt;br&gt;&lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/pF9d6lGQKScGHc&quot; width=&quot;595&quot; height=&quot;485&quot; frame
      
    
    </summary>
    
    
      <category term="distributed-system" scheme="http://kkc.github.io/tags/distributed-system/"/>
    
  </entry>
  
  <entry>
    <title>記一次 Elasticsearch troubleshooting 的歷程</title>
    <link href="http://kkc.github.io/2018/08/15/lesson-learn-of-elasticsearch-outage/"/>
    <id>http://kkc.github.io/2018/08/15/lesson-learn-of-elasticsearch-outage/</id>
    <published>2018-08-15T14:57:44.000Z</published>
    <updated>2018-09-28T01:36:07.963Z</updated>
    
    <content type="html"><![CDATA[<h2 id="過程"><a href="# 過程" class="headerlink" title="過程"></a>過程 </h2><p> 前陣子又發生了 AWS Elasticsearch 的 status 變成 red 的情況，這次跟以往的情形有點不一樣，之前爆炸都是因為 disk space 不足，而後來增加了 Curator 定期清理資料後就解了，而這次發生的 outage 有點不同，也讓我想要記錄下發生的原因和解法。</p><h2 id="調查"><a href="# 調查" class="headerlink" title="調查"></a>調查 </h2><p> 在開了 Support ticket 和查詢 AWS 的 document 後，初步有了一些方向，根據文件上面寫的 A red cluster status means that at least one primary shard and its replicas are not allocated to a node，其實就是跟 shard 是不是運作正常有關係，這邊更新一些 Elasticsearch 的科普知識，Elasticsearch 的 document 其實是放在 index 裡面，而 index 會根據你設定的 shard 數量，把 document 平均分散到不同 shard 中，然後把不同的 shard 放在不同的 node 中，以求可以分散式的去請求資料，而在沒有調整過的 AWS elasticsearch 中預設的 shard 數量是 5，所以每次 create 一個新的 index 就會產生 5 個 shard，經過 AWS support 的調查，我們家的 elasticsearch 裡面共有 10654 shard (抖)，而太多的 shard 接著就造成 CPU utilization 越來越重，最後重到某個 node 存取不到後 (猜想該 node 應該是炸掉了)，某個 shard 又沒有即時產生好 replica 存在另外一個 node 上，就這樣 status red recovery 失敗。</p><h2 id="Troubleshooting- 技巧"><a href="#Troubleshooting- 技巧" class="headerlink" title="Troubleshooting 技巧"></a>Troubleshooting 技巧</h2><ol><li>使用 <code>GET /_cluster/allocation/explain</code> 可以看到 cluster 裡面哪些 assigned shard 出問題，還有原因是什麼</li><li>使用 <code>GET /_cat/indices?v</code> 可以看到哪些 index 是有問題的</li></ol><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">green  open   test1            <span class="number">30</span>h1EiMvS5uAFr2t5CEVoQ   <span class="number">5</span>   <span class="number">0</span>        <span class="number">820</span>            <span class="number">0</span>       <span class="number">14</span>mb           <span class="number">14</span>mb</span><br><span class="line">green  open   test2            sdIxs_WDT56afFGu5KPbFQ   <span class="number">1</span>   <span class="number">0</span>          <span class="number">0</span>            <span class="number">0</span>       <span class="number">233</span>b           <span class="number">233</span>b</span><br><span class="line">green  open   test3            GGRZp_TBRZuSaZpAGk2pmw   <span class="number">1</span>   <span class="number">1</span>          <span class="number">2</span>            <span class="number">0</span>     <span class="number">14.7</span>kb          <span class="number">7.3</span>kb</span><br><span class="line">red    open   test4            BJxfAErbTtu5HBjIXJV_7A   <span class="number">1</span>   <span class="number">0</span></span><br><span class="line">green  open   test5            _8C6MIXOSxCqVYicH3jsEA   <span class="number">1</span>   <span class="number">0</span>          <span class="number">7</span>            <span class="number">0</span>     <span class="number">24.3</span>kb         <span class="number">24.3</span>kb</span><br></pre></td></tr></table></figure><ol start="3"><li><code>cannot allocate because a previous copy of the primary shard existed but can no longer be found on the nodes in the cluster</code> 基本上我們家遇到這個訊息在講的就是 primary shard 跟著 node 失蹤了，如果該 node 沒有回來，而你的資料很重要，可能就要從 snapshot 裡面撈回來</li></ol><h2 id="解決方法"><a href="# 解決方法" class="headerlink" title="解決方法"></a>解決方法 </h2><p> 我們基本上爛掉的 elasticsearch 是拿來存 application log 的，所以該 index 壞掉其實不太會影響線上資料，而按照 AWS support 的教學和查詢的一些文章，我們的解法如下</p><ol><li>砍掉該壞掉的 index ，<code>curl -XDELETE &lt;cluster&gt;/&lt;index_name&gt;</code></li><li>砍掉 older/unused/smaller 的 index 減少 cluster loading</li><li>更改設定減少每個 index 的 shard 的數量</li></ol><p>其他學習到的東西</p><ol><li>根據需求，可以使用 dedicated master node 增加系統的 stability</li><li>越少的 shard 系統會越穩定，10 shards gives great performance, 100 gives good performance, 500 gives okay performance, 1000 gives bad performance and over 2000 is when the cluster begins to become unstable.</li><li>還有讓 shard 的 size 保持在 10GB~50GB 的大小，會讓 query 的 performance 比較好</li><li>以下的兩篇 reference 有講到很多其他 troubleshooting 的技巧</li></ol><p>Reference<br><a href="https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-handling-errors.html#aes-handling-errors-red-cluster-status" target="_blank" rel="noopener">https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-handling-errors.html#aes-handling-errors-red-cluster-status</a><br><a href="https://www.elastic.co/blog/red-elasticsearch-cluster-panic-no-longer" target="_blank" rel="noopener">https://www.elastic.co/blog/red-elasticsearch-cluster-panic-no-longer</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;過程&quot;&gt;&lt;a href=&quot;# 過程&quot; class=&quot;headerlink&quot; title=&quot;過程&quot;&gt;&lt;/a&gt;過程 &lt;/h2&gt;&lt;p&gt; 前陣子又發生了 AWS Elasticsearch 的 status 變成 red 的情況，這次跟以往的情形有點不一樣，之前爆炸都是因
      
    
    </summary>
    
    
      <category term="elasticsearch" scheme="http://kkc.github.io/tags/elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Compassionate code</title>
    <link href="http://kkc.github.io/2018/07/24/thoughts-on-compassionate-code/"/>
    <id>http://kkc.github.io/2018/07/24/thoughts-on-compassionate-code/</id>
    <published>2018-07-24T01:46:28.000Z</published>
    <updated>2018-09-28T01:36:07.966Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/img/2018-07/compassionate.jpg" alt="compassionate.jpg"></p><p> 這是一篇感想文，最近看完了一篇文章叫做 <a href="http://johannesbrodwall.com/2018/06/24/forget-about-clean-code-lets-embrace-compassionate-code/" target="_blank" rel="noopener">Forget Clean Code, let’s embrace Compassionate Code</a>，還有一篇相關的文章 <a href="http://blog.markpearl.co.za/Thoughts-on-Compassionate-Code" target="_blank" rel="noopener">Thoughts-on-Compassionate-Code</a>，這裡寫的是對第一篇文章的感想，然後在第二篇的文章中找到了一些相同的感觸。</p><p> 從 Johannes 寫的 embrace compassionate code 中，談到他對於 clean code 的一些衝突，他原先是 clean code 的信徒，在他早期的職涯生活中，常常加班幫同事修正那些有 bad smell 的 code，但最後發現有時候這樣做，在沒有取得 psychology safety 的情況下，反而讓工作的氣氛變得更糟，而提出了 compassionate code ，把注意力拉回到人的本身，有些人不是不想寫 clean code ，而是每個人的生活有不同的 priority，有可能是趕 project deadline 或是修改一些 legacy code 讓系統可以動，而不想花太多時間改動程式碼，然後目的也許是早點下班為了家人小孩或是其他的興趣。</p><p> 其實文章裡面有些部分，感覺是 Johannes 對於 Uncle Bob 有一些不滿，因為 Uncle Bob 對於不遵守教條的人，似乎是用不近人情的方式批評，而 Johannes 也被冠上是 against clean code 的人，這也使得這篇文章變得有點攻擊性，但文章的核心其實很簡單，Software development 應該要回歸到人的本身，而不要為了程式碼而導致很多團隊摩擦。</p><p> 我最近也在省思，怎麼樣的工作環境和文化才會讓人有 psychology safety，回歸到人後，讓每個人都可以講出心裡話，而不是在背後抱怨或是 murmur ，也許才能使得團隊變成 self-organized， 因為每個人加入團隊的原因不同，還有對於工作和品質要求也不一樣，單純讓 programmer 遵守一堆 rules，而不是透過溝通了解 為什麼，有時候真的會造成不少的摩擦 ，這些摩擦其實也變成團隊的阻力，儘管 code 變漂亮了，但是人心卻散了，讓大家不想自動自發地提出建議和改善，這才是真正的傷害了效能。</p><p> 第二篇文章中寫道，Being Non-Judgemental &amp; Discerning 也是給我當頭棒喝，有時候我也在想維持皇城內的和諧 (psychology safety) 雖然很重要，但是否就是無法提出建言了呢，然後無法去提出讓事情變好的方法，文中提到其實提出意見，可以使用更好的方式，也就是不要只是從一個 dimension 做出評論，而是用比較的方式講出不同 dimension 的差別，像是評論兩個歌手的時候，不要只用某歌手唱歌不好聽來做評論，而是從他們的唱腔，會不會作詞作曲，或是一些表演的小細節來做比較，回歸到寫程式做架構這件事情上，其實也就是需要了解對方為什麼或這樣做，也許是不熟悉或是沒經驗，也有可能是為了趕時間的 workaround，之後再去給予建言比較，覺得這樣寫可以避免什麼問題，或是幫忙開張票紀錄以後可以重構這段 code，都是比起直接批評要好上不少。</p><p> 我的想法其實也簡單，很多事情都是有價值的，好的流程，好的程式碼，好的文件，有向心力的組織，好的工作環境，不應該為了其中一項而忘了其他東西，在團隊中互相支持，互相給予回饋，建立好的溝通管道，其實跟寫好程式碼是差不多重要的事情。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/img/2018-07/compassionate.jpg&quot; alt=&quot;compassionate.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; 這是一篇感想文，最近看完了一篇文章叫做 &lt;a href=&quot;http://johannesbrodwall.com/2018/
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Gracefully Shutdown Docker Container</title>
    <link href="http://kkc.github.io/2018/06/06/gracefully-shutdown-docker-container/"/>
    <id>http://kkc.github.io/2018/06/06/gracefully-shutdown-docker-container/</id>
    <published>2018-06-06T15:26:34.000Z</published>
    <updated>2018-09-28T01:36:07.952Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I have been working on some existing projects trying to implement graceful shutdown mechanism. The initial idea is to make application invokes deconstructor of each component as soon as the application receives specific signals such as <code>SIGTERM</code> and <code>SIGINT</code>.  The idea works really well when I ran the application natively on my Macbook pro.  However, by using <code>docker stop</code> and <code>docker kill</code>, it didn’t work as expected - To receives a signal and performs the corresponding cleanup tasks.  So, what is exactly the Docker container shutdown process ?</p><h2 id="Process-behavior-in-Docker"><a href="#Process-behavior-in-Docker" class="headerlink" title="Process behavior in Docker"></a>Process behavior in Docker</h2><p>When you run a docker container, by default it has a PID namespace, which means the docker process is isolated from other processes on your host. A typical PID namespace is a tree structure, and it starts from <code>PID1</code>, which is also called <code>init</code> in the Linux system. The PID namespace has an important task to reap zombie processes. So what is the correspondent of <code>PID1</code> in the docker container? Let’s see some scenarios according to <a href="https://engineeringblog.yelp.com/2016/01/dumb-init-an-init-for-docker.html" target="_blank" rel="noopener">yelp articles</a>.</p><p>when we use <code>docker run</code>, there are 2 forms:</p><ul><li><code>RUN &lt;command&gt;</code> (<em>shell</em> form)</li><li><code>RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</code> (<em>exec</em> form)</li></ul><h3 id="Senario1-shell-form"><a href="#Senario1-shell-form" class="headerlink" title="Senario1:  shell form"></a>Senario1:  shell form</h3><ul><li>docker run  (on the host machine)<ul><li><code>/bin/bash</code> (PID1, inside container)<ul><li><code>python server.py</code> (PID2, inside container)</li></ul></li></ul></li></ul><p>This uses <code>/bin/bash</code> as PID1 and runs your program as the subprocess. There is a problem with this approach - When a signal is sent to a shell, the signal actually won’t be forwarded to subprocesses. This pretty much makes our application broken. Consider situation that there are ongoing requests come to our server, and the data processing by server is still in the memory. If server is terminated without signal notification, tons of requests may fails and processing data might not be written back to the database.</p><h3 id="Senario2-exec-form"><a href="#Senario2-exec-form" class="headerlink" title="Senario2:  exec form"></a>Senario2:  exec form</h3><ul><li>docker run  (on the host machine)<ul><li><code>python server.py</code> (PID1, inside container)</li></ul></li></ul><p>By using the exec form, we can run our program as <code>PID1</code>. This method is much better than Senario1 because we can directly handle the signal in the application. But if you use exec form to run a shell script to spawn your application, remember to use <em>exec</em> syscall to overwrite <code>/usr/bin/bash</code> otherwise it will act as senario1.</p><p>instead of</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!<span class="meta-keyword">/usr/</span>bin/bash</span><br><span class="line">python <span class="meta-keyword">/app/</span>server.app</span><br></pre></td></tr></table></figure><p>do</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!<span class="meta-keyword">/usr/</span>bin/bash</span><br><span class="line">exec python <span class="meta-keyword">/app/</span>server.app</span><br></pre></td></tr></table></figure><p>Using exec form seems pretty good to us, but it leads to another problem, which is zombie process handling. Although the best practice is to create the program properly without generating zombie process. I often see zombie process generated in a program. It’s really hard to detect zombies process because zombies process may be generated by other frameworks or libraries. I need to mention In senario1, <code>/bin/bash</code> can handle repeating zombie process. So inevitably, we need to think if there are other better solutions.</p><h2 id="Tini-for-the-rescue"><a href="#Tini-for-the-rescue" class="headerlink" title="Tini for the rescue"></a>Tini for the rescue</h2><p><a href="https://github.com/krallin/tini" target="_blank" rel="noopener">https://github.com/krallin/tini</a> is a special project aiming to tackle this problem. According to README file, benefics of Using Tini are:</p><ul><li>It protects you from software that accidentally creates zombie processes, which can (over time!) starve your entire system for PIDs (and make it unusable).</li><li>It ensures that the <em>default signal handlers</em> work for the software you run in your Docker image. For example, with Tini, <code>SIGTERM</code> properly terminates your process even if you didn’t explicitly install a signal handler for it.</li></ul><p>We can simply run <code>tini</code> as PID1 and it will forward the signal for subprocesses. Typically, tini is a signal proxy and it also can deal with zombie process issue automatically. After <em>Docker 1.13</em>  or greater version, you can run your program with tini by passing <code>--init</code> flag to <code>docker run</code> .</p><p>Worth to mention that the other similar project is dump-init by Yelp. A python package that can be installed from Pypi.</p><h2 id="Gracefully-Shutdown"><a href="#Gracefully-Shutdown" class="headerlink" title="Gracefully Shutdown"></a>Gracefully Shutdown</h2><p>Let us take a look at 2 docker command related to shutdown container</p><h3 id="docker-stop"><a href="#docker-stop" class="headerlink" title="docker stop"></a>docker stop</h3><p>when we use <code>docker stop</code>, docker will wait for 10s for stopping container before killing a process (by default). The main process inside the container will receive <code>SIGTERM</code>, then docker daemon will wait for 10s and send <code>SIGKILL</code> to terminate process.</p><h3 id="docker-kill"><a href="#docker-kill" class="headerlink" title="docker kill"></a>docker kill</h3><p>kill running containers immediately. it’s more like <code>kill -9</code> and <code>kill --SIGKILL</code>.</p><p><code>docker stop</code> is what we rather use. It makes container perform a cleanup task after receiving <code>SIGTERM</code> signal.</p><h3 id="shutdownTimeout-and-stopTimeout"><a href="#shutdownTimeout-and-stopTimeout" class="headerlink" title="shutdownTimeout and stopTimeout"></a>shutdownTimeout and stopTimeout</h3><p>Knowing timeout is also important for us to implement gracefully shutdown. We need to set up a reasonable timeout for containers to clean up the task. The default time can be configured both on daemon and per containers.</p><p><code>shutdownTimeout</code> : docker deamon</p><p><code>stopTimeout</code>: docker container</p><p>When docker daemon receives <code>SIGTERM</code> , it will send the <code>SIGTERM</code> to all containers. The longest timeout will be applied.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul><li>Use exec form to run your program</li><li>Use exec in your shell script</li><li>Realize what’s PID1 in your docker container</li><li>Set up a reasonable timeout of docker daemon config</li><li>Leverage <code>docker run --init</code></li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/" target="_blank" rel="noopener">https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/</a><br><a href="https://engineeringblog.yelp.com/2016/01/dumb-init-an-init-for-docker.html" target="_blank" rel="noopener">https://engineeringblog.yelp.com/2016/01/dumb-init-an-init-for-docker.html</a><br><a href="https://hynek.me/articles/docker-signals/" target="_blank" rel="noopener">https://hynek.me/articles/docker-signals/</a><br><a href="https://github.com/moby/moby/pull/34992/files" target="_blank" rel="noopener">https://github.com/moby/moby/pull/34992/files</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Recently, I have been working on some existing projects trying to implement graceful shutdown mechanism. The initial idea is to make appl
      
    
    </summary>
    
    
      <category term="docker" scheme="http://kkc.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>用 docker 改善開發流程筆記</title>
    <link href="http://kkc.github.io/2018/04/28/docker-note/"/>
    <id>http://kkc.github.io/2018/04/28/docker-note/</id>
    <published>2018-04-27T16:05:18.000Z</published>
    <updated>2018-09-28T01:36:07.953Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h1><p> 在接觸 docker 的這三年中，從一開始的好奇和迷惘，到後來接受並享受了它的好處，途中經歷了一些不為人知的小困難，最近想寫這篇文慢慢回味並且分享一下我的 docker 學習心得，又因為我在 development + operation 方面的工作都有涉獵，更讓我對使用 docker 有不同的體會。</p><p>加入目前的公司 <a href="https://umbocv.ai/" target="_blank" rel="noopener">Umbo CV</a> 兩年多來，對於裡面的大小夥伴們能夠一起接受並學習 docker 作為開發環境，並且部署到 production 系統，現在回想起來，著實讓人感到興奮，畢竟在當時，使用 docker 並且跑在 production 上面的公司，少之又少，即使到了現在，也是有些公司尚未 dockerize 他們重要的 components，而我們在當時就毅然決然的全面採用 docker，真的是一項不錯的投資。</p><h1 id="Docker- 解決了什麼呢"><a href="#Docker- 解決了什麼呢" class="headerlink" title="Docker 解決了什麼呢?"></a>Docker 解決了什麼呢?</h1><p>這個問題讓我回想到大學時期當網管的時候，那時有一個很重要的任務，叫做電腦教室系統還原，印象深刻的是，我採用的高科技玩意叫做 Ghost，而把硬碟 mirror 後就會產生一個文件，我們稱它為映像檔 (image)，最棒的地方在於，不管你在哪台電腦上面用這個 image 做還原，他就會跟原本的製作的環境一模一樣，這帶來的好處很明顯，就是我們只要透過網路，而不需要一台一台電腦用磁片重新安裝就能使他們回復到一樣的狀態。</p><p>回過頭來講到執行環境，不管對於使用者或是開發者來說，都是一個很困擾的問題，同樣的程式在不同的 OS, libarary 下面執行，總是會有不同的執行結果和產生不同的臭蟲。舉個例子，在我的大學期末專題中，常常遇到不同人開發的程式，在其他人的電腦上面執行不了的問題，最慘的就是沒辦法在助教的電腦上面執行，而在當時筆記型電腦不盛行的時代，還需要人肉到助教的實驗室，借用電腦把程式修好。</p><p>再來到了雲端時代，在 AWS/Azure/GCP 上面有很方便的方法，幫忙你把既有的 VM 打成 image，可以很快地在不同的 instance type 上面做還原，然後個人電腦也有像是 virtualbox, vmware 加上 vagrant 去模擬不同的環境，打包好的 image 還有 config 也可以跟其他人互通有無，其實已經比以前方便非常多了!</p><p>而 docker 的橫空出世又是一個非常重要的里程碑，傳統的 VM solution 雖然是好棒棒，但是速度和體積來說真的是太大太肥，而開機的時間不管再怎麼壓縮，最快還是需要個 3~5 分鐘，當然這是相對 docker 而言，要不然 VM 已經是稱霸了好一陣子。 另外 docker 的出現真的是消弭了 development 和 operation 之間的環境差距，就像之前講的 developer 的環境有可能是自己安裝，或是使用 virtualbox 之類的工具，然後用 bash script/Makefile 或是寫進 Readme 文件裡面紀錄怎麼安裝，而負責 operation 的人也必須要花時間，看能不能成功裝在 AWS/Azure/GCP 這些 cloud provider 的 VM 上，這些工作常常需要耐心和時間，也常常因為版本的不同，導致 program 有不一樣的 behavior。</p><p><img src="/img/2018-04/say-it-works-on-my-computer-one-more-time.jpg" alt="say-it-works-on-my-computer-one-more-time.jpg"></p><h1 id="Docker-vs-VM"><a href="#Docker-vs-VM" class="headerlink" title="Docker vs VM"></a>Docker vs VM</h1><p><img src="/img/2018-04/docker.png" alt="docker.png"></p><p>這張圖來自 docker <a href="https://docs.docker.com/v17.09/get-started/" target="_blank" rel="noopener">官網</a>，基本上 Docker 會比 VM 輕量的原因就是因為少了一層 Guest OS，尤其在跑很多的 docker container 時，就少了 N 層的 Guest OS。</p><h1 id="Basic-Terminology"><a href="#Basic-Terminology" class="headerlink" title="Basic Terminology"></a>Basic Terminology</h1><p>首先先看一下這張來自 docker 官網的圖，簡單闡述了 docker components 之間的關係。</p><p><img src="img/2018-04/image-20180425223501866.png" alt="structure"></p><ul><li>Imgaes: 是一個 read-only 的 template，其中包含了需要的 library &amp; application，而當 containers 被執行起來的時候，這些 read-only 的 layers 會被共用。</li><li>Container: 可以視為從 image 產生出來的 instance，而每個容器都有自己的 lifecycle，從出生到死亡每個 container 之間是互相隔離的。而有趣的是 image 是 read-only 的，但是 container 卻會在上面多加一層 writalbe 的 layer。</li><li>Registry: 擺放 docker image 的倉庫。</li><li>Dockerfile: 用來記錄構建 image 的 instructions。 (上面這張圖沒畫出來)</li></ul><h2 id="基本指令"><a href="# 基本指令" class="headerlink" title="基本指令"></a>基本指令 </h2><p> 這邊只會做個簡單紀錄，很多網路上的文章都有詳細介紹惹！</p><ol><li>建構 docker image: <code>docker build --tag hello -f Dockerfile .</code></li><li>列出 docker images: <code>docker images</code></li><li>利用 docker image 去產生 <code>docker container: docker run hello</code></li><li>將 image 推到 docker registry: <code>docker push hello</code></li><li>將 image 從 docker registry 下載: <code>docker pull hello</code></li></ol><h1 id="建構 -docker-image-w-Dockerfile"><a href="# 建構 -docker-image-w-Dockerfile" class="headerlink" title="建構 docker image w/ Dockerfile"></a>建構 docker image w/ Dockerfile</h1><p>dockerfile 是拿來建構 image 的 file，而最基本的 Dockerfile 可以寫成下面這樣</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> busybox</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> /hello /</span></span><br><span class="line"><span class="bash">RUN cat /hello</span></span><br></pre></td></tr></table></figure><p>然後使用指令 <code>docker build -t hello:v1 -f Dockerfile .</code> 來建構我們的 image</p><h2 id="build-context"><a href="#build-context" class="headerlink" title="build context"></a>build context</h2><p>build context 的概念也是需要知道的一件事，會加速我們建構 docker image 的時間，而 context 可以是本地端的目錄或是遠端的 URL，而 docker 在 build stage 時，其實是把 context 傳進 docker daemon，然後透過 docker daemon 來 build image，而上面的指令可以視為 <code>docker build -t hello:v1 -f Dockerfile context</code>。</p><p>我們可以使用 <code>.dockerignore</code> 去定義哪些檔案不需要傳入 docker daemon，基本上在 build 時，會看到一個訊息像是 <code>Sending build context to Docker daemon  142.5MB</code> 就可以知道 build context 有多大。</p><h2 id="multistage-build"><a href="#multistage-build" class="headerlink" title="multistage build"></a>multistage build</h2><p>在 Docker 17.05 後，就可以使用 multistage build 去減少 docker image 的大小，以往我們因為要建構不同需求的 image 需要準備不同的 Dockerfile，像是</p><ul><li>有安裝 Build tool chain 的 docker image</li><li><p>專門跑 production application 的 image</p>  <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ---- Build ----</span></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">3</span> as build</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> requirements.txt .</span></span><br><span class="line"><span class="bash">RUN pip install -r requirements.txt</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="bash"><span class="comment">#---- Test ----</span></span></span><br><span class="line"><span class="bash"><span class="comment">## run test</span></span></span><br><span class="line"><span class="bash">FROM build as <span class="built_in">test</span></span></span><br><span class="line"><span class="bash">RUN pip install pylint &amp;&amp; \</span></span><br><span class="line"><span class="bash">    pip install pytest</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="bash"><span class="comment">#---- Release ----</span></span></span><br><span class="line"><span class="bash">FROM python:3-alpine</span></span><br><span class="line"><span class="bash">COPY --from=build /root/.cache /root/.cache</span></span><br><span class="line"><span class="bash">COPY --from=build requirements.txt .</span></span><br><span class="line"><span class="bash">RUN pip install -r requirements.txt &amp;&amp; rm -rf /root/.cache</span></span><br></pre></td></tr></table></figure></li></ul><p>而有了 multi-stage build 就可以利用一個 Dockerfile build 出不同 stage 的 image，例如</p><p><code>docker build --target build -t builder-stage -f Dockerfile .</code><br><code>docker build --target test -t test -f Dockerfile .</code><br><code>docker build -t release -f Dockerfile .</code></p><p>然後可以看到最後要 release 的版本，我們是利用 alpine，足足可以省下好幾百 mb 的空間。</p><h2 id="Optimization-amp-amp-Debugging-skill"><a href="#Optimization-amp-amp-Debugging-skill" class="headerlink" title="Optimization &amp;&amp; Debugging skill"></a>Optimization &amp;&amp; Debugging skill</h2><p>docker image 最佳化的部分，不免是減少 layer，將一些垃圾砍掉，但是有了 multistage build 之後，其實改善的空間更大，而很多其實參考 <a href="https://docs.docker.com/v17.09/engine/userguide/eng-image/dockerfile_best-practices/" target="_blank" rel="noopener"> 官網文件 </a> 也有寫到。</p><p>Debugging skill 的部分，我想很值得一提，以往我們常常在 build image 的時候，可能會有一些 package conflict 或是有些 library 裝不起來，但是一直使用 docker build 試誤也是很煩人的事情，舉個例子，如果上面的那個範例不小心打成</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#---- Test ----</span></span><br><span class="line"><span class="comment">## run test</span></span><br><span class="line"><span class="keyword">FROM</span> build as test</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pip install pylint</span></span><br><span class="line"><span class="bash">    pip install pytest</span></span><br></pre></td></tr></table></figure><p>少了 &amp;&amp; \ 會看到下列錯誤訊息</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Sending build context to Docker daemon   2.56kB</span><br><span class="line">Step 1/10 : FROM python:3 as build</span><br><span class="line"> <span class="comment">---&gt; 6bf7a4fa2d45</span></span><br><span class="line">Step 2/10 : LABEL builder=true</span><br><span class="line"> <span class="comment">---&gt; Using cache</span></span><br><span class="line"> <span class="comment">---&gt; 472d4ae6ffaa</span></span><br><span class="line">Step 3/10 : COPY requirements.txt .</span><br><span class="line"> <span class="comment">---&gt; Using cache</span></span><br><span class="line"> <span class="comment">---&gt; ba0558adfb4d</span></span><br><span class="line">Step 4/10 : RUN pip <span class="keyword">install</span> -r requirements.txt</span><br><span class="line"> <span class="comment">---&gt; Using cache</span></span><br><span class="line"> <span class="comment">---&gt; 9b432c1c82e4</span></span><br><span class="line">Step <span class="number">5</span>/<span class="number">10</span> : <span class="keyword">FROM</span> <span class="keyword">build</span> <span class="keyword">as</span> <span class="keyword">test</span></span><br><span class="line"> <span class="comment">---&gt; 9b432c1c82e4</span></span><br><span class="line">Step <span class="number">6</span>/<span class="number">10</span> : RUN pip <span class="keyword">install</span> pylint      pip <span class="keyword">install</span> pytest</span><br><span class="line"> <span class="comment">---&gt; Running in 01fde55c23d9</span></span><br><span class="line">Collecting pylint</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/<span class="number">8</span>b/<span class="number">62</span>/b2c07085dd7bb4b7e8bb813873421692c1157191e87234550a1c39dff232/pylint<span class="number">-1.8</span><span class="number">.4</span>-py2.py3-<span class="keyword">none</span>-any.whl (<span class="number">690</span>kB)</span><br><span class="line">Requirement already satisfied: pip <span class="keyword">in</span> /usr/<span class="keyword">local</span>/lib/python3<span class="number">.6</span>/site-packages (<span class="number">10.0</span><span class="number">.1</span>)</span><br><span class="line">Collecting <span class="keyword">install</span></span><br><span class="line">  Could <span class="keyword">not</span> find a <span class="keyword">version</span> that satisfies the requirement <span class="keyword">install</span> (<span class="keyword">from</span> <span class="keyword">versions</span>: )</span><br><span class="line"><span class="keyword">No</span> matching distribution <span class="keyword">found</span> <span class="keyword">for</span> <span class="keyword">install</span></span><br><span class="line">The command <span class="string">'/bin/sh -c pip install pylint      pip install pytest'</span> returned a non-zero code: <span class="number">1</span></span><br></pre></td></tr></table></figure><p>這時候其實可以使用指令 <code>docker run -ti --rm 9b432c1c82e4 bash</code> 登入 intermediate layer 來 debug，這個技巧在實務上面蠻需要的。</p><h1 id="Development-environment-revolution"><a href="#Development-environment-revolution" class="headerlink" title="Development environment revolution"></a>Development environment revolution</h1><p>重朔 Development environment ，我認為是 docker 對 developer 來說最大的改變，就如我之前講的 developer 寫好的 code ，常常離實際的 production 環境有段距離，更別說現在有些採用 microservice 架構的應用，更是難以在本機建構一模一樣的環境做測試，以下會介紹一下我們 project 的 layout，加上如何採用 docker 來建構開發環境。</p><p>以下是 project layout，可以看到我們會擺放 <code>Dockerfile</code>，還有會放一個 <code>enter_dev_env.sh</code> 的 bash script 以供 developer 快速啟動 docker 的開發環境。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── README.md</span><br><span class="line">├── app</span><br><span class="line">│   └── main.py</span><br><span class="line">├── enter_dev_env.sh</span><br><span class="line">└── requirements.txt</span><br></pre></td></tr></table></figure><p>enter_dev_env.sh 的內容</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash -xe</span></span><br><span class="line"><span class="attribute">CONTAINER</span>=<span class="string">"<span class="variable">$&#123;USER&#125;</span>_application_container"</span></span><br><span class="line"><span class="attribute">START_SHELL</span>=<span class="string">"/bin/bash"</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">BASE_IMAGE</span>=python:3.6-slim</span><br><span class="line"></span><br><span class="line"><span class="comment"># test if the container is running</span></span><br><span class="line"><span class="attribute">HASH</span>=`docker ps -q -f <span class="attribute">name</span>=<span class="variable">$CONTAINER</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment"># test if the container is stopped</span></span><br><span class="line"><span class="attribute">HASH_STOPPED</span>=`docker ps -qa -f <span class="attribute">name</span>=<span class="variable">$CONTAINER</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [-n <span class="string">"<span class="variable">$HASH</span>"</span> ];then</span><br><span class="line">    echo <span class="string">"founding existing running container <span class="variable">$CONTAINER</span>, proceed to exec another shell"</span></span><br><span class="line">    docker exec -it <span class="variable">$HASH</span> <span class="variable">$START_SHELL</span></span><br><span class="line">elif [-n <span class="string">"<span class="variable">$HASH_STOPPED</span>"</span> ];then</span><br><span class="line">    echo <span class="string">"founding existing stopped container <span class="variable">$CONTAINER</span>, proceed to start"</span></span><br><span class="line">    docker start --attach -i <span class="variable">$HASH_STOPPED</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    echo <span class="string">"existing container not found, createing a new one, named <span class="variable">$CONTAINER</span>"</span></span><br><span class="line">    docker pull <span class="variable">$BASE_IMAGE</span></span><br><span class="line">    docker <span class="builtin-name">run</span> <span class="attribute">--name</span>=<span class="variable">$CONTAINER</span> <span class="attribute">--hostname</span>=<span class="variable">$CONTAINER</span> -ti \</span><br><span class="line">        -v ~/.aws:/root/.aws:ro -v ~/.ssh:/root/.ssh:ro \</span><br><span class="line">        -v <span class="variable">$PWD</span>:/app -w /app <span class="attribute">--entrypoint</span>=<span class="variable">$START_SHELL</span> <span class="variable">$BASE_IMAGE</span></span><br><span class="line">fi</span><br><span class="line">echo <span class="string">"see you, use'docker rm <span class="variable">$CONTAINER</span>'to kill the vm if you want a fresh env next time"</span></span><br></pre></td></tr></table></figure><p>通過這個 file 可以讓全部的開發者，擁有一樣的開發環境，也可以自行修改 <code>$BASE_IMAGE</code> 使用不同的版本和自己建構的 base image，也可以中途離開 container 後，使用同樣這個 script 在登入，接著接續上次的工作。然後</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run --name=<span class="variable">$CONTAINER</span> --hostname=<span class="variable">$CONTAINER</span> -ti \</span><br><span class="line">        -v ~/<span class="selector-class">.aws</span>:/root/<span class="selector-class">.aws</span>:ro -v ~/<span class="selector-class">.ssh</span>:/root/<span class="selector-class">.ssh</span>:ro \</span><br><span class="line">        -v <span class="variable">$PWD</span>:/app -w /app --entrypoint=<span class="variable">$START_SHELL</span> <span class="variable">$BASE_IMAGE</span></span><br></pre></td></tr></table></figure><p>這段是將 base image 跑起來的指令，這邊大家可以自行調整，除了 application 的目錄外，我還習慣把 aws &amp; ssh key 給掛進去以方便開發。</p><h1 id="待續"><a href="# 待續" class="headerlink" title="待續"></a>待續 </h1><p> 這篇文章打到這邊也有點手軟惹，接下來如果有機會，想要把如何使用 docker-compose 做 integration test ，還有搭配 Jenkinsfile 的部署流程分享一下。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h1&gt;&lt;p&gt; 在接觸 docker 的這三年中，從一開始的好奇和迷惘，到後來接受並享受了它的好處，途中經歷了一些不為人知的小困難，最近想寫這篇文慢慢
      
    
    </summary>
    
    
      <category term="docker" scheme="http://kkc.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>IPSec 筆記</title>
    <link href="http://kkc.github.io/2018/03/21/IPSEC-note/"/>
    <id>http://kkc.github.io/2018/03/21/IPSEC-note/</id>
    <published>2018-03-21T12:49:34.000Z</published>
    <updated>2018-09-28T01:36:07.962Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h1><p> 這篇筆記是用來記錄 IPSec protocal 的一些細節，前陣子在架設 AWS VPN 的時候，遇到了一些小問題，主要還是防火牆擋到需要走的 port ，而當時就在想自己對於 IPSec protocal 也太不熟悉了，所以才有這篇文章來稍微紀錄一下。</p><h1 id="為什麼需要 -IPSec"><a href="# 為什麼需要 -IPSec" class="headerlink" title="為什麼需要 IPSec"></a>為什麼需要 IPSec</h1><p>IP is not secure，我想這點學過計算機網路的同學應該都會知道這點，而有可能受到以下的風險</p><ul><li><a href="https://en.wikipedia.org/wiki/IP_address_spoofing" target="_blank" rel="noopener">source spoofing</a></li><li><a href="https://en.wikipedia.org/wiki/Replay_attack" target="_blank" rel="noopener">replay packets</a></li><li>data integrity (資料受到竄改)</li></ul><p>基本上使用 VPN 走 IPSec protocal 可以確保 CIA (似乎跟資安有關的都會提到這三個詞）</p><ul><li>Confidentiality: 利用演算法將資料加密 (DES, 3DES, AES &amp; Blowfish)</li><li>Integrity: 資料完整性，利用 hashing algorithm 保證資料沒有受到竄改</li><li>Authentication: 認證</li></ul><h1 id="IPSec-security-architecture"><a href="#IPSec-security-architecture" class="headerlink" title="IPSec security architecture"></a>IPSec security architecture</h1><ul><li>使用 <code>Layer3 Network layer</code> 這層</li><li>Application 層的大家可以無感的享受其 CIA 的好處</li><li>Components<ul><li>Authentication Header (AH)</li><li>Encapsulation Security Payload (ESP)</li><li>Security Associations (SA)</li></ul></li></ul><p>基本上我覺得要懂 IPSec，可以先來弄懂 AH &amp; ESP 會比較重要，因為這兩個東西有對 IP packet 動手腳</p><h2 id="Authentication-Header"><a href="#Authentication-Header" class="headerlink" title="Authentication Header"></a>Authentication Header</h2><p>AH 主要提供的是驗證 Data integrity &amp; data origin source，然後沒有提供任何 <em> 加密 </em> 的功能，使用 HMAC 算法，把 payload &amp; header 和 IKE 定義好的 key 一起拿來 hash，但這邊要小心因為 NAT 會改變 header，而被改變的話，另外一邊就沒辦法解析正確，所以基本上 AH 應該是不可能跟 NAT 共存。<br>而其中又分為 Transport mode &amp; Tunnel mode，後面會有介紹有什麼不同。<br>AH 使用 port 51。</p><p><img src="/img/2018-03/AH.png" alt="AH.png"></p><h2 id="Encapsulation-Security-Payload"><a href="#Encapsulation-Security-Payload" class="headerlink" title="Encapsulation Security Payload"></a>Encapsulation Security Payload</h2><p>ESP 的功能比起 AH 強大了許多，confidentiality, authentication, integrity 都包含在其中了，所以真正有提供加密的功能，而在驗證 Data integrity 方面，還是要看是使用 Transport mode 或是 Tunnel mode</p><ul><li>Transport mode: ESP 沒有對 IP header 做 hash ，所以只能保證 Data 是沒有被修改的</li><li>Tunnel mode: 有將 IP header 包進來，所以這點跟 AH 是一致的</li></ul><p>對照下圖可以發現，ESP 和 AH 最大的差別應該是 AH 會對於 Outer IP header 做驗證，所以其實 IPSec 唯有使用 ESP tunnel mode 才能和 NAT 共存。<br>而在 <a href="https://tools.ietf.org/html/rfc3948" target="_blank" rel="noopener">RFC 3948</a> 裡面也有寫道: <code>Because the protection of the outer IP addresses in IPsec AH is inherently incompatible with NAT, the IPsec AH was left out of the scope of this protocol specification.</code> 證實我們的推論應該是無誤的，難怪 AWS 的 NAT 教學裡面都是用 ESP 來做連線啊 QQ。<br>ESP 使用 port 50。</p><p><img src="/img/2018-03/ESP.png" alt="ESP.png"></p><h2 id="Transport-mode-amp-Tunnel-mode"><a href="#Transport-mode-amp-Tunnel-mode" class="headerlink" title="Transport mode &amp; Tunnel mode"></a>Transport mode &amp; Tunnel mode</h2><p>Transport mode: 通常是直接建立在兩台主機上，因為不需要再多加一個 IP header ，整體來說較省頻寬，在這個模式下，兩邊的主機都要安裝 IPSec 的 protocal，而且不能隱藏主機的 IP 位置。<br>Tunnel mode: 針對 Firewall 或是 Gateway proxy，一般來說我們會用這個模式，因為他們不是原本的發送收端。</p><h2 id="Security-Associations"><a href="#Security-Associations" class="headerlink" title="Security Associations"></a>Security Associations</h2><p>IPsec 中最重要的其實是 SA，因為它定義了如何協商，還有要使用哪些 Policy 和參數</p><ol><li>Authentication method</li><li>Encryption algorithm &amp; hashing algorithm</li><li>Life time of SA</li><li>Sequence number (避免 replay 攻擊)</li></ol><p>而基本上 SA 是單向的，所以通常要建立兩條 SA (from A to B and B to A)，然後這些 parameter 會經過 Internet Key Exchange (IKE) protocal 來決定，IKE 主要有分兩個 step</p><p>IKE phase1: 主要做 Authenticate，Authentication 方面常常使用的都是 pre-shared key，基本上就是用同一組密碼，接著透過 Diffie-Hellman 來建立一組 Key，而這組 Key 是要被 Phase2 拿來用的。<br>IKE phase2: 處理 IPsec security 協商，最後 IPSec SA 完成，接下來才會建立 IPSec 的連線。</p><p>** IKE 主要走 port 500</p><h2 id="結論"><a href="# 結論" class="headerlink" title="結論"></a>結論 </h2><p> 這只是一篇小小的筆記，而網路上面有更多詳細的資料，但有了這些基本概念後，對於為什麼 VPN 打不通，會有更多除錯的方法，像是那些 port 是不是沒開，或是 SA 整個設定錯誤，導致雙方協商失敗等等，會讓我們更有方向。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://chunchaichang.blogspot.tw/2011/12/ipsec-nat-t.html" target="_blank" rel="noopener">http://chunchaichang.blogspot.tw/2011/12/ipsec-nat-t.html</a></li><li><a href="https://www.jannet.hk/zh-Hant/post/internet-protocol-security-ipsec/" target="_blank" rel="noopener">https://www.jannet.hk/zh-Hant/post/internet-protocol-security-ipsec/</a></li><li><a href="https://en.wikipedia.org/wiki/IPsec#Security_association" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/IPsec#Security_association</a></li><li><a href="https://tools.ietf.org/html/rfc3948" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc3948</a></li><li><a href="http://www.deepsh.it/networking/IPSec.html" target="_blank" rel="noopener">http://www.deepsh.it/networking/IPSec.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h1&gt;&lt;p&gt; 這篇筆記是用來記錄 IPSec protocal 的一些細節，前陣子在架設 AWS VPN 的時候，遇到了一些小問題，主要還是防火牆擋
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>AWS VPN with RouterBoard</title>
    <link href="http://kkc.github.io/2018/03/14/AWS-VPN-with-RouterBoard/"/>
    <id>http://kkc.github.io/2018/03/14/AWS-VPN-with-RouterBoard/</id>
    <published>2018-03-14T08:37:16.000Z</published>
    <updated>2018-09-28T01:36:07.967Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>This post is used to note down how to setup Managed VPN connection between office to AWS by using Mikrotik RouterBoard. We basically follow instructions of <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html" target="_blank" rel="noopener">this document</a> and it litterally describes everything we need to know. AWS supports Internet Protocol security (IPsec) VPN connections. Following figure shows the architecture of VPN connection.</p><p><img src="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/images/VPN_Basic_Diagram.png" alt="VPN_Basic_Diagram.png"></p><h1 id="Components-of-VPN"><a href="#Components-of-VPN" class="headerlink" title="Components of VPN"></a>Components of VPN</h1><h2 id="Virtual-Private-Gateway"><a href="#Virtual-Private-Gateway" class="headerlink" title="Virtual Private Gateway"></a>Virtual Private Gateway</h2><p>A virtual private gateway is the VPN concentrator on the Amazon side of the VPN connection. We can specify the Autonomous System Number (ASN) for the Amazon side of the gateway.</p><h2 id="Customer-Gateway"><a href="#Customer-Gateway" class="headerlink" title="Customer Gateway"></a>Customer Gateway</h2><p>A customer gateway should be a device or software VPN on our side for VPN connection.</p><p>we should define following items</p><ul><li>Internet-routable IP address: Our side public IP address</li><li>The type of routing: static or dynamic</li></ul><p>One thing we need to know is that VPN connection is initiated by our side.</p><h2 id="AWS-Managed-VPN"><a href="#AWS-Managed-VPN" class="headerlink" title="AWS Managed VPN"></a>AWS Managed VPN</h2><p>By using AWS managed VPN, we can have several benefits.</p><ul><li>Fully managed by AWS, and AWS also provides HA for us. we no longer need to worry about VPN disconnection issues while zone down.</li><li>IPSec site-to-site tunnel with AES-256, SHA-2.</li></ul><h1 id="Our-Settings"><a href="#Our-Settings" class="headerlink" title="Our Settings"></a>Our Settings</h1><p>In this article, we will try to use BGP routing connecting with AWS managed VPN.</p><p><img src="/img/2018-03/bgp-routing.png" alt="bgp_routing"></p><h2 id="In-AWS-side"><a href="#In-AWS-side" class="headerlink" title="In AWS side:"></a>In AWS side:</h2><ol><li>Open the Amazon VPC console at <a href="https://console.aws.amazon.com/vpc/" target="_blank" rel="noopener">https://console.aws.amazon.com/vpc/</a>.</li><li>Choose Virtual Private Gateways, Create Virtual Private Gateway and create a virtual private gateway.<ul><li>attach VPC that you wanna connect to</li></ul></li><li>Create a Customer Gateway</li><li>choose <strong>VPN Connections, Create VPN Connection.</strong><ul><li>specify Virtual Private Gateway and Customer Gateway</li><li>Routing Options → BGP</li></ul></li><li>Route Tables → <strong>Route Propagation</strong></li></ol><h2 id="In-Customer-Network"><a href="#In-Customer-Network" class="headerlink" title="In Customer Network:"></a>In Customer Network:</h2><ol><li>Download configuration file from AWS VPN connections:<ul><li>vendor: Mitrotik</li><li>Platform: RouterOS</li><li>Software: 6.36</li></ul></li><li>Download routerboard script generator from <a href="https://github.com/kkc/aws-vpn-mikrotik" target="_blank" rel="noopener">https://github.com/kkc/aws-vpn-mikrotik</a></li><li>Run script by using ./dynamic-router-config vpn-94e3fff5.txt</li><li>Performing script mikrotik-aws-config at routerboard</li></ol><p>Example of routerboard config<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tunnel1 &amp; tunnel2 CIDR</span></span><br><span class="line"><span class="built_in">/ip </span>addr</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">address</span>=169.254.47.58/30 <span class="attribute">interface</span>=ether1-WAN</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">address</span>=169.254.46.146/30 <span class="attribute">interface</span>=ether1-WAN</span><br><span class="line"></span><br><span class="line"><span class="comment"># ipsec proposal</span></span><br><span class="line"><span class="built_in">/ip ipsec </span>proposal</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">auth-algorithms</span>=sha1 <span class="attribute">comment</span>=<span class="string">"AWS PROPOSAL"</span> <span class="attribute">enc-algorithms</span>=aes-128-cbc <span class="attribute">lifetime</span>=1h <span class="attribute">name</span>=aws <span class="attribute">pfs-group</span>=modp1024</span><br><span class="line"></span><br><span class="line"><span class="comment"># ipsec policy</span></span><br><span class="line"><span class="built_in">/ip ipsec </span>policy</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">src-address</span>=0.0.0.0/0  <span class="attribute">src-port</span>=any <span class="attribute">dst-address</span>=10.0.0.0/16 <span class="attribute">dst-port</span>=any  <span class="attribute">protocol</span>=all <span class="attribute">action</span>=encrypt <span class="attribute">level</span>=require   <span class="attribute">ipsec-protocols</span>=esp  <span class="attribute">tunnel</span>=<span class="literal">yes</span> <span class="attribute">sa-src-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">sa-dst-address</span>=<span class="variable">$TUNNEL1_IP</span>  <span class="attribute">proposal</span>=aws <span class="attribute">priority</span>=0</span><br><span class="line"></span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">src-address</span>=0.0.0.0/0  <span class="attribute">src-port</span>=any <span class="attribute">dst-address</span>=10.0.0.0/16 <span class="attribute">dst-port</span>=any  <span class="attribute">protocol</span>=all <span class="attribute">action</span>=encrypt <span class="attribute">level</span>=require    <span class="attribute">ipsec-protocols</span>=esp  <span class="attribute">tunnel</span>=<span class="literal">yes</span> <span class="attribute">sa-src-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">sa-dst-address</span>=<span class="variable">$TUNNEL2_IP</span> <span class="attribute">proposal</span>=aws <span class="attribute">priority</span>=0</span><br><span class="line"></span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">src-address</span>=0.0.0.0/0  <span class="attribute">src-port</span>=any <span class="attribute">dst-address</span>=169.254.47.57/32 <span class="attribute">dst-port</span>=any <span class="attribute">protocol</span>=all <span class="attribute">action</span>=encrypt <span class="attribute">level</span>=require <span class="attribute">ipsec-protocols</span>=esp  <span class="attribute">tunnel</span>=<span class="literal">yes</span> <span class="attribute">sa-src-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">sa-dst-address</span>=<span class="variable">$TUNNEL1_IP</span>  <span class="attribute">proposal</span>=aws <span class="attribute">priority</span>=0</span><br><span class="line"></span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">src-address</span>=0.0.0.0/0  <span class="attribute">src-port</span>=any <span class="attribute">dst-address</span>=169.254.46.145/32 <span class="attribute">dst-port</span>=any  <span class="attribute">protocol</span>=all <span class="attribute">action</span>=encrypt <span class="attribute">level</span>=require <span class="attribute">ipsec-protocols</span>=esp  <span class="attribute">tunnel</span>=<span class="literal">yes</span> <span class="attribute">sa-src-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">sa-dst-address</span>=<span class="variable">$TUNNEL2_IP</span>  <span class="attribute">proposal</span>=aws <span class="attribute">priority</span>=0</span><br><span class="line"></span><br><span class="line"><span class="built_in">/ip ipsec </span>peer</span><br><span class="line">     <span class="builtin-name">add</span> <span class="attribute">address</span>=<span class="variable">$TUNNEL1_IP</span>/32 <span class="attribute">local-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">passive</span>=<span class="literal">no</span> <span class="attribute">port</span>=500 <span class="attribute">auth-method</span>=pre-shared-key <span class="attribute">secret</span>=<span class="variable">$YOUR_SECRET</span> <span class="attribute">generate-policy</span>=<span class="literal">no</span> <span class="attribute">exchange-mode</span>=main <span class="attribute">send-initial-contact</span>=<span class="literal">yes</span> <span class="attribute">nat-traversal</span>=<span class="literal">no</span>      <span class="attribute">proposal-check</span>=obey <span class="attribute">hash-algorithm</span>=sha1 <span class="attribute">enc-algorithm</span>=aes-128 <span class="attribute">dh-group</span>=modp1024 <span class="attribute">lifetime</span>=8h <span class="attribute">lifebytes</span>=0 <span class="attribute">dpd-interval</span>=10s      <span class="attribute">dpd-maximum-failures</span>=3</span><br><span class="line"> </span><br><span class="line">     <span class="builtin-name">add</span> <span class="attribute">address</span>=<span class="variable">$TUNNEL2_IP</span>/32 <span class="attribute">local-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">passive</span>=<span class="literal">no</span> <span class="attribute">port</span>=500 <span class="attribute">auth-method</span>=pre-shared-key      <span class="attribute">secret</span>=<span class="variable">$YOUR_SECRET</span> <span class="attribute">generate-policy</span>=<span class="literal">no</span> <span class="attribute">exchange-mode</span>=main <span class="attribute">send-initial-contact</span>=<span class="literal">yes</span> <span class="attribute">nat-traversal</span>=<span class="literal">no</span>      <span class="attribute">proposal-check</span>=obey <span class="attribute">hash-algorithm</span>=sha1 <span class="attribute">enc-algorithm</span>=aes-128 <span class="attribute">dh-group</span>=modp1024 <span class="attribute">lifetime</span>=8h <span class="attribute">lifebytes</span>=0 <span class="attribute">dpd-interval</span>=10s      <span class="attribute">dpd-maximum-failures</span>=3</span><br><span class="line"></span><br><span class="line"><span class="comment"># firewall rules</span></span><br><span class="line"><span class="built_in">/ip firewall </span>filter</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=input <span class="attribute">action</span>=accept <span class="attribute">protocol</span>=ipsec-esp <span class="attribute">src-address</span>=<span class="variable">$TUNNEL1_IP</span> <span class="attribute">dst-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">in-interface</span>=ether1-WAN   <span class="attribute">place-before</span>=1</span><br><span class="line"> </span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=input <span class="attribute">action</span>=accept <span class="attribute">protocol</span>=udp <span class="attribute">src-address</span>=<span class="variable">$TUNNEL1_IP</span> <span class="attribute">dst-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">in-interface</span>=ether1-WAN <span class="attribute">src-port</span>=500  <span class="attribute">dst-port</span>=500   <span class="attribute">place-before</span>=1</span><br><span class="line"> </span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=input <span class="attribute">action</span>=accept <span class="attribute">protocol</span>=ipsec-esp <span class="attribute">src-address</span>=<span class="variable">$TUNNEL2_IP</span> <span class="attribute">dst-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">in-interface</span>=ether1-WAN   <span class="attribute">place-before</span>=1</span><br><span class="line"> </span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=input <span class="attribute">action</span>=accept <span class="attribute">protocol</span>=udp <span class="attribute">src-address</span>=<span class="variable">$TUNNEL2_IP</span> <span class="attribute">dst-address</span>=<span class="variable">$YOUR_OFFICE_PUBLIC_IP</span> <span class="attribute">in-interface</span>=ether1-WAN <span class="attribute">src-port</span>=500 <span class="attribute">dst-port</span>=500   <span class="attribute">place-before</span>=1</span><br><span class="line"> </span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=input <span class="attribute">action</span>=accept <span class="attribute">protocol</span>=tcp <span class="attribute">src-address</span>=169.254.47.57 <span class="attribute">dst-address</span>=169.254.47.58 <span class="attribute">dst-port</span>=179   <span class="attribute">place-before</span>=1</span><br><span class="line"> </span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=input <span class="attribute">action</span>=accept <span class="attribute">protocol</span>=tcp <span class="attribute">src-address</span>=169.254.46.145 <span class="attribute">dst-address</span>=169.254.46.146 <span class="attribute">dst-port</span>=179  <span class="attribute">place-before</span>=1</span><br><span class="line"> </span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=forward <span class="attribute">action</span>=accept <span class="attribute">src-address</span>=10.0.0.0/16 <span class="attribute">in-interface</span>=ether1-WAN</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">chain</span>=forward <span class="attribute">action</span>=accept <span class="attribute">dst-address</span>=10.0.0.0/16 <span class="attribute">in-interface</span>=ether2-master</span><br><span class="line"> </span><br><span class="line"><span class="comment"># nat rule</span></span><br><span class="line"><span class="comment"># critically important to AWS connectivity that this rule be ahead of "masquerade".</span></span><br><span class="line"><span class="built_in">/ip firewall </span>nat</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">comment</span>=AWS-VPN <span class="attribute">chain</span>=srcnat <span class="attribute">action</span>=src-nat <span class="attribute">to-addresses</span>=192.168.0.0/24 <span class="attribute">dst-address</span>=10.0.0.0/16 <span class="attribute">place-before</span>=0</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">comment</span>=AWS-VPN <span class="attribute">chain</span>=dstnat <span class="attribute">action</span>=accept <span class="attribute">src-address</span>=10.0.0.0/16 <span class="attribute">in-interface</span>=ether1-WAN <span class="attribute">place-before</span>=0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">/routing bgp </span>instance</span><br><span class="line">  <span class="builtin-name">set</span><span class="built_in"> default </span><span class="attribute">disabled</span>=<span class="literal">yes</span></span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">as</span>=65101 <span class="attribute">client-to-client-reflection</span>=<span class="literal">no</span> <span class="attribute">name</span>=vgw-1 <span class="attribute">redistribute-static</span>=<span class="literal">yes</span> <span class="attribute">router-id</span>=169.254.47.58</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">as</span>=65101 <span class="attribute">client-to-client-reflection</span>=<span class="literal">no</span> <span class="attribute">name</span>=vgw-2 <span class="attribute">redistribute-static</span>=<span class="literal">yes</span> <span class="attribute">router-id</span>=169.254.46.146</span><br><span class="line"> </span><br><span class="line"><span class="built_in">/routing bgp </span>network</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">network</span>=192.168.0.0/24</span><br><span class="line"> </span><br><span class="line"><span class="built_in">/routing bgp </span>peer</span><br><span class="line">  <span class="builtin-name">add</span> <span class="attribute">hold-time</span>=30s <span class="attribute">instance</span>=vgw-1 <span class="attribute">name</span>=a</span><br></pre></td></tr></table></figure></p><h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><p>If the connection doesn’t work due to some reason, we can try following troubleshooting step.</p><p>Verify interesting traffic</p><ul><li>ESP =&gt; allow IP protocal 50 open</li><li>IPSEC Phase2 =&gt; Verify encryption parameter AES-128 and hashing parameter SHA-1</li><li>IPSEC PHase2 =&gt; Lifetime is configured to 3600s or 1hour</li><li>Ensure that perfect forward (PFS) is enabled</li><li>Verify port 500 is not blocked</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.youtube.com/watch?v=eNxPhHTN8gY" target="_blank" rel="noopener">AWS re:Invent 2017: Deep Dive: AWS Direct Connect and VPNs (NET403)</a></li><li><a href="https://helpx.adobe.com/enterprise/using/create-vpn-connection.html" target="_blank" rel="noopener">Create IPSec VPN connection between AWS VPC and customer network</a></li><li><a href="https://www.youtube.com/watch?v=7V2tf2zgerc" target="_blank" rel="noopener">How do I troubleshoot phase 1 IKE issues with an AWS VPN connection</a></li><li><a href="https://www.youtube.com/watch?v=OnkhrzFzQT8" target="_blank" rel="noopener">How do I troubleshoot phase 2 IKE issues with an AWS VPN connection</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;This post is used to note down
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>TCP Network Performance Tuning 筆記</title>
    <link href="http://kkc.github.io/2017/12/18/Network-Performance-Tuning/"/>
    <id>http://kkc.github.io/2017/12/18/Network-Performance-Tuning/</id>
    <published>2017-12-18T01:26:17.000Z</published>
    <updated>2018-09-28T01:36:07.955Z</updated>
    
    <content type="html"><![CDATA[<p>這篇速記主要紀錄看了 AWS reinvent 這個影片的心得，裡面講解怎麼 tuning TCP 相關的 networking issue，影片來源在此<br><div class="video-container"><iframe src="//www.youtube.com/embed/LjeXZItav34" frameborder="0" allowfullscreen></iframe></div></p><p>相當推薦這個影片，裡面不僅提到一些 TCP 上面的學術名詞，也很實際的告訴你在 linux 上面怎麼改變那些值，然後還可以看到在 application 的 benchmark 有很大的差距，這是我之前想像不到的，居然更改了一些設定可以有那麼巨大的差別。</p><h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>講到 TCP ，講者一開始打賭大家第一個想到的，一定是 3 way handshake，一定是 SYN-ACK，但其實 TCP 很棒的地方在於，它提供了一個抽象層，然後我們不需要知道中間到底 packet 發生什麼情況，TCP 會幫忙處理類似重傳，還有要送多快不會掉包的問題，盡最大的可能讓 packet 到達目的地，並且保證封包到達的順序性。</p><ul><li>TCP does well on flow control</li><li>it makes sure it sends as many packets as it can without overwhelming the receiver.</li></ul><h1 id="TCP-optimization"><a href="#TCP-optimization" class="headerlink" title="TCP optimization"></a>TCP optimization</h1><p>主要有幾個重點</p><h2 id="Receive-Window"><a href="#Receive-Window" class="headerlink" title="Receive Window"></a>Receive Window</h2><p>接收端的流量控制</p><p><img src="https://hpbn.co/assets/diagrams/19e54ddeee77adfc1c724b912f7b2694.svg" alt="flow_control"></p><p>傳送數據的時候，如果對方收不下那麼多封包，就會產生 packet drop 的現象，為了避免這種現象發生，接收方要回報自己的 Receive Window (RWND) 有多大，傳送方知道了這個數值後，才不會多送封包過去造成浪費。而 Receive Window 基本上跟接收方開多少 Receive buffer 有關，在 linux 這邊可以用 <code>sysctl -a</code> 去查 RWND 的大小</p><p><code>sysctl -a | grep mem</code><br><code>net.ipv4.tcp_rmem = &lt;MIN&gt; &lt;DEFAULT&gt; &lt;MAX&gt;</code></p><p>有些人會遇到明明網卡很強，網路 bandwidth 也很大，尤其在內網的情況，為什麼網路速度還是上不來，有時候其實只是這個值在搞鬼。<br>而另外一點是，RWND 要設定到多少才是合理？設太大會吃掉太多 linux 的 Memory，設太小又會造成接收資料堵塞，實際上 RWND 的正常值是跟<a href="https://en.wikipedia.org/wiki/Bandwidth-delay_product" target="_blank" rel="noopener">BDP</a> 有相關，也就是跟 bandwidth 和 RTT (round trip time) 有相關，RTT 是指兩台主機間的延遲，你發出 request 後過了多久收到 response 基本上就是 RTT。</p><p>BDP 的公式，假如 bandwidth 是 100Mbps，而 RTT 是 100ms<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BDP = <span class="number">100</span>Mbps * <span class="number">100</span>ms = (<span class="number">100</span> / <span class="number">8</span>) * (<span class="number">100</span> / <span class="number">1000</span>) = <span class="number">1.25</span>MB</span><br></pre></td></tr></table></figure></p><p>在這個公式中，接收端 in-flight 就可以吃下 1.25MB 的資料，所以 RWND 不應該設定小於 1.25MB</p><h2 id="Congestion-control"><a href="#Congestion-control" class="headerlink" title="Congestion control"></a>Congestion control</h2><p>傳送端的流量控制</p><p>傳送端也可以做流量管制，因為 RWND 只有反應接收方的電腦狀態，而沒辦法確切代表整體網路，而且現在網路的的品質其實差距很大，像是 wifi，4G/5G 和有線網路就有很大的差別，所以傳送端這邊也有非常多的演算法，來推導發送多少的 packet 才會是最好的，減少半途消失的損失。</p><p>這邊演算法有根據不同的情況而產生的設計</p><ul><li>Packet LOSS</li><li>Latency</li><li>Bandwidth</li></ul><h3 id="TCP-slow-start"><a href="#TCP-slow-start" class="headerlink" title="TCP slow start"></a>TCP slow start</h3><p>TCP slow start 的概念就是一開始先送小一點的資料量，再慢慢增加到會掉包的程度，最後在減少發送量，以期找到最佳的傳輸大小，這邊就引入了一個值叫做 Congestion Window (CWND)，透過更改 CWND 的大小去找到最佳值。</p><p><img src="https://hpbn.co/assets/diagrams/e76659d1dbe30bbf31d9a5ef6238a236.svg" alt="congestion_control"></p><p>印象中 linux 舊版的 init CWND 是 <code>3MSS</code>，新版的 init CWND 則是 <code>10MSS</code>，一個 MSS 是 1448 bytes。</p><p>這邊有個例子讓大家感受一下 CWND 大小的影響，現在有個網頁是 20KB，如果是 3MSS(4.2KB)，在不考慮 CWND 會改變的情況下，需要發送將近 5 次，而改成 10MSS 則可以大幅降低傳輸次數。</p><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>Loss 會造成 throughput 下降<br><img src="/img/2017-12/loss.png" alt="loss"></p><p>可以透過觀察 TCP retransmissions 看有沒有 loss 發生<br><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -s <span class="string">| grep retransmit</span></span><br></pre></td></tr></table></figure></p><p>但是這個指令不太好用，因為無法看到是哪個 TCP 連線造成的，也沒有時間的資訊，只能靠一直 polling 去畫圖才會比較好用。</p><p>取而代之的是用 socket level 的 debug tool<br>使用 <code>ss -ite</code> 可以看到更多的資訊</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">send-Q: 多少資料在 <span class="built_in"> queue </span> 裡面需要被送出，如果這個值是 0，有可能是 application 裡面就卡住了，大於 0 才會是正常的</span><br><span class="line">cubic: congestion control algorithm</span><br><span class="line">rto: retransmission timeout</span><br><span class="line">cwnd: initial congestion control window</span><br><span class="line">retrans: 重送多少次</span><br></pre></td></tr></table></figure><p>另外這個影片有提到一個 tool 叫做 <code>tcpretrans</code><br>made by netflix brendangregg 可以拿來即時監控 retransmission</p><h3 id="Congestion-Control-Algorithm"><a href="#Congestion-Control-Algorithm" class="headerlink" title="Congestion Control Algorithm"></a>Congestion Control Algorithm</h3><p>Cubic: 2.6.19+ 目前我看我手上的 ubuntu 都是預設使用這個<br>Other algo: BBR, Vegas, illinois, Westwood, Highspeed, Scalable</p><h3 id="Retransmission-Timer"><a href="#Retransmission-Timer" class="headerlink" title="Retransmission Timer"></a>Retransmission Timer</h3><p>封包掉時，要經過多久才重送</p><ul><li>太低: congestion control 反應過度，而且重傳無法改善問題，只會造成網路更壅塞</li><li>太高: 增加 latency</li></ul><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>TC (traffic control) 可以製造一些 loss，還可以更改 qdisc 去做一些 network performance 測試<br>MTU: maximum transmission unit 在 VPC 內的 EC2 可以使用 Jumbo Frame 來溝通，使用 MTU 9001 會幫助蠻多的</p><h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><p>最後有個簡短的 experiment result</p><h2 id="case-1-Http-with-intermediate-network-loss"><a href="#case-1-Http-with-intermediate-network-loss" class="headerlink" title="case 1. Http with intermediate network loss"></a>case 1. Http with intermediate network loss</h2><p><img src="/img/2017-12/ex1.png" alt="ex1.png"><br><img src="/img/2017-12/ex1_res.png" alt="ex1_res.png"><br><img src="/img/2017-12/ex1_res2.png" alt="ex1_res2.png"><br>更改 TCP-BBR 不管在有無 loss 的情況下，拿來跟 cubic 對比，p50 都好上不好，不過 spike 其實會變多</p><h2 id="case-2-low-RTT-between-servers"><a href="#case-2-low-RTT-between-servers" class="headerlink" title="case 2. low RTT between servers"></a>case 2. low RTT between servers</h2><p><img src="/img/2017-12/ex2.png" alt="ex2.png"><br><img src="/img/2017-12/ex2_res.png" alt="ex2_res.png"><br><img src="/img/2017-12/ex2_res2.png" alt="ex2_res2.png"><br>更改 RTO 對 request 的 p99.99 有巨大的改善</p><h2 id="case-3-High-transaction-rate-HTTP-service"><a href="#case-3-High-transaction-rate-HTTP-service" class="headerlink" title="case 3. High transaction rate HTTP service"></a>case 3. High transaction rate HTTP service</h2><p><img src="/img/2017-12/ex3.png" alt="ex3.png"><br><img src="/img/2017-12/ex3_res.png" alt="ex3_res.png"><br>更改 init CWND，p50 latency 改善也很多，但是要注意需要的 Bandwidth 也會有所改變</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>圖片來源來自這本很棒的書<br><a href="https://hpbn.co/building-blocks-of-tcp/#congestion-avoidance-and-control" target="_blank" rel="noopener">https://hpbn.co/building-blocks-of-tcp/#congestion-avoidance-and-control</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;這篇速記主要紀錄看了 AWS reinvent 這個影片的心得，裡面講解怎麼 tuning TCP 相關的 networking issue，影片來源在此&lt;br&gt;&lt;div class=&quot;video-container&quot;&gt;&lt;iframe src=&quot;//www.youtube.
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>AWS fargate 的簡短筆記</title>
    <link href="http://kkc.github.io/2017/12/03/aws-fargate/"/>
    <id>http://kkc.github.io/2017/12/03/aws-fargate/</id>
    <published>2017-12-03T08:32:48.000Z</published>
    <updated>2018-09-28T01:36:07.962Z</updated>
    
    <content type="html"><![CDATA[<p>AWS reinvent 2017 推出了許多對 container 管理的新工具，基本上我原本以為有 K8s on AWS 就很厲害了，沒想到 AWS 也沒有想放棄 ECS，在這兩個 container orchestration 的方法上面又疊加了一層 managed system – fargate。</p><p>這篇主要是對這個 youtube 做的簡短筆記，但這裡他是用 ECS 作為例子，而針對 EKS 的 fargate 應該要等到 2018 才看得到了。</p><div class="video-container"><iframe src="//www.youtube.com/embed/0SceSgOTyrw" frameborder="0" allowfullscreen></iframe></div><h1 id="Fargate"><a href="#Fargate" class="headerlink" title="Fargate"></a>Fargate</h1><ul><li>No instance management</li><li>Task native API</li><li>Resource based pricing</li></ul><p>有談到 per seconds billing，根據選擇的 resource 類型來計價，會是新的 pricing model</p><h2 id="改良"><a href="# 改良" class="headerlink" title="改良"></a>改良 </h2><p> 以前在使用 ECS 的時候，其實有很多地方還是需要管理</p><ul><li>ECS cluster</li><li>EC2 instances (HA, resource provision, mantainence)<ul><li>docker daemon</li><li>ECS agent</li><li>OS version</li><li>…etc</li></ul></li></ul><p>而在使用 fargate 後，我們可以完全不去管理 EC2 這層，感覺概念跟 serverless 很像，我就把 task 丟上去，請你幫我好好管理後面調度的部分。</p><h2 id="Task-definition"><a href="#Task-definition" class="headerlink" title="Task definition"></a>Task definition</h2><p>fargate w/ ECS 也是沿用 ECS 的 task definition</p><p>Task definition</p><ul><li>Task size</li><li>Task execution role</li><li>network configuration for task placement<ul><li>VPC</li><li>Subnet</li><li>Security Group</li></ul></li></ul><h2 id="Network-w-fargate"><a href="#Network-w-fargate" class="headerlink" title="Network w/ fargate"></a>Network w/ fargate</h2><p><img src="/img/2017-12/fargate_network.png" alt="network"><br>針對每個 task 會有不同的 ENI 可以使用</p><ul><li>AWS VPC networking mode - each tasks get its own ENI</li><li>Full control of network interface vis SG and NACLs</li><li>Public IP support</li></ul><h2 id="security"><a href="#security" class="headerlink" title="security"></a>security</h2><p>權限劃分很重要</p><ul><li>cluster level isolation</li><li>permission<ul><li>cluster permission<ul><li>Who can run/see tasks in the cluster</li></ul></li><li>Application permission<ul><li>Which of mu AWS resource can this task access</li></ul></li><li>House keeping permission<ul><li>ECR</li><li>cloudwatch</li><li>…etc</li></ul></li></ul></li></ul><h1 id="結語"><a href="# 結語" class="headerlink" title="結語"></a>結語 </h1><p> 整個看起來，使用 fargate 好像會讓 container 管理變得更方便，但穩定性也是一大考驗，像是 AWS 的 ES，因為碰不到底層的 EC2，改個設定常常要跑半天，想起來如果用更 high level 的管理方式，常常改動需要等待更久的時間，也是犧牲了一點彈性，希望 fargate 不會有給我這樣的感覺。另外一方面，其實也有想過 AWS 的權限管理部分，真的需要有另外一層東西包起來，才能夠好好處理，這點我覺得 AWS 真的花蠻大的心力去解這問題，要不然直接用 k8s 跑，似乎在 compliance 上面都會有不少的難題要解。</p><p>Fargate 目前也只有少部分 region 可以使用，這邊許個願能夠在明年年中之前，讓大部分的 region 可用，這樣應該就夠了吧 (誤</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;AWS reinvent 2017 推出了許多對 container 管理的新工具，基本上我原本以為有 K8s on AWS 就很厲害了，沒想到 AWS 也沒有想放棄 ECS，在這兩個 container orchestration 的方法上面又疊加了一層 managed 
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Retrieving AWS IP range</title>
    <link href="http://kkc.github.io/2017/11/17/aws-ip-range/"/>
    <id>http://kkc.github.io/2017/11/17/aws-ip-range/</id>
    <published>2017-11-16T19:39:05.000Z</published>
    <updated>2018-09-28T01:36:07.961Z</updated>
    
    <content type="html"><![CDATA[<p>It’s a simple note that how to get notifications while AWS IP range changed</p><h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><p><a href="http://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html" target="_blank" rel="noopener">http://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html</a></p><p>AWS provides the ip range file, you can download from <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" target="_blank" rel="noopener">ip-ranges.json</a></p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">jq  <span class="string">'.prefixes[] | select(.region=="us-east-1")'</span> &lt; ipranges.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"ip_prefix"</span>: <span class="string">"23.20.0.0/14"</span>,</span><br><span class="line">  <span class="string">"region"</span>: <span class="string">"us-east-1"</span>,</span><br><span class="line">  <span class="string">"service"</span>: <span class="string">"AMAZON"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"ip_prefix"</span>: <span class="string">"50.16.0.0/15"</span>,</span><br><span class="line">  <span class="string">"region"</span>: <span class="string">"us-east-1"</span>,</span><br><span class="line">  <span class="string">"service"</span>: <span class="string">"AMAZON"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"ip_prefix"</span>: <span class="string">"50.19.0.0/16"</span>,</span><br><span class="line">  <span class="string">"region"</span>: <span class="string">"us-east-1"</span>,</span><br><span class="line">  <span class="string">"service"</span>: <span class="string">"AMAZON"</span></span><br><span class="line">&#125;,</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>can use it to get specific IP range</p><h1 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h1><ul><li><p>Implementing Egress Control<br>  allow outbound traffic to the CIDR block in the Amazon list</p></li><li><p>Implementing Ingress Control<br>  while using different cloud or different platform, we can use it to define legal traffic</p></li></ul><h1 id="AWS-IP-Address-Ranges-Notifications"><a href="#AWS-IP-Address-Ranges-Notifications" class="headerlink" title="AWS IP Address Ranges Notifications"></a>AWS IP Address Ranges Notifications</h1><p>strongly recommened to set this up, really helpful<br><a href="http://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html#subscribe-notifications" target="_blank" rel="noopener">http://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html#subscribe-notifications</a></p><p>Keep Route53 Health check source IP’s up to date<br><a href="http://johntdyer.com/aws/2015/03/16/keep-route53-healthcheck-source-ips-up-to-date.html" target="_blank" rel="noopener">http://johntdyer.com/aws/2015/03/16/keep-route53-healthcheck-source-ips-up-to-date.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It’s a simple note that how to get notifications while AWS IP range changed&lt;/p&gt;
&lt;h1 id=&quot;Usage&quot;&gt;&lt;a href=&quot;#Usage&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Transaction 筆記</title>
    <link href="http://kkc.github.io/2017/10/08/transaction-note/"/>
    <id>http://kkc.github.io/2017/10/08/transaction-note/</id>
    <published>2017-10-08T04:48:47.000Z</published>
    <updated>2018-09-28T01:36:07.961Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h1><p> 大家都知道 RDBMS 其中有個主要的功能，就是能夠把 Transaction 這種任務，做得很完美，而 Transaction 這件事，在很多地方像是銀行轉帳或是進銷存的商業行為裡面，都是非常重要的，因為可以保證資料庫內的資料一致性。 而隨著 NOSQL 的蓬勃發展，看到很多 3rd party library 都想要在 application level 處理 Transaction 的議題，但往往好像使用者都沒搞懂，其實大部分的 lib 只有做到了 ACID 裡面的 Atomicity，而在多併發的環境下，不同的 transaction requests 其實是有機會把數據弄亂，這篇文章就是想要來複習一下 ACID 裡面 Isolation 這塊。</p><h1 id="ACID- 複習"><a href="#ACID- 複習" class="headerlink" title="ACID 複習"></a>ACID 複習 </h1><p>ACID &amp; RDBMS 的複習，推薦大家可以看看 <a href="https://www.youtube.com/watch?v=-exEZS_CEPU" target="_blank" rel="noopener">COSCUP 2017 VanillaDB - 由淺入深的教學型 RDBMS</a>，還有<a href="http://www.slmt.tw/slides/intro_vanilladb.pdf" target="_blank" rel="noopener"> 投影片 </a><br> 這邊也拿裡面銀行轉帳的例子，簡單講解一下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">BEGIN</span> <span class="keyword">TRANSACTION</span>;</span><br><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">account</span> <span class="keyword">SET</span> balance = balance - <span class="number">100</span> <span class="keyword">WHERE</span> <span class="keyword">name</span> = <span class="string">"Red"</span>;</span><br><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">account</span> <span class="keyword">SET</span> balance = balance + <span class="number">100</span> <span class="keyword">WHERE</span> <span class="keyword">name</span> = <span class="string">"Blue"</span>;</span><br><span class="line"><span class="keyword">COMMIT</span> <span class="keyword">TRANSACTION</span>;</span><br></pre></td></tr></table></figure><ul><li><p>Atomicity: all or nothing<br>如果 Transaction 只完成了一部分操作，像是遇到斷電或是資料庫掛掉，該 Transaction 會整個被取消，所有數據會透過日誌復原。</p></li><li><p>Consistent:<br>在每一個操作的過程中，資料庫內的數據需要保持一致性，不會有 Transaction 執行到一半，去查詢資料時，資料庫內整體的餘額 (balance) 變成不一樣。</p></li><li><p>Isolation:<br>就算每一個 Transaction 中有 Atomicity 的特性，但是無法保證在同時執行多個 Transaction 時，能夠保證整個資料庫的一致性，這時候就需要 Isolation 這個特性來幫忙。</p></li><li><p>Duration:<br>資料庫內的資料不會因為斷電，系統崩潰而損失資料。</p></li></ul><h1 id="Isolation"><a href="#Isolation" class="headerlink" title="Isolation"></a>Isolation</h1><p>前面提到就算有 Atomicity 的特性，但是在多個 Transaction 情況下，還是有機會把數據搞亂，例如下面這個例子：</p><p>Transaction 1 將 $100 轉入給 A</p><ol><li>讀取 A 的值</li><li>這個值加上 $100 並寫回 A</li></ol><p>如果在這兩個操作中，有個 Transaction2 也修改了 A 的值加上 $100<br>原本的結果應該是 A 增加了 $200 ，但實際上 A 最後很可能只有加上了 $100</p><p>這也是為什麼我們要為 database 加上 Isolation，這樣才能讓 database 在修改數據時維持一致性，一般討論 Isolation 有數種隔離級別，其實基本上就是上鎖的概念，而鎖的顆粒度大小不一樣。</p><p>分為四個級別：</p><ol><li>Read Uncommitted</li><li>Read Committed</li><li>Repeatable-Read</li><li>Serializable</li></ol><p>為了瞭解這些級別的差距，我們必須要討論一下各個級別解決的問題是什麼。</p><h2 id="Read-Uncommitted"><a href="#Read-Uncommitted" class="headerlink" title="Read Uncommitted"></a>Read Uncommitted</h2><p>最一開始時，想要解決的就是兩個以上不同的 process 對同一筆數據做改變，而最基本的解決方法就是建立排他鎖 (eXclusive Locks or 寫鎖)</p><ol><li>啟動 Transaction A 時，該筆數據只能被此 Transaction 修改</li><li>其它 process 只能讀取</li></ol><p>這個級別我們就稱為 Read Umcommitted</p><h2 id="Read-Committed"><a href="#Read-Committed" class="headerlink" title="Read Committed"></a>Read Committed</h2><p>有了 Read Umcommitted 後，事情可沒就這樣結束了，後來大家馬上就發現到，如果 Transaction A 將某個值改變到一半，又把它 rollback 回去，這樣其他的 process 有可能讀取到錯誤的值，接著又把這個錯誤的值 commit 就糟糕了，這就是所謂的 <em>Dirty Read</em>，也就是讀取到還沒 commit 的值。</p><p><strong>Dirty read</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A <span class="keyword">update</span> field1</span><br><span class="line">B <span class="keyword">read</span> field1</span><br><span class="line">A <span class="keyword">rollback</span></span><br><span class="line">B <span class="keyword">commit</span></span><br></pre></td></tr></table></figure></p><p>這個時候其實只是需要調整鎖的程度，對於需要修改的數據，加上寫鎖後，需要到整個 Transaction 結束後才會釋放，而對於單純讀取 (SELECT) 的數據就沒有那麼嚴格，一但在 Transaction 內讀取完就釋放讀鎖。</p><h2 id="Repeatable-Read"><a href="#Repeatable-Read" class="headerlink" title="Repeatable-Read"></a>Repeatable-Read</h2><p>這個級別主要是要解決 Unrepeatable read 的情況，當我們需要在一個 Transaction 裡面讀取同個 field 時，有可能會讀到不一樣的值， 情況有可能是這樣發生的，當 Transaction A 在讀取 Field1 時，同時間 Transaction B 改變了這個該值，當 Transaction A 再次讀取該值時，其數據就有可能被改變，這也是因為 read lock 會在 SELECT 完後馬上就被釋放，所以最簡單的方法就是把讀寫鎖釋放的時間延後到 Transaction 結束後，但壞處就是系統的效能會下降的很快，連讀取資料的部分也需要排隊讀取</p><p><strong>Unrepeatable read</strong><br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A read field1</span><br><span class="line">B <span class="keyword">update</span> field1</span><br><span class="line">B <span class="keyword">commit</span></span><br><span class="line">A <span class="keyword">read</span> field1</span><br></pre></td></tr></table></figure></p><h2 id="Serializable"><a href="#Serializable" class="headerlink" title="Serializable"></a>Serializable</h2><p>最高的級別，一般資料庫不會使用到這個級別，而這個級別是要解決 phantom read 的問題，主要跟 Range query 比較有相關，舉例來說，當 Transaction A 使用 range query 查詢後得到 10 筆資料，而 Transaction B 在這個條件裡面新增了一筆資料並且 commit 後，Transaction A 在去 query 時，就會變成 11 筆資料。<br>但使用這個級別，最簡單的做法基本上就是鎖住整張表，以免不同的 Transaction 更動其資料，所以造成的效率低落也是可以想像的。</p><p><strong>phantom read</strong><br><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A query =&gt; <span class="meta">get</span> <span class="number">10</span> <span class="meta">data</span></span><br><span class="line"><span class="keyword">B </span>insert <span class="number">1</span> <span class="meta">data</span></span><br><span class="line"><span class="keyword">B </span>commit</span><br><span class="line">A query =&gt; <span class="meta">get</span> <span class="number">11</span> <span class="meta">data</span></span><br></pre></td></tr></table></figure></p><h1 id="總結一下 -isolation-amp-lock- 的關係"><a href="# 總結一下 -isolation-amp-lock- 的關係" class="headerlink" title="總結一下 isolation &amp; lock 的關係"></a>總結一下 isolation &amp; lock 的關係</h1><p>from <a href="https://en.wikipedia.org/wiki/Isolation_%28database_systems%29#Read_phenomena" target="_blank" rel="noopener">wiki</a></p><table><thead><tr><th>Isolation level</th><th>Write Operation</th><th>Read Operation</th><th>Range Operation</th></tr></thead><tbody><tr><td>Read Uncommitted</td><td>until commit</td><td>not used</td><td>not used</td></tr><tr><td>Read Committed</td><td>until commit</td><td>during statement</td><td>not used</td></tr><tr><td>Repeatable Read</td><td>until commit</td><td>until commit</td><td>not used</td></tr><tr><td>Serializable</td><td>until commit</td><td>until commit</td><td>until commit</td></tr></tbody></table><p>順便借用一下 <a href="http://www.slmt.tw/blog/about/" target="_blank" rel="noopener">Yu-Shan Lin</a> 大大的投影片的圖</p><p><img src="/img/2017-10/database_isolation.png" alt="database_isolation.png"></p><h1 id="結語"><a href="# 結語" class="headerlink" title="結語"></a>結語 </h1><p> 複習了一下 RDBMS 的 ACID 概念，其實發現在提升 concurrency 的情況下，又要讓數據保持完整，其實是一件很困難的事情，而其實還有很多東西像是 MVCC、Row version、樂觀鎖、悲觀鎖還有死鎖等等東西，這篇都還來不及贅述，要實作真正的 Transaction 在 application 端其實是很複雜的，而 RDBMS 其實都很好的幫我們處理完這些問題，所以要處理數據且需要 Transaction 的話，還是推薦交給專業的工具，而不要自己傻傻的刻一套啊。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Isolation_(database_systems)</a></li><li><a href="https://www.zhihu.com/question/30272728" target="_blank" rel="noopener">https://www.zhihu.com/question/30272728</a></li><li><a href="https://technet.microsoft.com/en-us/library/ms187101(v=sql.105).aspx" target="_blank" rel="noopener">https://technet.microsoft.com/en-us/library/ms187101(v=sql.105).aspx</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h1&gt;&lt;p&gt; 大家都知道 RDBMS 其中有個主要的功能，就是能夠把 Transaction 這種任務，做得很完美，而 Transaction 這件
      
    
    </summary>
    
    
      <category term="RDBMS" scheme="http://kkc.github.io/tags/RDBMS/"/>
    
  </entry>
  
  <entry>
    <title>淺談 Asynchronous Programming</title>
    <link href="http://kkc.github.io/2017/09/01/asynchronous-programming/"/>
    <id>http://kkc.github.io/2017/09/01/asynchronous-programming/</id>
    <published>2017-09-01T14:08:31.000Z</published>
    <updated>2018-09-28T01:36:07.963Z</updated>
    
    <content type="html"><![CDATA[<iframe src="//www.slideshare.net/slideshow/embed_code/key/2OtC3FTsUFvtNN" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <p> 利用這篇文章稍微紀錄一下，最近在公司分享的淺談 Asynchronous programming 的心得，其實在現在各個網路公司盛行的時代，不懂點 Asynchronous model 應該是不太可能的，而且就算不懂實際上大家也是天天在用，類似寫 Browser 端的 javascript，或是不論 nodejs 或是 python (像是 gevent)，都常常看到大家再談 Asynchronous model 對 performance 帶來的好處，正好同事們很多人正在學 javascript，而有些人似乎不知道最初是在解決什麼問題，所以才會有這個投影片的誕生，不過因為太多方法可以處理 Asynchronous model，我並沒有講得太深入，很多地方只有點到為止，希望之後有機會能夠再補充一些。</p><p> 所以到底 Asncyhronous or concurrency 解決了什麼問題呢？一言以敝之，追根究底就是消除等待。<br>concurrency 主要拿來跟 parallellism 比較，concurrency 談的其實就是能夠在同一時間完成很多事情，我喜歡拿做菜為例子，就算只有一個廚師，他還是可以在同時間完成切菜，準備醬料，煮菜等等工作，他會在中間切換來切換去，而不會等到一盤菜好了，再去準備接下來的事情，而 Parallellism 比較像是同時有很多 worker 做差不多事情。</p><p> 我們一般寫的程式，其實大部分都在處理這種問題，像是 GUI 程式，使用者按了一個 button 後，你不可能完全卡在那邊等待其他的程式跑完，又像是你的 API server 經由網路呼叫一個 3rd party 的外部程式，如果你在那邊傻傻的等，是不是浪費了很多 CPU resource。這時候我猜大家都很聰明想到可以直接用 thread 去操作，避免掉 main process 被卡住的情況，而其實 thread 也算是一種 aysnchronous programming 的 model，而且現今的程式語言也有更好語法去使用它們，像是用 Future or Promise。</p><p> 在瞭解完要解決什麼問題後，需要知道的是不同解法之間的差異，因為公司同仁大部分都是寫 javascript 或是 python，所以在 asynchronous flow 上面比較多著墨 callback, eventloop, coroutine 還有最後衍生出來的 async/await，而 javascript 天生就使用一個 thread 去達成 concurrency，這點感覺有點奇妙，所以需要先補充一些 linux IO 的知識，像是 blocking IO/non-blocking IO 的差別，最後導出 IO multiplexing 才能講得下去 event loop 怎麼實作的，nginx 之類的 service 就是利用了 IO multiplexing 才有效的解決 <a href="https://en.wikipedia.org/wiki/C10k_problem" target="_blank" rel="noopener">C10K</a> 的問題，使用一個 thread 處理 network IO 請求，其實就減少了增減 thread 的開銷，memory 的使用量也大減，但取而代之的就是，程式會有點難寫難讀，所以就有了 libev, libevent, libuv 這類 library 幫忙處理 asynchronous IO 這部分，使用這類的 lib，上層 program 很簡單就可以使用 callback function 與之互動，等到 socket 的 file descriptor 被 trigger 時再去呼叫 callback 繼續處理下去。</p><p> 在有了 callback 後，世界並不是就太平了，很快就有人發現可以寫出 callback hell 這種程式，asynchronous progrmamming (主要談 callback) 到這邊就變成語法的改進了，希望能夠把程式寫得更漂亮更易讀一點，所以就有了 promise 或是 coroutine 的方法與其結合，在 coroutine 中會把控制權從 function 中切換回 main task 中，某種程度跟 eventloop 就很相似，所以可以利用 coroutine 的特性加上 non-blocking I/O 成為更好的框架，而程式也會變得像是 synchronous 的樣子，不過要注意一但有程式是 blocking IO 或是 cpu intensive 的任務，就會把這個 thread 卡住，最後提到的 async/await 只不過是語法的變形，其實跟 coroutine 的概念是很相似的，可以讓整個程式更好寫易讀，然後背後又能高效率的處理 IO bound 問題。</p><p> 最後來總結一下，其實這些方法都是為了解決一些任務太慢而產生的，在我們當使用者的時候 (caller)，實際上也許不知道背後這些 async module 是如何運作的，除非是自己要一手從下到上包辦，但還是有些點需要注意，如果這類程式只是處理 networking IO 的話，應該是不會有太大的問題，但如果中間有個 cpu intensive 的任務最好還是要能 fork 出 process/thread 去處理，或是利用 queue 丟給其他的 worker 去處理，所以一旦我們清楚這些架構後，才能知道採取哪種方式處理問題是比較好的。</p><p>Reference</p><ol><li><a href="https://www.youtube.com/watch?v=8aGhZQkoFbQ" target="_blank" rel="noopener">What the heck is the event loop anyway</a> 非常棒的 javascript eventloop 講解 </li><li><a href="https://x.st/javascript-coroutines/" target="_blank" rel="noopener">javascript-coroutine</a></li><li><a href="https://codewala.net/2015/07/29/concurrency-vs-multi-threading-vs-asynchronous-programming-explained/" target="_blank" rel="noopener">concurrency-vs-multi-threading-vs-asynchronous-programming-explained</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;iframe src=&quot;//www.slideshare.net/slideshow/embed_code/key/2OtC3FTsUFvtNN&quot; width=&quot;595&quot; height=&quot;485&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginhe
      
    
    </summary>
    
    
      <category term="programmming" scheme="http://kkc.github.io/tags/programmming/"/>
    
  </entry>
  
</feed>
