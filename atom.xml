<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kakashi&#39;s Notes</title>
  <icon>https://www.gravatar.com/avatar/a78f6cc4fc127a344343983280674d46</icon>
  <subtitle>修其本而末自應</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kkc.github.io/"/>
  <updated>2020-12-14T14:20:58.282Z</updated>
  <id>http://kkc.github.io/</id>
  
  <author>
    <name>Kakashi</name>
    <email>kakashi1000@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Golang 的 string interning 技巧</title>
    <link href="http://kkc.github.io/2020/12/14/golang-string-interning/"/>
    <id>http://kkc.github.io/2020/12/14/golang-string-interning/</id>
    <published>2020-12-14T13:49:23.000Z</published>
    <updated>2020-12-14T14:20:58.282Z</updated>
    
    <content type="html"><![CDATA[<h2 id="String-Interning"><a href="#String-Interning" class="headerlink" title="String Interning"></a>String Interning</h2><p>最近在 twitter 上面看到一篇推文</p><p><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hacked string interning profiler for <a href="https://twitter.com/hashtag/golang?src=hash&amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener">#golang</a>:<a href="https://t.co/EB2uJwzvtx" target="_blank" rel="noopener">https://t.co/EB2uJwzvtx</a><br>Allows to understand where to use interning &amp; exact savings for heap size/garbage rate. May be useful for larger projects.<br>Yay or nay? <a href="https://t.co/71h6tNJHaX" target="_blank" rel="noopener">pic.twitter.com/71h6tNJHaX</a></p>&mdash; Dmitry Vyukov (@dvyukov) <a href="https://twitter.com/dvyukov/status/1337847667125313538?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">December 12, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p><p>具體在討論這個 <a href="https://go-review.googlesource.com/c/go/+/277376" target="_blank" rel="noopener">CL</a> 要加入 string interning profile，而利用這個可以測量是否該加入 string interning，原本不知道這個是幹嘛的，後來看了一下 comments 內的一些解釋和文章，才知道原來 String interning 是個可以拿來有效減少 memory 使用量的技巧，原理相當簡單，而在其他語言裡面也有這種東西，像是 python 在一些小的數字和文字上面，都是會指向同一組記憶體，藉此來減少 memory allocation 的時間和用量，而 string intening 也是這類技巧的名字(<a href="https://en.wikipedia.org/wiki/String_interning)。" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/String_interning)。</a></p><h2 id="Golang- 裡面的運用"><a href="#Golang- 裡面的運用" class="headerlink" title="Golang 裡面的運用"></a>Golang 裡面的運用 </h2><p> 在 golang 裡面在什麼地方被用到，也可以看下面幾篇的解釋，個人覺得已經很清楚</p><ul><li><a href="https://artem.krylysov.com/blog/2018/12/12/string-interning-in-go/" target="_blank" rel="noopener">https://artem.krylysov.com/blog/2018/12/12/string-interning-in-go/</a></li><li><a href="https://commaok.xyz/post/intern-strings/" target="_blank" rel="noopener">https://commaok.xyz/post/intern-strings/</a></li></ul><p>基本上要做實驗可以透過下面的 function 去看 string 的 pointer 位置，看是不是同一份<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">pointer</span><span class="params">(s <span class="keyword">string</span>)</span> <span class="title">uintptr</span></span> &#123;</span><br><span class="line">    p := unsafe.Pointer(&amp;s)</span><br><span class="line">    h := *(*reflect.StringHeader)(p)</span><br><span class="line">    <span class="keyword">return</span> h.Data</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    b := []<span class="keyword">byte</span>(<span class="string">"hello"</span>)</span><br><span class="line">    s := <span class="keyword">string</span>(b)</span><br><span class="line">    t := <span class="keyword">string</span>(b)</span><br><span class="line">    fmt.Println(pointer(s), pointer(t))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>相關的 playgound 連結在 <a href="https://play.golang.org/p/oyq6Pz79EGa" target="_blank" rel="noopener"> 這邊</a>，從這個實驗中，我們可以很快發現，兩個字串指向的記憶體不同，而在 golang 裡面比對 string 如果是同一個 pointer 而且 Len 都一樣，就可以加速比對的過程，而不用一個 byte 一個 byte 的去比較，所謂的 interning，也就是如果我們能夠不重複 allocate 記憶體，都用同一個字串。</p><ul><li>而有另外一個有趣的點是，這個 playground 裡面可以把 hello 改成 h, 可以看到 pointer 都指向同一個位置，這是透過 compile time constant 的結果，具體可以看這個 <a href="https://go-review.googlesource.com/c/go/+/97717/" target="_blank" rel="noopener">CL</a> 的解釋，透過 benchmark 提前先 allocate 一個字元在效率上面可以提升很多。</li></ul><h2 id="自幹 -string-interning"><a href="# 自幹 -string-interning" class="headerlink" title="自幹 string interning"></a>自幹 string interning</h2><p>而在 golang 裡面其實並沒有很多地方有做 interning，但是我們在處理一些資料的時候，其實有機會用到這個技巧，像是第一篇文章裡面有寫到，如果我們要處理大量的 text，如果沒有 interning，可能就需要 allocate 很大量的記憶體去儲存這些資料，另外是像從資料庫讀取東西時，也可以有些數據是一直重複出現的，這時也可以應用同樣的技巧。</p><p>而一般來說透過類似 cache 的方式可以自幹 string interning，像是第二篇文章的 code<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">func intern(m map[string]string, b []byte) string &#123; </span><br><span class="line">    // look for an existing string to re-use </span><br><span class="line">    c, ok := m[string(b)] </span><br><span class="line">    if ok &#123; </span><br><span class="line">        // found an existing string return c </span><br><span class="line">    &#125; </span><br><span class="line">    // didn&apos;t find one, so make one and store it </span><br><span class="line">    s := string(b) </span><br><span class="line">    m[s] = s return s</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>但是麻煩的地方跟自己維護 LRU cache 一樣，如果有不需要用到的字串需要被 evict 掉，要不然也會佔據記憶體，另外是要做一個能夠 concurrent 存取的 LRU cache 也是不容易，所以這個東西沒處理也會變成反效果，而大家都會談論到這個 project <a href="https://github.com/josharian/intern" target="_blank" rel="noopener">https://github.com/josharian/intern</a>，裡面是用 sync.map 實作 interning，但是還是要斟酌一下是不是真的該用。</p><p>順帶一提是透過這個 CL，我又追到這個 <a href="https://github.com/golang/go/issues/32779#issuecomment-731623919" target="_blank" rel="noopener">CL</a>，裡面的討論也蠻不錯的，也讓我了解到設計系統需要考量的一些東西，我蠻建議看下 dsnet 對做 memorize stirngs during decode 的一些看法和實驗，很多地值得借鑒，像是</p><ul><li>String 越長，對於 cache 越不友善，有可能 cache hit rate 會下降的很快，而太長的 sring 也需要花更多時間去比對和做 hash，所以只需要選擇 cache 小一點的資料(e.g &lt; 16B)</li><li>Go men allocator 其實速度很快，配置 16B 的字串只需要 35ns，所以 cache 的 lookup 和比較應該要快於 35ns 才有賺</li><li>JSON 的 object name 有 high degree of locality，所以有個很小的 cache 去存這段東西很值得</li><li>而 JSON 的 value 可能就沒那麼值得去 cache，因為 locality 不好</li></ul><h2 id="結論"><a href="# 結論" class="headerlink" title="結論"></a>結論 </h2><p> 總的來說，string interning 也許不是很常會使用的技巧，但是如果真的有極端的 case，也許拿來使用減少記憶體和 gc 壓力也是不錯的途徑，當然前提還是要經過縝密的 benchmark。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://commaok.xyz/post/intern-strings/" target="_blank" rel="noopener">https://commaok.xyz/post/intern-strings/</a></li><li><a href="https://github.com/bserdar/go/commit/9829fb1b5501df91a44cb24e554310a6f28f123c" target="_blank" rel="noopener">https://github.com/bserdar/go/commit/9829fb1b5501df91a44cb24e554310a6f28f123c</a></li></ul><p><span>Photo by <a href="https://unsplash.com/@jessedo81?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">jesse orrico</a> on <a href="https://unsplash.com/s/photos/storage?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;String-Interning&quot;&gt;&lt;a href=&quot;#String-Interning&quot; class=&quot;headerlink&quot; title=&quot;String Interning&quot;&gt;&lt;/a&gt;String Interning&lt;/h2&gt;&lt;p&gt;最近在 twitter 上面
      
    
    </summary>
    
    
      <category term="golang" scheme="http://kkc.github.io/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>學習使用 compiler vector extension 去寫 SIMD 程式</title>
    <link href="http://kkc.github.io/2020/11/01/note-for-simd/"/>
    <id>http://kkc.github.io/2020/11/01/note-for-simd/</id>
    <published>2020-11-01T12:09:10.000Z</published>
    <updated>2020-11-01T15:12:21.590Z</updated>
    
    <content type="html"><![CDATA[<p>最近強者我 Tead lead <a href="https://www.facebook.com/champ.yen" target="_blank" rel="noopener">Champ Yen</a> 在公司內部做了一次 experience sharing，內容非常的精彩，分享了怎麼使用 compiler vector extensions 去寫 SIMD 的 program，進而將 program 的效率提升，並且可以產出 portable 的 program。</p><h2 id="SIMD- 到底是什麼"><a href="#SIMD- 到底是什麼" class="headerlink" title="SIMD 到底是什麼"></a>SIMD 到底是什麼</h2><p>SIMD 的全名是 single instruction multiple data，而顧名思義就是使用一個 instruction 去操作多組 data。</p><p>在 <a href="https://en.wikipedia.org/wiki/Flynn%27s_taxonomy" target="_blank" rel="noopener">Flynn taxonomy</a> 裡面將 information stream 分成了 instruction 和 data，進而對計算機做分類，而普通我們認知的 instruction 操作一個 data (register) 被稱為 SISD，而 SIMD 之所以重要是因為電腦的單核的頻率在古早前就上不去了，詳情可以見下圖</p><p><img src="https://github.com/karlrupp/microprocessor-trend-data/raw/master/48yrs/48-years-processor-trend.png?raw=true" alt="此圖"></p><p>而改善程式的效率的方式，就變成探索如何將其變成 parallelism 的過程，這方面就多了如何善用 Multicore，熟悉 NUMA，以及採用 SIMD 之類的技術。</p><h2 id="SIMD- 為什麼會比較快"><a href="#SIMD- 為什麼會比較快" class="headerlink" title="SIMD 為什麼會比較快"></a>SIMD 為什麼會比較快 </h2><p> 這頁取自交通大學劉志尉老師的課程 <a href="http://twins.ee.nctu.edu.tw/courses/ca_13/lecture/CA_lec08-chpater_4-vector_processing.pdf" target="_blank" rel="noopener"> 投影片</a>， 從中可以看到 scalar code 和 vector code 各自需要的 instruction 數量，而 scalar code 還要考慮外面有個 loop 迴圈，所以整體需要時間更多。</p><p><img src="https://i.imgur.com/JdA2fyy.png" alt></p><h2 id="SIMD-instruction- 有哪些 -type"><a href="#SIMD-instruction- 有哪些 -type" class="headerlink" title="SIMD instruction 有哪些 type"></a>SIMD instruction 有哪些 type</h2><ul><li>Load/Store</li><li>Per-Lane<ul><li>Arithmetic</li><li>Bitwise, Logical</li></ul></li><li>Cross/Inter Lane<ul><li>Permute, Select, Shuffle(LUT)</li><li>Alignment</li><li>Pack &amp; UnPack</li></ul></li><li>Reduction (e.g Average of vector)<ul><li>Minimum</li><li>Maximum</li><li>Average</li></ul></li><li>Special (特殊的 instruction)<ul><li>NN specific ISA</li><li>inter-lane + per lane attributes</li></ul></li></ul><h2 id="為什麼需要 -compiler-vector-extension"><a href="# 為什麼需要 -compiler-vector-extension" class="headerlink" title="為什麼需要 compiler vector extension"></a>為什麼需要 compiler vector extension</h2><ol><li>可以使用 vector 去提升程式的 performance</li><li>比直接使用特定平台的 intrinsics/ASM 來的容易使用</li><li>比較容易透過這種方式，去修改已經存在的 C/C++ 程式</li><li>portability (大加分)</li><li>可以跟 OpenMP 一起使用 (這邊我其實沒很懂，因為沒寫過 openmp)</li></ol><h2 id="如何使用呢"><a href="# 如何使用呢" class="headerlink" title="如何使用呢?"></a>如何使用呢?</h2><h3 id="GCC-vector-type-declaration"><a href="#GCC-vector-type-declaration" class="headerlink" title="GCC vector type declaration"></a>GCC vector type declaration</h3><p>先來學如何宣告 vector，可以使用下列語法</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> SCALAR_TYPE TYPE_NAME __attribute__((vector_size(SIZE), aligned(<span class="number">1</span>)));</span><br></pre></td></tr></table></figure><p>e.g:<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> v4si __attritube__ ((vector_size (<span class="number">16</span>), aligned(<span class="number">1</span>)));</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">float</span> v4sf __attribute__ ((vector_size (<span class="number">16</span>));</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">double</span> v4df __attribute__ ((vector_size (<span class="number">32</span>)));</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> v4di __attribute__ ((vector_size (<span class="number">32</span>)));</span><br></pre></td></tr></table></figure></p><p>以上的宣告很簡單，以 v4si 為例，我們宣告了一個 vector_size 為 16bytes 的 vector，其分割成 4 個 int sized unit。我們可以用下列的方式去初始化他們</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">v4si a = &#123;<span class="number">1</span>,<span class="number">-2</span>,<span class="number">3</span>,<span class="number">-4</span>&#125;;</span><br><span class="line">v4sf b = &#123;<span class="number">1.5f</span>,<span class="number">-2.5f</span>,<span class="number">3.f</span>,<span class="number">7.f</span>&#125;;</span><br><span class="line">v4di c = &#123;<span class="number">1U</span>LL,<span class="number">5U</span>LL,<span class="number">0U</span>LL,<span class="number">10U</span>LL&#125;;</span><br></pre></td></tr></table></figure><h3 id="用操作 -scalar- 的方式使用 -SIMD"><a href="# 用操作 -scalar- 的方式使用 -SIMD" class="headerlink" title="用操作 scalar 的方式使用 SIMD"></a>用操作 scalar 的方式使用 SIMD</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> v4si __attribute__ ((vector_size (<span class="number">16</span>)));</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    v4si a = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">    v4si b = &#123;<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">4</span>&#125;;</span><br><span class="line">    v4si c;</span><br><span class="line"></span><br><span class="line">    c = a + b;      <span class="comment">/* The result would be &#123;4, 4, 4, 8&#125;  */</span></span><br><span class="line">    c = a &gt; b;     <span class="comment">/* The result would be &#123;0, 0,-1, 0&#125;  */</span></span><br><span class="line">    c = a == b;     <span class="comment">/* The result would be &#123;0,-1, 0,-1&#125;  */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="再來學下其他的 -Compiler-Build-in-function"><a href="# 再來學下其他的 -Compiler-Build-in-function" class="headerlink" title="再來學下其他的 Compiler Build-in function"></a>再來學下其他的 Compiler Build-in function</h2><ul><li><code>__builtin_shuffle</code></li><li><code>__builtin_convertvector</code></li><li><code>__builtin_prefetch</code></li><li><code>__builtin__clear_cache</code></li></ul><h3 id="舉個例子"><a href="# 舉個例子" class="headerlink" title="舉個例子"></a>舉個例子 </h3><p> 這是我給 Champ 出的問題，如何高效地把一個 <code>vector&lt;int&gt;</code> 轉成 <code>vector&lt;float&gt;</code>，這邊就使用了 <code>__builtin_convertvector</code>，主要是因為 vector 也是連續的記憶體操作，所以可以使用 pointer 指過去後使用 SIMD 操作。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">float</span> v8sf __attribute__ ((vector_size (<span class="number">32</span>)));</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> v8si __attribute__ ((vector_size (<span class="number">32</span>)));</span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vint(TEST_LEN)</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt; vfp(TEST_LEN)</span><br><span class="line"></span><br><span class="line">srand(time(<span class="literal">NULL</span>))</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; TEST_LEN; i++) &#123;</span><br><span class="line">    vint[i] = rand()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *intp = vint.data();</span><br><span class="line"><span class="keyword">float</span> *fpp = vfp.data();</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">stime</span>, <span class="title">etime</span>;</span></span><br><span class="line">gettimeofday(&amp;stime, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i+<span class="number">8</span> &lt; TEST_LEN; i+=<span class="number">8</span>) &#123;</span><br><span class="line">    *((v8sf*)(fpp+i)) = __builtin_convertvector(*(v8si*)(intp + i), v8sf);</span><br><span class="line">&#125;</span><br><span class="line">gettimeofday(&amp;etime, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure><h2 id="Architecture-Dependent-Compiler-Intrinsics"><a href="#Architecture-Dependent-Compiler-Intrinsics" class="headerlink" title="Architecture Dependent Compiler Intrinsics"></a>Architecture Dependent Compiler Intrinsics</h2><p>可以使用 union 去撈出 vector register 裡面個別的值，這樣對於 debug 或是真的要轉型就不會那麼麻煩。</p><h3 id="gcc"><a href="#gcc" class="headerlink" title="gcc:"></a>gcc:</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;immintrin.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> u8x16 __attribute__ ((vector_size (<span class="number">16</span>)));</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> u32x4 __attribute__ ((vector_size (<span class="number">16</span>)));</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> &#123;</span><br><span class="line">    __m128i mm;</span><br><span class="line">    u8x16   u8;</span><br><span class="line">    u32x4   u32;</span><br><span class="line">&#125; v128</span><br></pre></td></tr></table></figure><h3 id="LLVM-clang"><a href="#LLVM-clang" class="headerlink" title="LLVM/clang:"></a>LLVM/clang:</h3><ul><li>use vector extension variables directly </li></ul><p>Ref: <a href="https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html" target="_blank" rel="noopener">https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html</a></p><h2 id="其他的 -Tips"><a href="# 其他的 -Tips" class="headerlink" title="其他的 Tips"></a>其他的 Tips</h2><h3 id="Porting-amp-Troubleshoot- 的一些方法"><a href="#Porting-amp-Troubleshoot- 的一些方法" class="headerlink" title="Porting &amp; Troubleshoot 的一些方法"></a>Porting &amp; Troubleshoot 的一些方法 </h3><p> 需要人工算一下將原本的 loop 切成 fixed size 的 chunk (e.g 8 for int32_t)，接著再把 loop 內部換成 vector operations。</p><h3 id="Deployment-Function-Multi-Versioning-a-k-a-FMV"><a href="#Deployment-Function-Multi-Versioning-a-k-a-FMV" class="headerlink" title="Deployment - Function Multi-Versioning (a.k.a FMV)"></a>Deployment - Function Multi-Versioning (a.k.a FMV)</h3><ul><li><p>Pros:<br>透過這個方法可以讓編譯出來的 binary 跑在不同的平台上面</p></li><li><p>Cons:<br>binary 會變肥大</p></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__attribute__((target_clones(<span class="string">"avx2"</span>, <span class="string">"avx"</span>, <span class="string">"sse4.2"</span>, <span class="string">"sse3"</span>, <span class="string">"sse2"</span>, <span class="string">"default"</span>)))</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    v8si v0 = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>&#125;;</span><br><span class="line">    v8si v1 = &#123;<span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>&#125;;</span><br><span class="line">    </span><br><span class="line">    v8si v2 = v0 + v1;</span><br><span class="line">    <span class="keyword">return</span> v2[<span class="number">3</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有興趣的人可以透過 <a href="https://godbolt.org/z/of5d6v" target="_blank" rel="noopener">https://godbolt.org/z/of5d6v</a> 去看看有加這行，會多產生不同的 assembly code，這樣一來就對應不同平台上面的 vector operations。</p><p>Ref: <a href="https://lwn.net/Articles/691932/" target="_blank" rel="noopener">https://lwn.net/Articles/691932/</a></p><h2 id="使用 -SIMD-Vector- 的一些眉眉角角"><a href="# 使用 -SIMD-Vector- 的一些眉眉角角" class="headerlink" title="使用 SIMD/Vector 的一些眉眉角角"></a>使用 SIMD/Vector 的一些眉眉角角</h2><ul><li>需要找到 Parallelism 的演算法</li><li>可以透過不同的方式使用 SIMD, 不過要考慮 portability 的問題。</li><li>unsupported operations<ul><li>division, high level function(math functions)</li></ul></li><li>Floating point<ul><li>cross device compatibility</li></ul></li><li>Boundary handling 等邊界問題<ul><li>需要使用 padding, predication, 或是 fallback 去使用 scalar</li></ul></li><li>Divergence</li><li>Register splitting</li><li>需要考慮 Non-Regular Access/Process Pattern 還有 dependency<ul><li>像是 LUT, AoS (Array of structure)</li></ul></li></ul><h2 id="一些心得"><a href="# 一些心得" class="headerlink" title="一些心得"></a>一些心得 </h2><p> 通過 Champ 這個分享，我真的終於知道如果安全的使用 SIMD，之前都是看一堆 project 寫 x86 assembly 寫得很爽，或是只能依靠 compiler 的 <a href="https://en.wikipedia.org/wiki/Automatic_vectorization" target="_blank" rel="noopener">Automatic vectorization</a>，現在終於知道也可以透過 compiler instrinsic 來寫，另外是 Champ 也提到 SIMD 這個技術已經發展了很多年，而 compiler instrinsic 像是 gcc 也是從 3.1 就開始支援了，所以大家放心的使用，然後害怕的 portability 的問題也是被解決的蠻好的，而我大概查了一下，如果真的想達成 compiler agnostic，也可以使用 libarary instrinsic，不過就各有優缺點了，用 compiler instrinsic 的好處，整體的程式碼還是可以寫得跟處理 scalar 一樣，個人也覺得看起來蠻舒服的。</p><p>另外是在搜索相關資料的過程中，看了很多不錯的文章，像是 stackoverflow 的 blog 就有提到一些 SIMD 的 <a href="https://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/" target="_blank" rel="noopener"> 應用 </a>，但也從這個<a href="https://www.slideshare.net/WeiTaWang/simd-109492525" target="_blank" rel="noopener"> 快快樂樂 SIMD</a> 看到蠻多要注意的地方，而像是 AWS 所提供的 x86 &amp; ARM 機器也都會有提到，他們各自支援的 SIMD 指令，我們如果真的要學習榨效能，這塊的基本概念真的也需要撿起來。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html" target="_blank" rel="noopener">https://gcc.gnu.org/onlinedocs/gcc/Vector-Extensions.html</a></li><li><a href="https://www.karlrupp.net/2015/06/40-years-of-microprocessor-trend-data/" target="_blank" rel="noopener">https://www.karlrupp.net/2015/06/40-years-of-microprocessor-trend-data/</a></li><li><a href="https://github.com/karlrupp/microprocessor-trend-data" target="_blank" rel="noopener">https://github.com/karlrupp/microprocessor-trend-data</a></li><li><a href="https://www.uio.no/studier/emner/matnat/ifi/IN3200/v19/teaching-material/avx512.pdf" target="_blank" rel="noopener">https://www.uio.no/studier/emner/matnat/ifi/IN3200/v19/teaching-material/avx512.pdf</a></li><li><a href="https://champyen.blogspot.com/2020/05/clang-gcc-vector-extension.html" target="_blank" rel="noopener">https://champyen.blogspot.com/2020/05/clang-gcc-vector-extension.html</a></li><li><a href="http://twins.ee.nctu.edu.tw/courses/ca_13/lecture/CA_lec08-chpater_4-vector_processing.pdf" target="_blank" rel="noopener">交通大學 Computer Architecture Lecture 8: Vector Processing</a></li><li><a href="https://www.slideshare.net/WeiTaWang/simd-109492525" target="_blank" rel="noopener">快快樂樂 SIMD</a></li></ul><p>photo credit from <a href="https://unsplash.com/photos/Uf-c4u1usFQ" target="_blank" rel="noopener">https://unsplash.com/photos/Uf-c4u1usFQ</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近強者我 Tead lead &lt;a href=&quot;https://www.facebook.com/champ.yen&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Champ Yen&lt;/a&gt; 在公司內部做了一次 experience sharing，內容
      
    
    </summary>
    
    
      <category term="gcc" scheme="http://kkc.github.io/tags/gcc/"/>
    
      <category term="performance" scheme="http://kkc.github.io/tags/performance/"/>
    
  </entry>
  
  <entry>
    <title>google 的 swisstable hashmap 筆記</title>
    <link href="http://kkc.github.io/2020/10/17/swisstable-hashmap-note/"/>
    <id>http://kkc.github.io/2020/10/17/swisstable-hashmap-note/</id>
    <published>2020-10-17T04:25:14.000Z</published>
    <updated>2020-10-17T04:31:32.426Z</updated>
    
    <content type="html"><![CDATA[<p>Matt Kulukundis 在 cppcon 2017 年給的 <a href="https://www.youtube.com/watch?v=ncHmEUmJZf4" target="_blank" rel="noopener">talk</a>，我覺得這個 talk 講得非常好，主要是說明如何使用 Swiss Tables ，設計出更符合當代硬體架構的 hash map (flat hash map)，google 內部大量採用這個改寫 std:unordered_map，我看完這個之後有點觀念被刷，覺得還蠻震驚的。</p><p> 這個 hash map 的實作考量到了 cache-friendly 以及透過 SIMD 來加速，主要讓我學習到的是，以往很多 hash map 實作使用 chaining 是因為在 load factor 很高的情況下，可以減少 key collision 改善插入的時間，而 flat hash map 則是告訴我們使用 open addressing，將 element 都放進一個 flat memory array 裡面，其實是 cache-friendly，另外是透過 SIMD 可以一步就知道結果，而不用在 透過好幾次的 cpu cycle 找資料，接著就可以在搜索上面得到巨大的加速。</p><p> 看到幾篇文章 <a href="https://gankra.github.io/blah/hashbrown-tldr/" target="_blank" rel="noopener">Swisstable, a Quick and Dirty Description</a> 把概念也講得蠻清楚的，也成功 port 這個 table 到 <a href="https://github.com/rust-lang/hashbrown" target="_blank" rel="noopener">Rust</a> 上面，稍微想了一下像這類的方法，Go 的架構因為要考慮 Runtime 還有沒有 Generics，似乎就比較難實作這塊，這邊有錯還請指正，</p><p> 總的來說 google 開源的 Abseil [1] 和 Rust stdlib [2] 都有採用這個的資料結構，不過還是要注意一下自己的資料長怎麼樣，還有 key 通過 hash function 後的 distribution，來找到適合自己使用的 hash  map。</p><p> 另外我現在才學習到有非常多 SIMD 的 algo，簡直是開了我的眼界，感覺還有非常多的東西可以使用這個加速，就讓我們再繼續看下去。</p><p>[1] <a href="https://github.com/abseil/abseil-cpp" target="_blank" rel="noopener">https://github.com/abseil/abseil-cpp</a><br>[2] <a href="https://github.com/rust-lang/hashbrown" target="_blank" rel="noopener">https://github.com/rust-lang/hashbrown</a><br>[3] <a href="https://rcoh.me/posts/hash-map-analysis/" target="_blank" rel="noopener">https://rcoh.me/posts/hash-map-analysis/</a><br>[4] <a href="https://www.youtube.com/watch?v=ncHmEUmJZf4" target="_blank" rel="noopener">https://www.youtube.com/watch?v=ncHmEUmJZf4</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Matt Kulukundis 在 cppcon 2017 年給的 &lt;a href=&quot;https://www.youtube.com/watch?v=ncHmEUmJZf4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;talk&lt;/a&gt;，我覺得這個 tal
      
    
    </summary>
    
    
      <category term="swisstable" scheme="http://kkc.github.io/tags/swisstable/"/>
    
      <category term="hashmap" scheme="http://kkc.github.io/tags/hashmap/"/>
    
  </entry>
  
  <entry>
    <title>Coscup sharing - How I contribute golang OSS</title>
    <link href="http://kkc.github.io/2020/09/21/coscup-sharing/"/>
    <id>http://kkc.github.io/2020/09/21/coscup-sharing/</id>
    <published>2020-09-21T13:09:40.000Z</published>
    <updated>2020-09-21T13:32:07.832Z</updated>
    
    <content type="html"><![CDATA[<p>Coscup is an annual conference held by Taiwan open source communities. This year, I participated in Coscup as a speaker and gave the talk about how I contribute golang OSS.  It’s a really good experience to give a talk at Coscup. Not only it’s a biggest open source feast in Taiwan but also you can learn and see a lot of passionate people in this conference. Although recent years you can hear a large amount of questions like What FOSS stands for? Some people consider different groups treat OSS from different purposes. More and more companies and people join and contribute OSS but some of them are for business reasons and some of them just want to gain more reputations. However, I still believe most of us just want to share good things with others. It’s also the reason why I like to join the communities.</p><p>Unlike last year, I gave a quite technical topic regarding CNCF project called Thanos. This year I tried to talk about how I participated in golang OSS project called <a href="https://github.com/kkdai/youtube" target="_blank" rel="noopener">YouTube</a>. One of most interesting thing is that at the end of my talk a lot of people come to ask me more details about this project. Things like how to create a PR properly, how to join an OSS without writing code. This makes me feel good because I potentially help some people get involved in contributing something.</p><iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRy5QXUd805bEuP760eYUQSSAuVqtAipz9zRAShikpOsPaNtwjHJCNCay9T0NZcB8r_0o2782HWhmKI/embed?start=false&loop=false&delayms=60000" frameborder="0" width="480" height="299" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe><p>Photo shoot by a friend<br><img src="./kakashi.jpg" alt="me"></p><p>Here is all the golang track videos and slides.  I highly recommend you guys to take a look at them.</p><ol><li><a href="https://www.youtube.com/watch?v=CDxDL8uyKQ0&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=54" target="_blank" rel="noopener">net &amp; http &amp; timeout by Hsueh-Tsung Kuo</a></li><li><a href="https://www.youtube.com/watch?v=SY1pMIs1ibw&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=55" target="_blank" rel="noopener">How to use Go channel correctly by Gaston Chiu</a></li><li><a href="https://www.youtube.com/watch?v=BhhG5B3Iqc4&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=56" target="_blank" rel="noopener">How the pitfalls of cgo and channels make reading messages from USB fail by lschyi</a></li><li><a href="https://www.youtube.com/watch?v=MVcWLd5YbMc&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=57" target="_blank" rel="noopener">Debug golang program with delve by Peter Lai</a></li><li><a href="https://www.youtube.com/watch?v=4rxMPYZdyHo&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=58" target="_blank" rel="noopener"> 談談 go 測試的二三事 by David Chou</a></li><li><a href="https://www.youtube.com/watch?v=57oYNEEOkGc&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=59" target="_blank" rel="noopener">Functional verification test framework with Go by Rain Wu</a></li><li><a href="https://www.youtube.com/watch?v=3uyiGO6a4qQ&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=60" target="_blank" rel="noopener">Goroutine stack and local variable allocation in Go by Cherie Hsieh</a></li><li><a href="https://www.youtube.com/watch?v=L9uJgYaepYs&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=61" target="_blank" rel="noopener"> 從零開始貢獻 Go 相關 open source project by kakashi</a></li><li><a href="https://www.youtube.com/watch?v=aVNOq3sbxEc&amp;list=PLqfib4St70XPWjZqmkE2auXM50140lgut&amp;index=62" target="_blank" rel="noopener">Go Go Power Slice! by Yu-Lang Chu</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Coscup is an annual conference held by Taiwan open source communities. This year, I participated in Coscup as a speaker and gave the talk
      
    
    </summary>
    
    
      <category term="golang" scheme="http://kkc.github.io/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>Linux 的 file descriptor 筆記</title>
    <link href="http://kkc.github.io/2020/08/22/file-descriptor/"/>
    <id>http://kkc.github.io/2020/08/22/file-descriptor/</id>
    <published>2020-08-22T14:29:10.000Z</published>
    <updated>2020-08-23T16:55:13.140Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h1><p> 說來慚愧，一直以來都在跟 Linux 打交道，也瞭解 <a href="https://en.wikipedia.org/wiki/Everything_is_a_file" target="_blank" rel="noopener">everything in unix is a file</a> 的概念，卻沒有真的好好理解 file descriptor 的基本結構是怎樣，但是在知乎上面看到這篇 <a href="https://zhuanlan.zhihu.com/p/34280875" target="_blank" rel="noopener">Linux file descriptor 演進史</a>，讓我對於他為什麼長這樣有更進一步的認識。(其實原本想找找英文資料，不過這篇講歷史的還蠻清楚的)</p><p>基本上這篇文章會筆記目前新版的 file descriptor 結構，也會延伸一些其他看到的資料，基於我對於 Linux kernel 並不是專家，如果有錯的地方希望大家能夠指正。</p><h1 id="file-descriptor"><a href="#file-descriptor" class="headerlink" title="file descriptor"></a>file descriptor</h1><p><a href="https://en.wikipedia.org/wiki/File_descriptor" target="_blank" rel="noopener">file descriptor</a> (fd) 基本上是一層介面，可以讓我們去操作 file 和其他 input/output interface (例如 pipe &amp; socket)。</p><h2 id="kernel- 內的基本結構"><a href="#kernel- 內的基本結構" class="headerlink" title="kernel 內的基本結構"></a>kernel 內的基本結構</h2><ul><li>每個 process 裡面包含 file descriptor 的 table。</li><li>file descriptor 其實只是個指標，指向系統層面 (system-wide) 的 openfile table 的 entry ，而這個 openfile table 在 Posix 裡面稱為 open file description。</li><li>fd_table 內的 inode_ptr 在去指向 i-node table 內的 entry。</li></ul><p>file descriptor 和 file 之間的關係並不是一對一的。<br><img src="./relationship.png" alt><br>圖從這個投影片來的 <a href="https://man7.org/training/download/lusp_fileio_slides.pdf" target="_blank" rel="noopener">lusp_fileio_slides.pdf</a>，另外要大推作者的書 <a href="https://man7.org/tlpi/index.html" target="_blank" rel="noopener">The Linux Programming Interface</a>，非常值得收藏</p><h2 id="對應的 -data-structure-source-code"><a href="# 對應的 -data-structure-source-code" class="headerlink" title="對應的 data structure source code"></a>對應的 data structure source code</h2><ol><li><p>process task_struct 裡面有 file_struct 成員，基本上需要從這個 file_struct 裡面找到對應的 file descriptor。file_struct 的成員原本是直接在 task_struct 內的，現在將它獨立起來，並用指標去存取，主要是因為 linux 在支援 thread 之後，需要以 task_struct 為 thread 單位，可以透過指標共用 file_struct 這種資源。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> &#123;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span> *<span class="title">files</span>;</span></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>files_struct 裡面可以找到 per process fdtable (file descriptor table)，其中使用了很厲害的 RCU 技術，主要是針對讀多寫少的情況下，提升存取寫入 fdtable 效能。<br>(struct fdtable in include/linux/fdtable.h)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">files_struct</span> &#123;</span></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * read mostly part</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="keyword">atomic_t</span> count;</span><br><span class="line"><span class="keyword">bool</span> resize_in_progress;</span><br><span class="line"><span class="keyword">wait_queue_head_t</span> resize_wait;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> __<span class="title">rcu</span> *<span class="title">fdt</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> <span class="title">fdtab</span>;</span></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * written part on a separate cache line in SMP</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="keyword">spinlock_t</span> file_lock ____cacheline_aligned_in_smp;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> next_fd;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> close_on_exec_init[<span class="number">1</span>];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> open_fds_init[<span class="number">1</span>];</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> full_fds_bits_init[<span class="number">1</span>];</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file</span> __<span class="title">rcu</span> * <span class="title">fd_array</span>[<span class="title">NR_OPEN_DEFAULT</span>];</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">fdtable</span> &#123;</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> max_fds;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file</span> __<span class="title">rcu</span> **<span class="title">fd</span>;</span>      <span class="comment">/* current fd array */</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> *close_on_exec;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> *open_fds;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> *full_fds_bits;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rcu_head</span> <span class="title">rcu</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li><li><p>open file table 也稱為 open file descriptions，是系統層級的 table (<a href="https://github.com/torvalds/linux/blob/master/include/linux/fs.h#L921)，這個" target="_blank" rel="noopener">https://github.com/torvalds/linux/blob/master/include/linux/fs.h#L921)，這個</a> struct 定義了一些蠻重要的資料像是 file_offset, file_status, 還有最重要的 inode_ptr 去指向對應的 inode。</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">file</span> &#123;</span></span><br><span class="line"><span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">llist_node</span><span class="title">fu_llist</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rcu_head</span> <span class="title">fu_rcuhead</span>;</span></span><br><span class="line">&#125; f_u;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">path</span><span class="title">f_path</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">inode</span>*<span class="title">f_inode</span>;</span>/* cached value *<span class="regexp">/</span></span><br><span class="line"><span class="regexp">const struct file_operations*f_op;</span></span><br></pre></td></tr></table></figure></li><li><p>open file table 在指向 system-wide 的 inode-table (<a href="https://github.com/torvalds/linux/blob/master/include/linux/fs.h#L615)，其中的" target="_blank" rel="noopener">https://github.com/torvalds/linux/blob/master/include/linux/fs.h#L615)，其中的</a> i_mode 就記錄了對應的是哪一種檔案類型。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">inode</span> &#123;</span></span><br><span class="line"><span class="keyword">umode_t</span>i_mode;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">short</span>  i_opflags;</span><br><span class="line"><span class="keyword">kuid_t</span>i_uid;</span><br><span class="line"><span class="keyword">kgid_t</span>i_gid;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span>i_flags;</span><br></pre></td></tr></table></figure></li></ol><h1 id="一些常見的 -fd- 操作"><a href="# 一些常見的 -fd- 操作" class="headerlink" title="一些常見的 fd 操作"></a>一些常見的 fd 操作</h1><ul><li>同一個 process 內通常透過 <code>dup()</code> or <code>dup2()</code> 可以複製 file descriptor，而兩個 fd 就可以指向同一筆 openfile entry (也就是同一個 file)</li><li>不同 process 透過 <code>fork()</code> 也會拿到各自的 file descriptor，去指向同一筆 openfile entry</li><li>不同 process 去開啟同一份檔案，會用各自的 file descriptor 指向不同的 openfile entry，但最後會指向同一份 inode</li></ul><h1 id="其他的經驗分享"><a href="# 其他的經驗分享" class="headerlink" title="其他的經驗分享"></a>其他的經驗分享 </h1><p> 在沒有了解 fd 的時候其實在寫程式上面犯了不少錯，像是在曾經在寫一個 socket programming 時，在 main process 內 fork child process ，但是卻沒有使用 close-on-exec flag ，所以把 main process 打開的 fd 也帶過去給 child，所以就算在 main process 去 close socket，對於那個被 child 抓住的 socket 還是沒被釋放，所以就看到前面的 LB 說後端的連線數量沒有下降，接著因為 rate limiting 的緣故，就把外面的連線給擋住了，而其實這時候後端還閒著很，這就是不熟悉 fd 行為而種下的雷，在理解了 fd 後，接著會再做一些筆記來談談 epoll &amp; scm_right 之類的東西怎麼運作的，了解 fd 對於我們寫程式真的蠻重要的啊!</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h1><ul><li><a href="https://man7.org/training/download/lusp_fileio_slides.pdf" target="_blank" rel="noopener">https://man7.org/training/download/lusp_fileio_slides.pdf</a></li></ul><p>圖片從<a href="https://unsplash.com/photos/o6GEPQXnqMY" target="_blank" rel="noopener">https://unsplash.com/photos/o6GEPQXnqMY</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h1&gt;&lt;p&gt; 說來慚愧，一直以來都在跟 Linux 打交道，也瞭解 &lt;a href=&quot;https://en.wikipedia.org/wiki/E
      
    
    </summary>
    
    
      <category term="linux" scheme="http://kkc.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux 5.1 的 io_uring</title>
    <link href="http://kkc.github.io/2020/08/19/io-uring/"/>
    <id>http://kkc.github.io/2020/08/19/io-uring/</id>
    <published>2020-08-19T15:11:06.000Z</published>
    <updated>2020-08-19T15:51:14.742Z</updated>
    
    <content type="html"><![CDATA[<p> 之前在 Facebook 上面分享不少技術文章的心得，被網友建議說可以放在 blog 上面，其實原本想在 blog 上面放一些比較長且整理過的東西，不過想想如果自己的心得能讓更多人看見，並且有機會交流也是不錯的事情，接下來應該會慢慢將之前的筆記謄過來。</p><p><a href="https://www.facebook.com/kkcliu/posts/10157179358206129" target="_blank" rel="noopener">https://www.facebook.com/kkcliu/posts/10157179358206129</a></p><h1 id="io-uring"><a href="#io-uring" class="headerlink" title="io_uring"></a>io_uring</h1><p> 前陣子在寫 epoll 文章的時候，剛好看到了一個討論串裡面談到 io_uring，其實原本沒聽過這個是什麼，後來查了一下才知道是新版的 Linux kernel 5.1 會加入這個 io_uring，主要目的是可以很好的改善原本 Linux native AIO 的問題，其實一般來說 AIO 的效能應該會比 epoll 還好，簡單一點的比較可以看 stackoverflow 上面寫的，<a href="https://stackoverflow.com/questions/5844955/whats-the-difference-between-event-driven-and-asynchronous-between-epoll-and-a" target="_blank" rel="noopener">https://stackoverflow.com/questions/5844955/whats-the-difference-between-event-driven-and-asynchronous-between-epoll-and-a</a></p><ul><li>epoll is a blocking operation (epoll_wait()) - you block the thread until some event happens and then you dispatch the event to different procedures/functions/branches in your code.</li><li>In AIO, you pass the address of your callback function (completion routine) to the system and the system calls your function when something happens.</li></ul><p> 簡單來說 epoll 是等待 event 發生，才去做事情，所以 epoll_wait 是個 blocking 的 operation，而 AIO 是把對應的 callback function 交給系統去做，算是真正的 asynchronous， Mysql 的 innodb 也是使用了 native linux AIO，但是看了下原生的 Linux AIO 有蠻多大大小小的問題，所以並不是真的太流行，這邊可以推薦大家看一下 cloudflare 這篇 <a href="https://blog.cloudflare.com/io_submit-the-epoll-alternative-youve-never-heard-about/" target="_blank" rel="noopener">https://blog.cloudflare.com/io_submit-the-epoll-alternative-youve-never-heard-about/</a> ， 有介紹怎麼使用 AIO，也提到 AIO 的一些問題，有趣的地方像是提到 Linus 對 AIO 的評價:</p><blockquote><p>AIO is a horrible ad-hoc design, with the main excuse being “other, less gifted people, made that design, and we are implementing it for compatibility because database people - who seldom have any shred of taste - actually use it”. But AIO was always really really ugly.</p></blockquote><p> 接著是又看到 Facebook 分享的 slides: <a href="https://www.slideshare.net/ennael/kernel-recipes-2019-faster-io-through-iouring" target="_blank" rel="noopener">https://www.slideshare.net/ennael/kernel-recipes-2019-faster-io-through-iouring</a> 和 Hackernews <a href="https://news.ycombinator.com/item?id=19843464" target="_blank" rel="noopener">https://news.ycombinator.com/item?id=19843464</a> 上面的介紹，最重要的是 performance 真的好上不少，從這邊 <a href="https://github.com/frevib/io_uring-echo-server/blob/io-uring-feat-fast-poll/benchmarks/benchmarks.md" target="_blank" rel="noopener">https://github.com/frevib/io_uring-echo-server/blob/io-uring-feat-fast-poll/benchmarks/benchmarks.md</a> ，可以找到 epoll vs io_uring 的 benchmark ，可以看出 io_uring 的效能可以快到 40% 以上。</p><p><img src="./benchmark.png" alt></p><p> 然後也看到很多不同的 project 像是 libuv, rust, ceph, rocksdb，正在討論或是進行 io_uring integration，這對 database &amp; cloud 相關的產業會有重大的影響，省下來的成本光用想的就很驚人，雖然要等到大家升到 5.1 不容易，但是越來越期待這個發展了。</p><p> 後記: 同事 Champ 大大有提點, Linux AIO 的問題是因為只能用在 DIRECT_IO 上面，所以對於很多程式來說，就沒辦法得到系統上面的 page cache 的好處，這也是為什麼 AIO 不好用的原因。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://kernel.dk/io_uring-whatsnew.pdf" target="_blank" rel="noopener">https://kernel.dk/io_uring-whatsnew.pdf</a></li><li><a href="https://github.com/agnivade/frodo" target="_blank" rel="noopener">https://github.com/agnivade/frodo</a></li><li><a href="https://github.com/hodgesds/iouring-go" target="_blank" rel="noopener">https://github.com/hodgesds/iouring-go</a></li><li><a href="https://lwn.net/Articles/776703/" target="_blank" rel="noopener">https://lwn.net/Articles/776703/</a></li><li><a href="https://www.slideshare.net/ennael/kernel-recipes-2019-faster-io-through-iouring" target="_blank" rel="noopener">https://www.slideshare.net/ennael/kernel-recipes-2019-faster-io-through-iouring</a></li></ul><p>Header photo is from <a href="https://unsplash.com/photos/1XgFFEG_RGA" target="_blank" rel="noopener">https://unsplash.com/photos/1XgFFEG_RGA</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 之前在 Facebook 上面分享不少技術文章的心得，被網友建議說可以放在 blog 上面，其實原本想在 blog 上面放一些比較長且整理過的東西，不過想想如果自己的心得能讓更多人看見，並且有機會交流也是不錯的事情，接下來應該會慢慢將之前的筆記謄過來。&lt;/p&gt;
&lt;p&gt;&lt;a
      
    
    </summary>
    
    
      <category term="linux" scheme="http://kkc.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Improve CPU Utilization of Go app By Using BPF</title>
    <link href="http://kkc.github.io/2020/06/05/improve-cpu-utilization-by-using-bpf/"/>
    <id>http://kkc.github.io/2020/06/05/improve-cpu-utilization-by-using-bpf/</id>
    <published>2020-06-05T13:43:24.000Z</published>
    <updated>2020-06-07T20:19:51.520Z</updated>
    
    <content type="html"><![CDATA[<p>In this post, I’d like to share an experience that how I used BPF to fix a CPU saturation issue in a Go app. Especially this CPU saturation issue happened in the cgo level so that it’s really hard to detect the root cause.</p><h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h1><p>A few months ago, I worked on cloud cost reduction and found out the CPU utilization of our streaming services kept 80% ~ 90% no matter how many clients connect to them. This is quite weird because normally the CPU utilization should be decreased when the total number of connections goes down. This also makes us not able to do further improvement like applying instance autoscaling according to different workloads.</p><h1 id="Triage"><a href="#Triage" class="headerlink" title="Triage"></a>Triage</h1><p>Usually, we should be able to use go built-in profiling tool <code>go tool pprof</code> to track the CPU or memory issues. However, because this Go program highly depends on a C library, I was afraid that the bottleneck would be in the C code.</p><p>I recently enjoyed watching Brendan Gregg’s BPF talks and thought if we can use it to solve this issue. If you are not familiar with BPF, there are tons of great talks you can find on the youtube:</p><ul><li><a href="https://www.youtube.com/watch?v=bj3qdEDbCD4" target="_blank" rel="noopener">Velocity 2017: Performance Analysis Superpowers with Linux eBPF</a></li><li><a href="https://www.youtube.com/watch?v=03EC8uA30Pw" target="_blank" rel="noopener">YOW! 2018 Brendan Gregg - Cloud Performance Root Cause Analysis at Netflix</a></li><li><a href="https://www.youtube.com/watch?v=fhBHvsi0Ql0" target="_blank" rel="noopener">LISA19 - Linux Systems Performance</a></li></ul><p><a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener">BCC</a> is a toolkit for BPF-based Linux analysis. BCC includes a lot of good tools helping us analyze the current system without writing the BPF program on our own. I’d highly recommend everyone should try to adopt some BCC tools because using those tools is so simple and useful.</p><p>In our case, I used <code>profile.py</code> to profile CPU usage. This profiling tool would take samples of stack tracing at certain timed intervals. It also provides a way to generate a popular Flamegraph format. The most interesting part is it can profile the running process by attaching a given PID. I thought this is really powerful when we need to investigate issues of the online system. I used the following command to generate the Flamegraph.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ./profile -df -p &lt;pid&gt; 5 &gt; out.profile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/brendangregg/FlameGraph</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ./FlameGraph/flamegraph.pl &lt; out.profile &gt; out.svg</span></span><br></pre></td></tr></table></figure><p>Here is what I got:</p><p><img src="./flamegraph.png" alt="flamegraph"></p><p>Before we dive into this chart, I want to note how to analyze this flamegraph. There are 2 important things when we observe flamegraph according to this book <a href="https://books.google.com.tw/books?id=iNS-DwAAQBAJ&amp;pg=PT73&amp;lpg=PT73&amp;dq=bpf+profile+overhead&amp;source=bl&amp;ots=SVM1q-uwoz&amp;sig=ACfU3U0nr5OXULNKPwdZ8b_pX8aY1DT0wg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjuzK_y9erpAhULyosBHf-_D3QQ6AEwA3oECAkQAg#v=onepage&amp;q=bpf%20profile%20overhead&amp;f=false" target="_blank" rel="noopener">Linux Observability with BPF</a>:</p><ul><li>The x-axis is ordered alphabetically. This represents the most frequent code consuming CPU in your system.</li><li>The y-axis shows the stack traces ordered as the profiler reads them, preserving the trace hierarchy.</li></ul><p>With this flame graph, it was now possible to see most CPU time spend on <code>epoll_wait</code>. Because it’s a streaming service, obviously it should adopt epoll to deal with many client connections efficiently. However, I didn’t expect this <code>epoll_wait</code> should be invoked so many times. I also try another BCC tool called <a href="https://github.com/iovisor/bcc/blob/master/tools/syscount_example.txt" target="_blank" rel="noopener">syscount</a> to count syscalls.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">syscount -<span class="selector-tag">p</span> &lt;my_progrom_pid&gt;</span><br></pre></td></tr></table></figure><p>I saw the result like this.</p><p><img src="./syscount.png" alt="syscount1"></p><p>Then I tried to use <code>strace -p &lt;my_program_pid&gt;</code> to observe what happened in that process. I did see a lot of epoll_wait invokations during process running as following.</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">epoll_wait(<span class="number">4</span>, [], <span class="number">1</span>, <span class="number">0</span>)                  = <span class="number">0</span></span><br><span class="line">epoll_wait(<span class="number">10</span>, [], <span class="number">1</span>, <span class="number">0</span>)                 = <span class="number">0</span></span><br><span class="line">epoll_wait(<span class="number">20</span>, [], <span class="number">1</span>, <span class="number">0</span>)                 = <span class="number">0</span></span><br><span class="line">epoll_wait(<span class="number">4</span>, [], <span class="number">1</span>, <span class="number">20</span>)                 = <span class="number">0</span></span><br><span class="line">epoll_wait(<span class="number">10</span>, [&#123;EPOLLIN, &#123;u32=<span class="number">5</span>, u64=<span class="number">140200617443333</span>&#125;&#125;], <span class="number">1</span>, <span class="number">50</span>) = <span class="number">1</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>I was so curious what’s the meaning of epoll_wait function arguments. I checked the <a href="https://www.man7.org/linux/man-pages/man2/epoll_wait.2.html" target="_blank" rel="noopener">man page</a> and realized the signature of that function.</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span>(<span class="params"><span class="keyword">int</span> epfd, <span class="keyword">struct</span> epoll_event *events, <span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout</span>)</span>;</span><br></pre></td></tr></table></figure><p>It looks to me that the field <code>timeout</code> could be the key to this problem so that I need to figure out the definition of timeout.</p><blockquote><p>Specifying a timeout of -1 causes epoll_wait() to block indefinitely, while specifying a timeout equal to zero cause epoll_wait() to return immediately, even if no events are available.</p></blockquote><p>This is really interesting. I soon went back to check our code. It turns out that the value of timeout is not a fixed number but generated by another function. This function acted too aggressively and set up timeout as 0 in most cases. We also double-checked epoll_wait mostly returned nothing when the timeout is 0. When you write the code using epoll, the pseudo-code might be like</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    n = epoll_wait(efd, events, MAXEVENTS, timeout);</span><br><span class="line">    <span class="keyword">if</span> (n &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">/* process activity */</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* process inactivity */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>That means when timeout value is 0, it will create a busy loop and CPU time spent on here for nothing.</p><h1 id="Fix"><a href="#Fix" class="headerlink" title="Fix"></a>Fix</h1><p>We did a quick small change to modify the timeout value to 1ms when the timeout value equals to 0. This change should reduce total number of invocation of that epoll_wait and following function blocks. We also deployed this fix both on the staging and production system to make sure video streaming still works smoothly. It was a remarkable moment when we saw the impact it had. We successfully reduced CPU usage from <code>6%</code> to <code>1%</code> on staging server. There was same trend on production services which improvement is around 30% to 70% deponed on different workloads.</p><p><img src="./fix1.png" alt="fix1"></p><p>After applying this fix, we tried to use <code>syscount</code> again to verify our system. As you can see the total number of epoll_wait is close to recvform, which means we save a lot of CPU time.</p><p><img src="./fix2.png" alt="fix2"></p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><ul><li>BPF is a really good tool that can help us quickly identify the potential root cause of the problem. The benefit of using BPF is it only introduces very small overhead on your system.</li><li><code>strace</code> is a very powerful tool too. Every programmer should learn how to use it. We can use <code>strace</code> to observe system call of your program on the fly which can give us a lot of information to understand how our program works.</li><li>Encourage everyone to try other bcc tools to observe the online system. It’s really fun!</li></ul><p>after I fixed this issues with BPF, my feeling is like</p><p><img src="./fly.jpg" alt></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.youtube.com/watch?v=bj3qdEDbCD4" target="_blank" rel="noopener">Velocity 2017: Performance Analysis Superpowers with Linux eBPF</a></li><li><a href="https://www.youtube.com/watch?v=03EC8uA30Pw" target="_blank" rel="noopener">YOW! 2018 Brendan Gregg - Cloud Performance Root Cause Analysis at Netflix</a></li><li><a href="https://www.youtube.com/watch?v=fhBHvsi0Ql0" target="_blank" rel="noopener">LISA19 - Linux Systems Performance</a></li><li><a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener">BCC tools</a></li><li><a href="https://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642" target="_blank" rel="noopener">https://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642</a></li><li><a href="https://jvns.ca/blog/2017/06/03/async-io-on-linux--select--poll--and-epoll/" target="_blank" rel="noopener">https://jvns.ca/blog/2017/06/03/async-io-on-linux--select--poll--and-epoll/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In this post, I’d like to share an experience that how I used BPF to fix a CPU saturation issue in a Go app. Especially this CPU saturati
      
    
    </summary>
    
    
      <category term="golang" scheme="http://kkc.github.io/tags/golang/"/>
    
      <category term="bpf" scheme="http://kkc.github.io/tags/bpf/"/>
    
      <category term="cgo" scheme="http://kkc.github.io/tags/cgo/"/>
    
  </entry>
  
  <entry>
    <title>AWS SSM session manager 筆記</title>
    <link href="http://kkc.github.io/2020/04/11/aws-ssm-session-manager-note/"/>
    <id>http://kkc.github.io/2020/04/11/aws-ssm-session-manager-note/</id>
    <published>2020-04-11T13:09:31.000Z</published>
    <updated>2020-04-11T13:58:41.497Z</updated>
    
    <content type="html"><![CDATA[<p>一直以來，如何登入到 AWS EC2 instance 就是個大問題，以往的方式都是在建立 Instance 的時候，設定其 <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html" target="_blank" rel="noopener">key pair</a> ，再把 private key 好好的保存下來，不過這個方式對於管理許多機器的人，其實是很煩人的，試問有多少人會乖乖的 rotate 機器上面的 key，而在有很多服務和機器的情況下，對於這些 key 的生命週期管理是非常重要的。</p><p>再者，在有些情況下，還是會見到把 EC2 instance 變成所謂的寵物機，然後見到一堆人的 key 被加入到 <code>.ssh/authorized_keys</code> 內，以便大家可以登入存取，這種方式讓我們更難的去顧到機器安全，在人員離開後，也不知道有沒有正確的把那些 key 拔掉。</p><p>通常來說，為了安全性，我們都會建立所謂的 Bastion host (跳板機) 還有 ip whitelist 及 VPN，去規範讓有權限的人去存取機器，不過不管是哪種方式也好，其實都增加了管理上的成本。</p><p>AWS 推出了 session manager 很好的幫我們解決了這個問題，而去年也推出了一些新服務，可以讓我們 <a href="https://aws.amazon.com/about-aws/whats-new/2019/07/session-manager-launches-tunneling-support-for-ssh-and-scp/" target="_blank" rel="noopener">scp</a> EC2 上面的檔案或是利用 <a href="https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/" target="_blank" rel="noopener">portforwarding</a> 的方式，讓我們從 local 機器測試 private VPC 內的服務，這篇筆記會列出該如何使用 session manager 以及相關的 IAM 設定。</p><h2 id="安裝"><a href="# 安裝" class="headerlink" title="安裝"></a>安裝 </h2><h3 id="Local-machine- 需求"><a href="#Local-machine- 需求" class="headerlink" title="Local machine 需求"></a>Local machine 需求</h3><p> 遵照 <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-prerequisites.html" target="_blank" rel="noopener"> 官方文件</a></p><ol><li>安裝最新版的 aws cli，版本需要大於等於 <code>1.16.12</code> 才能使用</li><li>安裝 <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html" target="_blank" rel="noopener">session manger plugin</a></li></ol><h3 id="EC2- 需求"><a href="#EC2- 需求" class="headerlink" title="EC2 需求"></a>EC2 需求 </h3><p> 預設 session manager 是沒有權限可以碰 EC2 的，需要修改 instance profile 和加裝 ssm agent。 </p><ol><li><p>Create an IAM instance profile for Systems Manager (<a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-instance-profile.html</a>)</p><ul><li>需要有 <code>AmazonSSMManagedInstanceCore</code> </li><li>另外可以參照 <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent-minimum-s3-permissions.html" target="_blank" rel="noopener">minimul s3 bucket permission</a> <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">     <span class="attr">"Action"</span>: [</span><br><span class="line">         <span class="string">"s3:GetObject"</span></span><br><span class="line">     ],</span><br><span class="line">     <span class="attr">"Resource"</span>: [</span><br><span class="line">         <span class="string">"arn:aws:s3:::aws-ssm-us-east-1/*"</span>,</span><br><span class="line">         <span class="string">"arn:aws:s3:::aws-windows-downloads-us-east-1/*"</span>,</span><br><span class="line">         <span class="string">"arn:aws:s3:::amazon-ssm-us-east-1/*"</span>,</span><br><span class="line">         <span class="string">"arn:aws:s3:::amazon-ssm-packages-us-east-1/*"</span>,</span><br><span class="line">         <span class="string">"arn:aws:s3:::us-east-1-birdwatcher-prod/*"</span>,</span><br><span class="line">         <span class="string">"arn:aws:s3:::patch-baseline-snapshot-us-east-1/*"</span></span><br><span class="line">     ]</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>確認 instance 上面都有安裝好 <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-manual-agent-install.html" target="_blank" rel="noopener">SSM agent</a>，AWS 上面新版的 ubuntu &amp; amazon linux2 都有先裝好了，不過舊的 AMI 就需要自己去安裝。  </p></li></ol><h2 id="使用者設定"><a href="# 使用者設定" class="headerlink" title="使用者設定"></a>使用者設定 </h2><p> 根據 <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/getting-started-restrict-access-quickstart.html" target="_blank" rel="noopener"> 文件</a>，設定 user 對應的 iam policy 權限，以下是個簡單的範例</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"Version"</span>: <span class="string">"2012-10-17"</span>,</span><br><span class="line">    <span class="attr">"Statement"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">            <span class="attr">"Action"</span>: [</span><br><span class="line">                <span class="string">"ssm:StartSession"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"Resource"</span>: [</span><br><span class="line">                <span class="string">"arn:aws:ec2:*:*:instance/*"</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">            <span class="attr">"Action"</span>: [</span><br><span class="line">                <span class="string">"ssm:DescribeSessions"</span>,</span><br><span class="line">                <span class="string">"ssm:GetConnectionStatus"</span>,</span><br><span class="line">                <span class="string">"ssm:DescribeInstanceProperties"</span>,</span><br><span class="line">                <span class="string">"ec2:DescribeInstances"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"Resource"</span>: <span class="string">"*"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">            <span class="attr">"Action"</span>: [</span><br><span class="line">                <span class="string">"ssm:TerminateSession"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"Resource"</span>: [</span><br><span class="line">                <span class="string">"arn:aws:ssm:*:*:session/$&#123;aws:username&#125;-*"</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>進階一點，我們可以使用 tag 去區別用戶能夠存取的環境，像是 staging or production</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"Version"</span>: <span class="string">"2012-10-17"</span>,</span><br><span class="line">    <span class="attr">"Statement"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">            <span class="attr">"Action"</span>: [</span><br><span class="line">                <span class="string">"ssm:StartSession"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"Resource"</span>: [</span><br><span class="line">                <span class="string">"arn:aws:ec2:*:*:instance/*"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"Condition"</span>: &#123;</span><br><span class="line">                <span class="attr">"StringLike"</span>: &#123;</span><br><span class="line">                    <span class="attr">"ssm:resourceTag/Environment"</span>: [</span><br><span class="line">                        <span class="string">"staging"</span></span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"Effect"</span>: <span class="string">"Allow"</span>,</span><br><span class="line">            <span class="attr">"Action"</span>: [</span><br><span class="line">                <span class="string">"ssm:TerminateSession"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"Resource"</span>: [</span><br><span class="line">                <span class="string">"arn:aws:ssm:*:*:session/$&#123;aws:username&#125;-*"</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>設定完以上的基本設定後，就可以透過下列的指令去登入機器</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ssm <span class="keyword">start</span>-<span class="keyword">session</span> <span class="comment">--target i-0b0d92751733d1234</span></span><br></pre></td></tr></table></figure><h2 id="使用 -scp"><a href="# 使用 -scp" class="headerlink" title="使用 scp"></a>使用 scp</h2><h3 id="設定"><a href="# 設定" class="headerlink" title="設定"></a>設定 </h3><p> 這邊筆記下如何透過 session manager 去達成 scp ，基本上透過 AWS 文件  <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-getting-started-enable-ssh-connections.html" target="_blank" rel="noopener">session-manager-getting-started-enable-ssh-connections</a> 上的描述，可以得知是利用 Proxycommand 透過 AWS tunnel 直接連接到我們的 EC2 機器上。</p><p>編輯 <code>~/.ssh/config</code> 並加入<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SSH over Session Manager</span></span><br><span class="line">host i-* mi-*</span><br><span class="line">    ProxyCommand sh -c <span class="string">"aws ssm start-session --target %h --document-name AWS-StartSSHSession --parameters'portNumber=%p'"</span></span><br></pre></td></tr></table></figure></p><p>就可以使用</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -<span class="selector-tag">i</span> -<span class="selector-tag">i</span> /path/my-key-pair<span class="selector-class">.pem</span> test123 ubuntu@i-<span class="number">0</span>b0d92751733d1234:~/test123</span><br></pre></td></tr></table></figure><p>注意這邊還是要利用一開始設定好的 key pair 去做連線。</p><h3 id="進階設定"><a href="# 進階設定" class="headerlink" title="進階設定"></a>進階設定 </h3><p> 上面提供的方法雖然可以讓我們使用 scp &amp; ssh，但是有點討厭的是還是得設定 EC2 機器的 key，那有沒有辦法繞過去呢? 答案是有的，只是需要透過一個比較 tricky 的方式。</p><p>網路上有人寫好了這個 proxy command 的 <a href="https://gist.github.com/qoomon/fcf2c85194c55aee34b78ddcaa9e83a1" target="_blank" rel="noopener">script</a>，使用的方式很簡單</p><ol><li>下載並且把這個 script 放到 <code>~/.ssh/aws-ssm-ec2-proxy-command.sh</code></li><li>修改 aws-ssm-ec2-proxy-command.sh 成為可以執行</li><li>修改 <code>~/.ssh/config</code> 裡面的指令</li></ol><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">host i-* mi-*</span><br><span class="line">  ProxyCommand ~/.ssh/aws-ssm-ec2-proxy-command.sh <span class="built_in">%h</span> <span class="built_in">%r</span> <span class="built_in">%p</span></span><br></pre></td></tr></table></figure><p>就不用在帶一把 key 去做認證了</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp test123 ubuntu<span class="meta">@i</span><span class="number">-0</span><span class="string">b0d92751733d1234:</span>~/test123</span><br></pre></td></tr></table></figure><p>其實原理很簡單，利用 <code>aws ec2-instance-connect send-ssh-public-key</code> 去建立一個 short-lived 的 key，這個指令詳細的好處可以看這篇 aws 文章 <a href="https://aws.amazon.com/blogs/compute/new-using-amazon-ec2-instance-connect-for-ssh-access-to-your-ec2-instances/" target="_blank" rel="noopener">new-using-amazon-ec2-instance-connect-for-ssh-access-to-your-ec2-instances</a>，接著再使用這把 key 透過原本的 start session 那條路連上遠端的 ec2 機器。</p><h2 id="Port-forwarding"><a href="#Port-forwarding" class="headerlink" title="Port forwarding"></a>Port forwarding</h2><p>這邊要再提供一個很有趣的方法，可以讓人透過 port forwarding 去連接 EC2 上面的服務，很多時候我們會把服務都放進 private subnet 內， 而 developer 想要測試這些 services 時，往往要利用 VPN 或是開一台在內網的 EC2 去連結，而使用 port forwarding 可以讓我們更容易地達成這個需求。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ssm start-session <span class="params">--target</span> i-0b0d92751733d1234 <span class="params">--document-name</span> AWS-StartPortForwardingSession <span class="params">--parameters</span> '&#123;<span class="string">"portNumber"</span>:[<span class="string">"80"</span>],<span class="string">"localPortNumber"</span>:[<span class="string">"9999"</span>]&#125;'</span><br></pre></td></tr></table></figure><p>這樣就可以透過 localhost:9999 去連結到 EC2 上面 service 的 80 port 了，詳細的內容也可以看這篇 AWS 的文章 <a href="https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/" target="_blank" rel="noopener">new-port-forwarding-using-aws-system-manager-sessions-manager</a></p><h2 id="Takeaway"><a href="#Takeaway" class="headerlink" title="Takeaway"></a>Takeaway</h2><ul><li>使用 session manger 可以減少 key 的管理，減少資安漏洞</li><li>透過 proxycommand 可以讓我們建立 ssh tunnel，進而可以使用 scp 等等工具</li><li>port forwarding 可以幫助 developer 測試在 private subnet 的服務</li><li>搭配 aws cliv2 可以透過 SSO 增加系統安全</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://www.youtube.com/watch?v=nzjTIjFLiow" target="_blank" rel="noopener">https://www.youtube.com/watch?v=nzjTIjFLiow</a></li><li><a href="https://www.youtube.com/watch?v=kj9NgFfUIHQ" target="_blank" rel="noopener">https://www.youtube.com/watch?v=kj9NgFfUIHQ</a></li><li><a href="https://aws.amazon.com/blogs/compute/new-using-amazon-ec2-instance-connect-for-ssh-access-to-your-ec2-instances/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/compute/new-using-amazon-ec2-instance-connect-for-ssh-access-to-your-ec2-instances/</a></li><li><a href="https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/aws/new-port-forwarding-using-aws-system-manager-sessions-manager/</a></li><li><a href="https://globaldatanet.com/blog/ssh-and-scp-with-aws-ssm" target="_blank" rel="noopener">https://globaldatanet.com/blog/ssh-and-scp-with-aws-ssm</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一直以來，如何登入到 AWS EC2 instance 就是個大問題，以往的方式都是在建立 Instance 的時候，設定其 &lt;a href=&quot;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>有關 Cache 的一些筆記</title>
    <link href="http://kkc.github.io/2020/03/27/cache-note/"/>
    <id>http://kkc.github.io/2020/03/27/cache-note/</id>
    <published>2020-03-27T03:58:07.000Z</published>
    <updated>2020-03-27T07:00:29.130Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h1><p> 最近看了 Amazon 的一篇文章 Caching challenges and strategies，在談論 cache 的種類，還有一些使用的邏輯和策略，剛好就想稍微整理一下有關於 cache 在分散式系統上面的一些筆記，這中間如果還有看到其他內容，還會再把它補起來，這邊強烈推薦大家看一下<a href="https://aws.amazon.com/builders-library/caching-challenges-and-strategies/" target="_blank" rel="noopener">AWS 原文</a>，還有筆記最後整理的一些 Reference，相信看完大家都可以學習到很多東西。</p><h1 id="何時使用 -Cache"><a href="# 何時使用 -Cache" class="headerlink" title="何時使用 Cache"></a>何時使用 Cache</h1><p>很多時候，我們會考慮加入的 Cache 的情況，不外乎就是想要加速系統的反應，或是降低 Backend 或是 Database 的負擔。而加入 Cache 往往也是一種挑戰，因為對於整個系統來說，每加入一個環節，其實都帶來了風險和複雜度，像是如果 Cache 整體 hit rate 不高，加入 Cache 也許只是讓 latency 更高，在伴隨著帶來的 Cache Availability, Cache Coherence 和 Cache Invalidation 的問題，都是我們要考慮有沒有必要使用 Cache 的關鍵。</p><h1 id="Cache- 的種類"><a href="#Cache- 的種類" class="headerlink" title="Cache 的種類"></a>Cache 的種類</h1><ol><li><p>Local cache</p><p> 簡而言之，就是使用系統上面的 Memory 作為 Cache，好處是隨手可得且複雜度低，但壞處是不同機器間的 Cache consistency 的問題，另外剛開機的時候也會有 cold start 的問題。</p></li><li><p>External cache</p><p> External cache 相信大家最熟的就是使用 Memcache &amp; Redis，這個可以解決機器間 Cache consistency 的問題，但還是有可能因為更新快取的方式失敗或錯誤，造成其他 consistency 的問題，另外是加入這個元件，就提升了系統複雜度，需要有另外的機制去監控和管理，還有 availibility 也是需要考量的點，在 exteranl cache 爆炸的時候，application 需要有能力去克服這個情況。</p></li></ol><h1 id="常見的 -external-cache- 的問題"><a href="# 常見的 -external-cache- 的問題" class="headerlink" title="常見的 external cache 的問題"></a>常見的 external cache 的問題 </h1><p> 這邊記錄下常見的 external cache 的問題還有解法</p><h2 id="Caching-Penetration"><a href="#Caching-Penetration" class="headerlink" title="Caching Penetration"></a>Caching Penetration</h2><p>如果同時間有大量的 requests 打到系統上，但是 cache 裡面沒有相對應的 key，這時候壓力就會全部灌在後端系統上(很可能是 database)，讓系統變得不穩定。</p><p>解決方案:</p><ol><li><p>cache empty data:<br> 對於空的資料，也把他們 cache 起來，一般來說只存 cache key 應該佔用的空間不大。</p></li><li><p>bloom filter:<br> 利用 <a href="https://www.evanlin.com/BloomFilter/" target="_blank" rel="noopener">bloom filter</a> 把一定不可能存在的 request filter 掉，減少 cache penetration 的機會。</p></li><li><p>observe access pattern:</p><p> 可以觀察下進來的 request pattern，要對 key 設定一些規範，如果 key 長的樣子不太對，就直接 filter 掉，或是看使用者是不是來掃 database 的，對於那種長期查詢不同值的 pattern 要有防範的方法。</p></li></ol><h2 id="Cache-avalanche"><a href="#Cache-avalanche" class="headerlink" title="Cache avalanche"></a>Cache avalanche</h2><p>Cache 雪崩，這通常發生在 cache 重啟當機，或是有大量的 cache 同時失效，此時，有大量的 requests 打進來落在 backend service 或是 database 上，如果 database 被打掛了，很有可能也沒辦法再開起來，因為會一直被大流量沖垮。</p><p>順帶一提，有時候會有大量 cache 同時失效，有可能是因為在 cache 開起來時，過期時間 (TTL) 都設定太過接近。</p><p>解決方案:</p><ol><li><p>Cache High Avalability<br> 第一個想法就是確保 Cache 元件也符合 HA，像是 redis 可以使用 cluster 的模式，避免 Cache 的單點當機造成的雪崩</p></li><li><p>Hystrix (circuit breaker, rate limit)<br> 這個解法是為了保護，當 Cache 大規模失效的時候，後端的壓力會得太巨大， 像是資料庫這種東西絕對不能讓他被沖垮，所以可以出動像是 Hystrix 之類的 rate limiter 元件做 <em> 降級 </em> 處理，只讓部分的 requests 流到後面去。</p></li><li><p>Expiry with different TTL<br> 讓 key 的 TTL 都盡量分散，可以減少同時並發打到 database 的壓力。</p></li></ol><p>以上的解法很可能需要混搭才是好的解法</p><h2 id="Cache-Stampede-Thundering-Herd-problem"><a href="#Cache-Stampede-Thundering-Herd-problem" class="headerlink" title="Cache Stampede (Thundering Herd problem)"></a>Cache Stampede (Thundering Herd problem)</h2><p>在 cache 裡面的某個 key，經常被大量存取，屬於 cache 的 hotspot，在 <em>cache miss</em> 的時候，requests 也會一口氣打到後端或是 database 上，這個也是屬於 cache invalidation 怎麼做的範疇。</p><p>舉個例子，像是某個熱門商品的 metadata 被放在 cache 上面，cache 失效時，如果同時有 1000 個人同時 request 這個產品，這些 request 就可能會一口氣打到 database 上面，讓 database 被衝垮。</p><p>解決方案:<br>    基本上的解法都可以在這篇 <a href="https://medium.com/@vaibhav0109/cache-stampede-problem-5eba782a1a4f" target="_blank" rel="noopener">What is Cache Stampede</a> 找到</p><ol><li><p><strong>Mutex (Locking)</strong></p><p> 有些文章會使用 request coalescing 這個詞，這邊達成這個的手段的方式就是利用 lock，讓同時間只有一個 request 可以存取 database 去更新 cache，使用 redis 可以用 setNX 或是 <a href="https://redis.io/topics/distlock" target="_blank" rel="noopener">distributed lock</a> 去產生這個鎖，但是使用 lock 時也要注意解鎖之類的問題。</p></li><li><p><strong>External Computation</strong></p><p> 使用外部的計算單元，像是用 cronjob 或是 worker + queue 的模式去更新 cache，來處理 cache invalidation 的問題，像是利用 worker 定期去掃 database 的表去更新 cache，或是利用 queue 去 trigger 更新，不過要注意如果類似掃 database 去更新的模式，有可能會存了很多不需要的資料在 cache 裡面。</p></li><li><p><strong>XFetch</strong></p><p> 這邊要提供第三種方法是出自一篇論文叫做 <a href="http://www.vldb.org/pvldb/vol8/p886-vattani.pdf" target="_blank" rel="noopener">Optimal Probabilistic Cache Stampede Prevention</a>，還有一份 slides <a href="https://www.slideshare.net/RedisLabs/redisconf17-internet-archive-preventing-cache-stampede-with-redis-and-xfetch" target="_blank" rel="noopener">redisconf17-internet-archive-preventing-cache-stampede-with-redis-and-xfetch</a> 講解，其實核心概念很簡單，就是在 cache 還沒過期前，提前讓 <em> 一個 worker</em> 去計算更新值和 TTL，這個方法會那麼高效，是因為不像方法一需要引入一個 lock。</p><p> 網路上也可以找不同語言的實作:</p><ul><li>golang(<a href="https://github.com/Onefootball/xfetch-go" target="_blank" rel="noopener">https://github.com/Onefootball/xfetch-go</a>)</li><li>rust(<a href="https://docs.rs/xfetch/1.0.0/xfetch/" target="_blank" rel="noopener">https://docs.rs/xfetch/1.0.0/xfetch/</a>)</li><li>ruby(<a href="https://github.com/Kache/xfetch" target="_blank" rel="noopener">https://github.com/Kache/xfetch</a>)</li></ul></li></ol><h1 id="更新 -Cache- 的正確姿勢"><a href="# 更新 -Cache- 的正確姿勢" class="headerlink" title="更新 Cache 的正確姿勢"></a>更新 Cache 的正確姿勢 </h1><p> 這也是一件常常被做錯的事情，但是還好網路上真的蠻多不錯的資料，我這邊就直接引用這篇 <a href="https://coolshell.cn/articles/17416.html" target="_blank" rel="noopener"> 缓存更新的套路</a>，來學習下正確的方式。</p><p>考慮到下面這個更新 cache 的策略，非常的直覺，就是沒東西在 Cache 的時候，就跑去 DB 拿資料再去更新 Cache。<br><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ttl = <span class="number">60</span></span><br><span class="line"><span class="keyword">val</span> := cache.Get(<span class="string">"key"</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">val</span> == nil &#123;</span><br><span class="line">    <span class="keyword">val</span> := db.Read(<span class="string">"key"</span>)</span><br><span class="line">    cache.Set(<span class="string">"key"</span>, <span class="keyword">val</span>, ttl)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">val</span></span><br></pre></td></tr></table></figure></p><p>乍看之下沒什麼問題，但是在並發情況下，有可能會有出乎意料之外的後果。</p><p><img src="https://i.imgur.com/a92yIer.png" alt></p><p>從這張圖可以看到最後 Cache 裡面拿到的也許是髒資料 (dirty cache data)，所以在 CoolShell 的文章裡面提到 Facebook 的論文 <a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" target="_blank" rel="noopener">《Scaling Memcache at Facebook》</a> 提出的方法是，在寫的時候去把 cache 裡面的值刪掉，然後靠讀的人去更新，雖然還是有可能會發生 dirty cache data，但是在不傷害效能的情況下，已經讓發生的機率下降許多。</p><h2 id="其他"><a href="# 其他" class="headerlink" title="其他"></a>其他</h2><ul><li>要觀察 Data 的生命週期，去調整 TTL，如果有些 Data 不太會更新，但是又經常被存取，可以把 TTL 調高一點，而反之亦然。</li><li>更新不頻繁，透過鎖讓 reader 去更新 cache 資料</li><li>更新頻繁，可以考慮透過 queue + worker 的方式去刷新 cache。</li></ul><h1 id="結語"><a href="# 結語" class="headerlink" title="結語"></a>結語 </h1><p> 其實寫這篇文章是幫助我刷新一下記憶，也是把書籤的文章都看過一輪，一般來說我們的 cache 部署通常是很多層的，類似從 browser -&gt; CDN -&gt; local cache -&gt; exteranl cache -&gt; database，所以很多地方都需要這些知識，而 cache coherence 不管在硬體軟體上面都是很經典的問題，了解這些可以幫助我們更好的去架構系統。</p><p>另外在過程中也查到了 Java 有 <code>Ehcache</code>，然後 <code>Memcache</code> 的作者也用 Go 寫了一套 <code>Groupcache</code>，都是可以利用本機上面的 Memory 來達成 Distributed cache 的功能，也是蠻推薦大家去看看學習，之後應該會來爬一下 <code>Groupcache</code> 的代碼。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://github.com/PegasusWang/system-design-primer#cache" target="_blank" rel="noopener">system-design-primer#cache</a></li><li><a href="https://medium.com/@mena.meseha/3-major-problems-and-solutions-in-the-cache-world-155ecae41d4f" target="_blank" rel="noopener">https://medium.com/@mena.meseha/3-major-problems-and-solutions-in-the-cache-world-155ecae41d4f</a></li><li><a href="http://lanlingzi.cn/post/technical/2018/0624_cache_design/" target="_blank" rel="noopener">http://lanlingzi.cn/post/technical/2018/0624_cache_design/</a></li><li><a href="https://www.zhihu.com/question/39114188" target="_blank" rel="noopener">https://www.zhihu.com/question/39114188</a></li><li><a href="https://docs.rs/xfetch/1.0.0/xfetch/" target="_blank" rel="noopener">https://docs.rs/xfetch/1.0.0/xfetch/</a></li><li><a href="https://medium.com/coinmonks/tao-facebooks-distributed-database-for-social-graph-c2b45f5346ea" target="_blank" rel="noopener">https://medium.com/coinmonks/tao-facebooks-distributed-database-for-social-graph-c2b45f5346ea</a></li><li><a href="https://segmentfault.com/a/1190000013686915" target="_blank" rel="noopener">缓存中的穿透、并发及雪崩</a></li><li><a href="https://www.mailgun.com/blog/golangs-superior-cache-solution-memcached-redis/" target="_blank" rel="noopener">Golang’s Superior Cache Solution to Memcached and Redis</a></li><li><a href="http://lanlingzi.cn/post/technical/2018/0624_cache_design/" target="_blank" rel="noopener">http://lanlingzi.cn/post/technical/2018/0624_cache_design/</a></li><li><a href="https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md" target="_blank" rel="noopener">https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-caching-avalanche-and-caching-penetration.md</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h1&gt;&lt;p&gt; 最近看了 Amazon 的一篇文章 Caching challenges and strategies，在談論 cache 的種類，還
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="backend" scheme="http://kkc.github.io/tags/backend/"/>
    
      <category term="redis" scheme="http://kkc.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>How I Analyze S3 Upload Latency Issues</title>
    <link href="http://kkc.github.io/2020/03/16/s3-latency/"/>
    <id>http://kkc.github.io/2020/03/16/s3-latency/</id>
    <published>2020-03-16T14:34:25.000Z</published>
    <updated>2020-03-17T03:01:19.617Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TLDR"><a href="#TLDR" class="headerlink" title="TLDR;"></a>TLDR;</h2><p>Recently I helped company to finish S3 bucket migration in order to improve image upload speed of our lambda function. I found out letting lambda function and S3 buckets located in the same region can reduce latency significantly. Because lambda function is charged by the length of execution time and memory size, it’s quite helpful by reducing S3 upload latency.</p><h2 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h2><p>This article aims to explain why I need to move our alert bucket from us-east-1 to us-west-2. Because one of our lambda function is the latency-sensitive application, I start digging out why uploading a 60kb image takes more than 600ms. Typically AWS should minimize the end to end latency between 2 regions by utilizing AWS backbone network so that we consider the situation shouldn’t be that bad. Here we perform serveral experiments to find the reason behind the scene.</p><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>We store all the alert images on us-east-1 S3 bucket because previously we run everything on us-east-1. However, most AWS outages happen in that region as AWS tends to roll out new services or features in that region frequently. We want to make our services become more robust so that we soon migrate most of our critical services to us-west-2 but leave our S3 bucket in us-east-1. We don’t notice the upload latency between our application to S3 has a huge difference until we observe our edge lambda function.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>As of 2020 March, we do several experiments with different configs (location and ssl setting) and summarize the result as this table.</p><table><thead><tr><th></th><th>SSL: false</th><th>SSL: true</th></tr></thead><tbody><tr><td>Lambda (us-east-1) → S3 (us-west-2)</td><td>300ms ~ 400ms</td><td>500ms ~ 550ms</td></tr><tr><td>Lambda (us-east-1) → S3 (us-east-1)</td><td>60ms ~ 120ms</td><td>60ms ~ 133ms</td></tr></tbody></table><h3 id="SSL-false"><a href="#SSL-false" class="headerlink" title="SSL: false"></a>SSL: false</h3><h4 id="Lambda-us-east-1-→-S3-us-west-2"><a href="#Lambda-us-east-1-→-S3-us-west-2" class="headerlink" title="Lambda (us-east-1) → S3 (us-west-2)"></a>Lambda (us-east-1) → S3 (us-west-2)</h4><p><img src="./1.png" alt="1"><br><img src="./2.png" alt="2"></p><h4 id="Lambda-us-east-1-→-S3-us-east-1"><a href="#Lambda-us-east-1-→-S3-us-east-1" class="headerlink" title="Lambda (us-east-1) → S3 (us-east-1)"></a>Lambda (us-east-1) → S3 (us-east-1)</h4><p><img src="./3.png" alt="3"><br><img src="./4.png" alt="3"></p><h3 id="SSL-true"><a href="#SSL-true" class="headerlink" title="SSL: true"></a>SSL: true</h3><h4 id="Lambda-us-east-1-→-S3-us-west-2-1"><a href="#Lambda-us-east-1-→-S3-us-west-2-1" class="headerlink" title="Lambda (us-east-1) → S3 (us-west-2)"></a>Lambda (us-east-1) → S3 (us-west-2)</h4><p><img src="./7.png" alt="7"><br><img src="./8.png" alt="8"></p><h4 id="Lambda-us-east-1-→-S3-us-east-1-1"><a href="#Lambda-us-east-1-→-S3-us-east-1-1" class="headerlink" title="Lambda (us-east-1) → S3 (us-east-1)"></a>Lambda (us-east-1) → S3 (us-east-1)</h4><p><img src="./5.png" alt="5"><br><img src="./6.png" alt="6"></p><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h2><p>We use python <code>boto3</code> to perform S3 uploading and enabled logging level DEBUG for better observing what happened during uploading.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup logging</span></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line">logger.setLevel(logging.INFO)</span><br><span class="line"></span><br><span class="line">def main(event, context):</span><br><span class="line">    logging.getLogger().setLevel(logging.DEBUG)</span><br><span class="line">    upload_to_alarm_bucket()</span><br><span class="line">    return</span><br></pre></td></tr></table></figure><h3 id="HTTPS-connection"><a href="#HTTPS-connection" class="headerlink" title="HTTPS connection"></a>HTTPS connection</h3><p>When we use <code>s3.put_object</code> to upload our data, you can see first of all our application should establish a new http connection.</p><p>When we upload a 30 kb image from us-east-1 to us-west-2, we found out it takes us 250ms to establish https connection! It’s quite weird but actually it makes sense.  Let’s take a look at AWS internal latency report from <a href="https://www.cloudping.co/" target="_blank" rel="noopener">https://www.cloudping.co/</a>. The p50 of round trip time between us-west-2 to us-east-1 is 81.35 ms.  Thus, according to this Cloudflare chart, establishing a new https connection needs to take 3 RTTs and it is roughly 240 ms. (80ms * 3)</p><p><img src="./cloudflare.png" alt="cloudflare https connection explaination"></p><h3 id="Wait-for-100-continue-response"><a href="#Wait-for-100-continue-response" class="headerlink" title="Wait for 100 continue response"></a>Wait for 100 continue response</h3><p>Another interesting thing is when we put a new object to S3, we will see this message <code>Waiting for 100 continue response</code>.  According to <a href="https://docs.amazonaws.cn/en_us/AmazonS3/latest/dev/RESTRedirect.html" target="_blank" rel="noopener">S3 document</a>, before we upload our data, server-side can do further check like authentication or redirection. Normally we should specify <code>Expect: 100-continue</code> on headers, and server will return 100 continue or 417 response. If we get the 100, we can continue uploading our data. If we get 417, we should stop uploading anything.</p><p>This 100 Continue response helps us avoiding send data twice or stop unnecessary uploading. However, one more RTT takes place here, and this also adds another 80ms to our latency.</p><p><img src="./100.png" alt="100"></p><h3 id="Dropped-connections"><a href="#Dropped-connections" class="headerlink" title="Dropped connections"></a>Dropped connections</h3><p>The last thing we wanna analyze is dropped connections. We all know that establishing https connection is quite expensive. Typically, we assume this won’t happen frequently because we usually adopt http <code>keep-alive</code> to avoid http connection recreation. Despite S3 SDK boto set keep-alive on header automatically, we still find out there are a lot of <code>resetting dropped connection</code> messages.  After searching this on stackoverflow, <a href="https://stackoverflow.com/questions/41860771/s3-connections-timing-out-quickly-in-python-2-7" target="_blank" rel="noopener">1</a>, <a href="https://stackoverflow.com/questions/28867840/why-do-i-constantly-see-resetting-dropped-connection-when-uploading-data-to-my" target="_blank" rel="noopener">2</a>, we understand that s3 server will drop idle <code>keep-alive</code> connections after few seconds. This may help s3 become more robust because:</p><ul><li>a lot of idle connections also consume tons of memory</li><li>others not able to connect to S3 due to the max connections limit.</li></ul><p><img src="./drop.png" alt="drop"></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>No matter how big is your data, choose the nearest S3 bucket for your application can help you reduce latency significantly.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://stackoverflow.com/questions/41860771/s3-connections-timing-out-quickly-in-python-2-7" target="_blank" rel="noopener">https://stackoverflow.com/questions/41860771/s3-connections-timing-out-quickly-in-python-2-7</a></li><li><a href="https://stackoverflow.com/questions/28867840/why-do-i-constantly-see-resetting-dropped-connection-when-uploading-data-to-my" target="_blank" rel="noopener">https://stackoverflow.com/questions/28867840/why-do-i-constantly-see-resetting-dropped-connection-when-uploading-data-to-my</a></li><li><a href="https://d1.awsstatic.com/whitepapers/AmazonS3BestPractices.pdf" target="_blank" rel="noopener">https://d1.awsstatic.com/whitepapers/AmazonS3BestPractices.pdf</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;TLDR&quot;&gt;&lt;a href=&quot;#TLDR&quot; class=&quot;headerlink&quot; title=&quot;TLDR;&quot;&gt;&lt;/a&gt;TLDR;&lt;/h2&gt;&lt;p&gt;Recently I helped company to finish S3 bucket migration in o
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="S3" scheme="http://kkc.github.io/tags/S3/"/>
    
  </entry>
  
  <entry>
    <title>Golang 10th Anniversary x GTG 45th 心得</title>
    <link href="http://kkc.github.io/2019/11/13/golang-meetup45/"/>
    <id>http://kkc.github.io/2019/11/13/golang-meetup45/</id>
    <published>2019-11-13T14:59:26.000Z</published>
    <updated>2019-11-13T15:47:18.861Z</updated>
    
    <content type="html"><![CDATA[<p><img src="./10th.jpeg" alt="10 週年"></p><p>上禮拜很開心可以參加 Golang 10th anniversary 的聚會，身為這次聚會的 co-organizer 加上贊助商，不但要參加 Golang 官方的行前會議，還有準備訂 Pizza 加上當講者，要做的事情真的是蠻多的，然後 Pizza 訂太少，讓晚來的同學沒有吃到，真的是蠻抱歉的，下次還有機會訂 Pizza 就知道該怎麼辦了。</p><p><img src="./pizza.jpeg" alt="Pizza"></p><p>這次聚會相關資料如下，之後有興趣參加的人可以先加 meetup 帳號:</p><ul><li>社群 Golang Taipei Gathering： <a href="https://www.meetup.com/golang-taipei-meetup" target="_blank" rel="noopener">https://www.meetup.com/golang-taipei-meetup</a></li><li>本次活動網頁: <a href="https://www.meetup.com/golang-taipei-meetup/events/264921214/" target="_blank" rel="noopener">活動網址</a></li></ul><h2 id="How-I-become-Go-GDE"><a href="#How-I-become-Go-GDE" class="headerlink" title="How I become Go GDE"></a>How I become Go GDE</h2><p><img src="./evan.jpeg" alt="evan"></p><p><a href="https://blog.golang.org/10years" target="_blank" rel="noopener">十週年 </a> 聚會一開始就是 Golang 社群的扛霸子 Evan 大大主講，然後給的題目我覺得真的很適合十週年聚會，告訴大家了 Golang 這十年來的發展，還有 Evan 為什麼會接觸 Golang ，而其實我會學習 Golang 其實或多或少跟 Evan 也有關係，大概也是五年前，看到 Evan 在開 <a href="https://pdos.csail.mit.edu/6.824/" target="_blank" rel="noopener">MIT 6.824</a> 的讀書會時，所使用到的語言，接下來也是越來越多 infra 相關的 tool，像是 etcd, docker, k8s, terraform 等等都是用 Golang 開發的，讓我也對這個語言有了很大的興趣。</p><p>然後 Evan 也分享了他的學習過程與方法，寫部落格和分享大概是我從 Evan 身上學到最多的東西，雖然值和量還遠遠不及啊（抱頭），但是真的透過分享和寫作，可以把自己不熟悉的地方重複思考，因為真的是很怕講錯或是寫錯，這樣一來就有機會窺探自己的盲點。</p><p>投影片:</p><p><iframe src="//www.slideshare.net/slideshow/embed_code/key/iBL48fizlti9dZ" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/EvansLin/golang-taipei-45-10th-birthday" title="Golang taipei #45 10th birthday" target="_blank">Golang taipei #45 10th birthday</a> </strong> from <strong><a href="https://www.slideshare.net/EvansLin" target="_blank">Evan Lin</a></strong> </div></p><h2 id="Understanding-real-world-concurrency-bugs-in-go"><a href="#Understanding-real-world-concurrency-bugs-in-go" class="headerlink" title="Understanding real world concurrency bugs in go"></a>Understanding real world concurrency bugs in go</h2><p><img src="./kakashi.jpeg" alt="kakashi"></p><p>我給的 talk 主要是想跟大家聊聊一篇 <a href="https://songlh.github.io/paper/go-study.pdf" target="_blank" rel="noopener"> 論文</a> 的內容，他將 Golang 裡面的 bugs 分為 blocking &amp; non-blocking 兩種，並且給出結論是， Golang 的語法或是 practice ，不一定比傳統 mutex 的方式少 blocking 的 bugs，而在 non-blocking 的 bugs 上面，的確會少許多，並且給出了一些真實世界的範例，而這些範例都出自於很熱門的 open source project 像是 Docker, Kubernetes, etcd ，其實我對於讀那些 Bugs 比較有興趣，可以看到有些其實是不熟 Golang 語法而產生的，而這些 Bugs，又是在一般情況下，不太容易被走到的 path，從這些 Bugs 中，我們可以學習到很多有可能會犯錯的場景，相關的內容可以看我的投影片或是到論文的 <a href="https://github.com/system-pclub/go-concurrency-bugs" target="_blank" rel="noopener">GitHub repo</a> 找，很推薦大家去讀。</p><p>投影片:</p><p><iframe src="//www.slideshare.net/slideshow/embed_code/key/zqstqPzCiwSA6H" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/kakashiliu/understanding-real-world-concurrency-bugs-in-go-191283124" title="Understanding real world concurrency bugs in go (fixed)" target="_blank">Understanding real world concurrency bugs in go (fixed)</a> </strong> de <strong><a href="https://www.slideshare.net/kakashiliu" target="_blank">cc liu</a></strong> </div></p><h2 id="小結"><a href="# 小結" class="headerlink" title="小結"></a>小結 </h2><p>Golang meetup 也辦到第 45 場了，而且這次還上了 meetup Twitter 的<a href="https://twitter.com/Meetup/status/1193528748857024512" target="_blank" rel="noopener"> 推</a>，感覺真的是蠻棒的，希望台灣有越來越多寫 Golang 的人和公司，然後透過社群來一起學習，另外真心期望明年能夠把 GopherCon 辦成，接下來會更專心的來找贊助的機會，希望大家能多多支持摟。</p><p><img src="./gophercon.jpeg" alt="gophercon"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;./10th.jpeg&quot; alt=&quot;10 週年&quot;&gt;&lt;/p&gt;
&lt;p&gt;上禮拜很開心可以參加 Golang 10th anniversary 的聚會，身為這次聚會的 co-organizer 加上贊助商，不但要參加 Golang 官方的行前會議，還有準備訂 P
      
    
    </summary>
    
    
      <category term="golang" scheme="http://kkc.github.io/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>Coscup 分享 - HA Prometheus Solution Thanos</title>
    <link href="http://kkc.github.io/2019/08/22/coscup-ha-prometheus-solution-thanos/"/>
    <id>http://kkc.github.io/2019/08/22/coscup-ha-prometheus-solution-thanos/</id>
    <published>2019-08-22T02:23:55.000Z</published>
    <updated>2019-09-17T02:51:20.019Z</updated>
    
    <content type="html"><![CDATA[<p> 上個月參加了 Coscup，完成了我的 Coscup 講者處女秀，對比三年前當主持人，其實當講者輕鬆了不少，而且看到很多熟面孔的感覺非常好。</p><p> 這次參加的 SDN x Cloud Native x Golang 議程軌，其實有非常多的好主題，而我也分享了一個跟 CNCF &amp; Golang 有相關的 Opensource Project - Thanos，Thanos 主要就是為了解決 Prometheus 的 Global View &amp; High Availability &amp; Long-term storage 的問題，一直以來 Prometheus 作為 Cloud Native 主要監控元件，在經過社群的努力下，其實以單台 Prometheus 而言，效能和儲存效率上已經獲得很大的改善，目前是非常成熟的方案，但是在談到在部署多個 Prometheus 的情況時，往往會遇到一些問題像是，如何透過 PromQL Query 不同台的 Prometheus 並且 aggregate/merge 其中的資料，另外是 long-term storage 的問題，像是如何將歷史資料保存起來，而不是只有寫在 Prometheus 單體的 SSD 上面，這幾個問題就造就了 Thanos, Cortex, Uber M3 等等 Opensource 的存在。</p><h2 id="HA-prometheus-solution-Thanos"><a href="#HA-prometheus-solution-Thanos" class="headerlink" title="HA prometheus solution - Thanos"></a>HA prometheus solution - Thanos</h2><p> 我的投影片分享如下 <br><a href="https://docs.google.com/presentation/d/1KBs4FxYwFL6dsz_JUbPK4ZiKXYjsaLZI21VgVLI54I4" target="_blank" rel="noopener">https://docs.google.com/presentation/d/1KBs4FxYwFL6dsz_JUbPK4ZiKXYjsaLZI21VgVLI54I4</a></p><p> 前面幾頁就在講解單體 Prometheus 的問題，而就算使用了 Federate 之後，這個架構還是會有其他的問題，像是資料會被重複儲存在兩個地方，還有被拉取的 Prometheus 機器時也有可能發生 timeout 而很多情況下我們可能不會把所有的東西都拉到該機器上，另外壓力都會落在 Federate 起來的那台機器上面，這樣一來又還是需要到個別的 Prometheus 機器上面去做 Query，造成很多管理上面的不便。</p><p> 而 Thanos 主要實現了三個願望 </p><ul><li>Have a global view</li><li>Have an HA in place</li><li>Unlimited retention</li></ul><h3 id="Global-View-amp-HA"><a href="#Global-View-amp-HA" class="headerlink" title="Global View &amp; HA"></a>Global View &amp; HA</h3><p><img src="./ha.png" alt="img"><br><img src="./ha2.png" alt="img"></p><p> 可以看這張圖比較下使用 Thanos 取代 Prometheus Federate，基本上 Thanos 使用 Sidecar Pattern，就算你有既有的 Prometheus 正在跑著，也可以透過 Sidecar 這個元件去做讀取，Querier 這個元件使用了 Thanos 定義的 StoreAPI 從 Sidecar 中讀取資料，Querier 裡面有 Deduplicate 和 Merge 的功能，所以也不用怕資料散在不同的 Promethues 上面，Deduplicate 主要是可以透過 Label 去認出相同的資料，這樣就不會重複把同一條線畫出來。</p><p> 透過這種架構，可以很輕鬆的達成 HA，開兩台 Prometheus 去撈取資料，就算一台 Prometheus 掛掉，Thanos Querier 還是可以讀取其中一台，然後兩台都活著的時候， Deduplicate 可以將資料去重。</p><h3 id="Unlimited-Retention"><a href="#Unlimited-Retention" class="headerlink" title="Unlimited Retention"></a>Unlimited Retention</h3><p><img src="./retention.png" alt="img"><br><img src="./retention2.png" alt="img"></p><p>Thanos 實現 Umlimited Retention 的方式也相當的簡單，就是利用 Sidecar 把 Prometheus 裡面的 Block 讀出來寫到 Object Storage，然後再提供一個 Store 的元件，用來讀取 Object Storage 裡面的 Blocks，這邊很聰明的地方就是 Querier 都是透過 StoreAPI 去做讀取，這個介面一致化後，其實讓 Thanos 變得相當有彈性。</p><p> 這邊要寫一下要注意的地方，就是 Prometheus 其實預設是每兩個小時才會把 Memory 裡面的 Block 寫進 local storage，之後 Thanos Sidecar 才有機會將其上傳到 block storage，如果在中途你的 Prometheus crush 了，這樣就會有兩個小時的資料遺失了，所以 Thanos 官網上面其實是建議 Prometheus 如果跑在 k8s 上面，最好是掛著專屬的 PVC，這樣 Prometheus 回來的時候，還可以透過 WAL 回復資料。另外一個雷是 Prometheus 原本 Remote Read 沒有提供 Steaming 的格式，而 Sidecar 在讀取的時候，如果拉了一個 range 超大的資料，會造成 Prometheus OOM，而這個問題也在上個月的這個 <a href="https://github.com/prometheus/prometheus/commit/48b2c9c8eae2d4a286d8e9384c2918aefd41d8de" target="_blank" rel="noopener">PR</a> 解決惹。</p><h2 id="Other-Components"><a href="#Other-Components" class="headerlink" title="Other Components"></a>Other Components</h2><p> 基本上使用 Querier, Sidecar, 還有 Store 就可以完成很多的事情，但其實 Thanos 還有提供更多的功能，這邊我介紹了 Compactor 和 Ruler。</p><h3 id="Compactor"><a href="#Compactor" class="headerlink" title="Compactor"></a>Compactor</h3><p><img src="./compactor.png" alt="img"></p><p>Prometheus 的 TSDB 在改寫後，就有提供 Compaction (壓縮) 的功能，基本上就是把 Memory 裡面的資料，透過 delta-of-data &amp; XOR 的方式壓縮，這裡面參考了 Facebook 2015 年發表的論文 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.718.197&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">&lt;Gorilla: A Fast, Scalable, In-Memory Time Series DataBase&gt;</a>，有興趣的人可以看看，而透過這種壓縮方式，Prometheus 可以輕易地儲存很多的 series 以及保存很長的一段時間，而 Thanos compactor 乍看之下好像沒什麼用處，但其實它復用了 Prometheus 的 compactor library，並且在上面擴展了 Downsampling 的功能，也就是將這些 Blocks aggregate 成 5mins 和 1 hours，這樣的做法，可以讓讀取長時間的資料時，可以更快的取出資料，使用的 memory 也會變少，舉例來說，你想要看個半年的資料時，其實沒必要看到 raw data 那麼小的 resolution，其實只要透過 1hours 的資料就可以反推出趨勢，另外 Compactor 會幫忙管理資料的刪除，透過一個 Compactor 管理移除 Block Storage 的資料，其實也是比較好的做法。</p><p> 不過在使用 Compactor 時，其實也有一個雷，就是要把 Prometheus 上面的 Compaction 關閉，要不然 Thanos 的 Compactor 還需要多做一步將資料還原才能做 Downsampling。</p><h3 id="Ruler"><a href="#Ruler" class="headerlink" title="Ruler"></a>Ruler</h3><p><img src="./ruler.png" alt="img"></p><p>Ruler 這個元件其實是為了擴展 Alertmanager 而用的，因為使用 Thanos 後，在設定 Prometheus 上，可能會把超過 2 小時的 Block 儲存到 Block Storage 上，然後把 Prometheus 自身的 Retention 關小，如此一來你在 Prometheus 上面設定的 Alert rule 如果觀察的趨勢是超過 2 小時的，就很有可能會失效，另外是在 Query 不同 Cluster 上面，就沒辦法設定一個 Rule 去覆蓋所有的 Cluster，Ruler 給了我們這樣的彈性，可以將 Alert rules 都集中給 Ruler 管理。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p> 在投影片中，我還有列舉了一些官網上面建議的部署模式，可以看到 Thanos 也支援一些複雜的情境，然後其實已經有蠻多大公司都用在 Production 上面，所以算是一個成熟的方案，蠻推薦大家可以玩玩看。</p><p>Thanos 在七月的時候，也被捐出來給 CNCF，正式成為 CNCF Sandbox 的專案，有了更多資源後，我們可以預期他會越來越好用，社群的人解 issues 和 feedback 的速度也很快，有心玩 golang open source 的人，我覺得 Thanos 是蠻好的一個專案。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 上個月參加了 Coscup，完成了我的 Coscup 講者處女秀，對比三年前當主持人，其實當講者輕鬆了不少，而且看到很多熟面孔的感覺非常好。&lt;/p&gt;
&lt;p&gt; 這次參加的 SDN x Cloud Native x Golang 議程軌，其實有非常多的好主題，而我也分享了一個
      
    
    </summary>
    
    
      <category term="Prometheus" scheme="http://kkc.github.io/tags/Prometheus/"/>
    
      <category term="Thanos" scheme="http://kkc.github.io/tags/Thanos/"/>
    
      <category term="CNCF" scheme="http://kkc.github.io/tags/CNCF/"/>
    
  </entry>
  
  <entry>
    <title>Performance tweaking for fluentd aggregator (EFK stack)</title>
    <link href="http://kkc.github.io/2019/05/02/ultimate-note-for-tweaking-fluentd-aggregator/"/>
    <id>http://kkc.github.io/2019/05/02/ultimate-note-for-tweaking-fluentd-aggregator/</id>
    <published>2019-05-02T10:03:09.000Z</published>
    <updated>2020-05-07T07:55:07.126Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>Logging is one of the critical components for developers. Every time when things went wrong, we had no doubt but checked what’s going on in logs. <code>Fluentd</code> is an open source data collector solution which provides many input/output plugins to help us organize our logging layer. There are tons of articles describing the benefits of using <code>Fluentd</code> such as buffering, retries and error handling. In this note I don’t plan to describe it again, instead, I will address more how to tweak the performance of <code>Fluentd</code> aggregator. Especially the case I use the most when fluentd talks to elasticsearch.</p><p>The typical way to utilize fluentd is like the following architecture. We can use sidecar fluentd container to collect application logs and transfer logs to fluentd aggregator. By adopting sidecar pattern, fluentd will take care of error handling to deal with network transient failures. Moreover, our application can write logs asynchronously to fluentd sidecar which prevents our application from being affected once remote logging system becomes unstable.</p><p><img src="https://docs.fluentd.org/images/fluentd_ha.png" alt="img"></p><p>To understand more benefits, I suggest you guys take a look at this <a href="https://www.youtube.com/watch?v=aeGADcC-hUA" target="_blank" rel="noopener">youtube video</a> which gives a really great explanation. </p><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>Since many fluentd sidecars write their logs to fluentd aggregator, soon or later you will face some performance issues. For example, if our aggregator attempts to write logs to elasticsearch, but the write compacity of elasticsearch is insufficient. Then you will see a lot of 503 returns from elasticsearch and fluetnd aggregator has no other choices but keep records in the local buffer (in memory or files). The worst scenario is we run out of the buffer space and start dropping our records. There are 2 possible solutions comes to my mind to tackle this situation:</p><ol><li>Increase the size of elasticsearch, though it’s easy for me to change elasticsearch size (yes, I use AWS managed elasticsearch), this makes us spend more money on elasticserach nodes.</li><li>Tweak the fluentd aggregator parameters to see if we can improve the bottleneck.</li></ol><p>So before I increase elasticsearch node size, I tend to try option 2 to see how much performance can be improved by tuning the parameters.</p><h2 id="Understand-Buffer-plugin"><a href="#Understand-Buffer-plugin" class="headerlink" title="Understand Buffer plugin"></a>Understand Buffer plugin</h2><p><img src="./architecture.png" alt="400x400"></p><p>This picture borrowed from this <a href="https://www.slideshare.net/tagomoris/fluentd-overview-now-and-then" target="_blank" rel="noopener">official slides</a>. Let’s see how fluentd work internally. Here we only focus on input &amp; buffer </p><h3 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h3><p>When messages come in, it would be assigned a <code>timestamp</code> and a <code>tag</code>. Messages itself is wrapped as a<code>record</code> which is structured JSON format. <code>timestamp</code> + <code>tag</code> + <code>record</code> is called <code>event</code>.</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Timestamp:</span> <span class="number">2019</span><span class="number">-05</span><span class="number">-04</span> <span class="number">01</span>:<span class="number">22</span>:<span class="number">12</span></span><br><span class="line"><span class="symbol">Tag:</span> app.production</span><br><span class="line"><span class="symbol">Record:</span> &#123;</span><br><span class="line"><span class="string">"path"</span>: <span class="string">"/api/test"</span>,</span><br><span class="line"><span class="string">"user"</span>: <span class="string">"john"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><p><img src="https://docs.fluentd.org/images/fluentd-v0.14-plugin-api-overview.png" alt="400x400"></p><p>According to the document of fluentd, buffer is essentially a set of chunk.  Chunk is filled by incoming <code>events</code> and is written into file or memory. Buffer actually has 2 stages to store chunks. These 2 stages are called <code>stage</code> and <code>queue</code> respectively. Typically buffer has an <code>enqueue thread</code> which pushes chunks to queue. Buffer also has a <code>flush thread</code> to write chunks to destination.</p><h4 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h4><p><code>chunk</code> is allocated and filled in the <code>stage</code> level. Here we can specify some parameters to change the behavior of allocation and flushing.</p><ol><li><code>chunk_limit_size</code> decides max size of each chunks</li><li><code>chunk_limit_records</code> the max number of events that each chunks have</li><li><code>flush_interval</code> defines how often it invokes <code>enqueue</code>, this only works when <code>flush_mode</code> being set to <code>interval</code></li></ol><p>The <code>enqueue thread</code> will write chunk to queue based on the size and flush interval so that we can decide if we care more about latency or throughput (send more data or send data more frequent).</p><h4 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h4><p><code>queue</code> stores chunks and <code>flush thread</code> dequeues chunk from queue.</p><ol><li><code>flush_thread_count</code>: we can launch more than 1 <code>flush thread</code>, which can help us flush chunk in parallel.</li><li><code>flush_thread_interval</code> define interval to invoke flush thread</li><li><code>flush_thread_burst_interval</code> if buffer queue is nearly full, how often flush thread will be invoked.</li></ol><p>Typically we will increase <code>flush_thread_count</code> to increase throughput and also deal with network transient failure. see <a href="https://github.com/uken/fluent-plugin-elasticsearch#suggested-to-increase-flush_thread_count-why" target="_blank" rel="noopener">https://github.com/uken/fluent-plugin-elasticsearch#suggested-to-increase-flush_thread_count-why</a></p><h4 id="Other-parameters"><a href="#Other-parameters" class="headerlink" title="Other parameters"></a>Other parameters</h4><ul><li><code>total_limit_size</code> total buffer size (chunk size + queue size)</li><li><code>overflow_action</code> when buffer is full, what kind of action we need to take</li></ul><h4 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h4><p>Buffer plugin is extremely useful when the output destination provides bulk or batch API. So that we are able to flush whole <code>chunk</code> content at once by using those APIs instead of sending request multiple times. It’s the secret why many fluetnd output plugins make use of buffer plugins. For understanding the further detail, I suggest you guys go through the <a href="https://github.com/fluent/fluentd/blob/master/lib/fluent/plugin/output.rb" target="_blank" rel="noopener">source code</a>.</p><h2 id="Tweaking-elasticsearch-plugins"><a href="#Tweaking-elasticsearch-plugins" class="headerlink" title="Tweaking elasticsearch plugins"></a>Tweaking elasticsearch plugins</h2><p>After we understand how important buffer plugins is, we can go back to see how to tweak our elsticsearch plugin. For our use case, I try to collect logs as much as possible with small elasticsearch node.</p><p>The initial setting is like</p><figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">buffer</span>&gt;</span><br><span class="line">  @file</span><br><span class="line">  path /fluentd/<span class="built_in">log</span>/<span class="keyword">buffer</span></span><br><span class="line"></span><br><span class="line">  <span class="meta"># chunk + enqueue</span></span><br><span class="line">  flush_mode interval</span><br><span class="line">  flush_interval <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">  flush_thread_count <span class="number">2</span></span><br><span class="line">  retry_type exponential_backoff</span><br><span class="line">  retry_timeout <span class="number">1</span>h</span><br><span class="line">  overflow_action drop_oldest_chunk</span><br><span class="line">&lt;/<span class="keyword">buffer</span>&gt;</span><br></pre></td></tr></table></figure><p>The problem is that chunk fluentd collects is too small which lead to invoke too many elasticsearch write APIs. This also makes fluend queues many chunks in the disk due to fail requests of elasticsearch.</p><p>From AWS ES <a href="https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-limits.html" target="_blank" rel="noopener">doc</a> we know that the http payload varies with different instance type. The maximum size of HTTP request payloads of most instance type is 100MB. Thus we should make our chunk limit size bigger but less than 100MB. Plus we should increase the flush_interval so that fluentd is able to create big enough chunk before flushing to queue. Here we also adjust flush_thread_count depending on elasticsearch plugin suggestion.</p><p>The modified version:</p><pre><code>&lt;buffer&gt;      @file      path /fluentd/log/buffer      total_limit_size 1024MB      # chunk + enqueue    chunk_limit_size 16MB    flush_mode interval    flush_interval 5s    # flush thread    flush_thread_count 8    retry_type exponential_backoff    retry_timeout 1h    retry_max_interval 30    overflow_action drop_oldest_chunk&lt;/buffer&gt;</code></pre><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><p>After I change the setting, fluentd aggregator no longer complains about the insertion errors and drops the oldest chunks.<br>As you can see the following pictures show the memory usage drops dramatically so that it proves that fluentd works perfectly.</p><p><img src="./before.png" alt></p><p><img src="./after.png" alt></p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li><a href="https://www.youtube.com/watch?v=aeGADcC-hUA" target="_blank" rel="noopener">Fluentd Webinar: Best kept secret to unify logging on AWS, Docker, GCP, and more!</a></li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Logging directly <span class="keyword">from</span> microservice makes log storages overloaded</span><br><span class="line">  - too many connections</span><br><span class="line">  - too frequent import API call</span><br><span class="line"></span><br><span class="line">Aggregation server</span><br><span class="line">  - make log infra more reliable <span class="keyword">and</span> scalable</span><br><span class="line">  -<span class="built_in"> connection </span>aggregation</span><br><span class="line">  - buffering <span class="keyword">for</span> less frequent import API calls</span><br><span class="line">  - data persistence during downtime</span><br><span class="line">  - retry &amp; recovery <span class="keyword">from</span> down time</span><br></pre></td></tr></table></figure><ol start="2"><li><a href="https://docs.fluentd.org/v1.0/articles/buffer-plugin-overview" target="_blank" rel="noopener">https://docs.fluentd.org/v1.0/articles/buffer-plugin-overview</a></li><li><a href="https://github.com/uken/fluent-plugin-elasticsearch" target="_blank" rel="noopener">https://github.com/uken/fluent-plugin-elasticsearch</a></li><li><a href="https://gist.github.com/sonots/c54882f73e3e747f4b20" target="_blank" rel="noopener">https://gist.github.com/sonots/c54882f73e3e747f4b20</a></li><li><a href="https://github.com/fluent/fluentd/blob/3566901ab4a00e0168b4a6078153dde85601fc53/lib/fluent/plugin/buffer.rb" target="_blank" rel="noopener">https://github.com/fluent/fluentd/blob/3566901ab4a00e0168b4a6078153dde85601fc53/lib/fluent/plugin/buffer.rb</a></li><li><a href="https://abicky.net/2017/10/23/110103" target="_blank" rel="noopener">https://abicky.net/2017/10/23/110103</a> Very detailed explanation how buffer works</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;p&gt;Logging is one of the critical components for deve
      
    
    </summary>
    
    
      <category term="elasticsearch" scheme="http://kkc.github.io/tags/elasticsearch/"/>
    
      <category term="fluentd" scheme="http://kkc.github.io/tags/fluentd/"/>
    
  </entry>
  
  <entry>
    <title>透過 IAM access advisor API 來幫 IAM permission 做大掃除</title>
    <link href="http://kkc.github.io/2019/04/08/analyze-iam-permission-using-iam-access-advisor-api/"/>
    <id>http://kkc.github.io/2019/04/08/analyze-iam-permission-using-iam-access-advisor-api/</id>
    <published>2019-04-08T09:37:08.000Z</published>
    <updated>2019-04-08T14:40:16.505Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>隨著組織慢慢變大，在 AWS 上面常常會遇到一個問題就是，我的 IAM entity 的 permission 是不是開的太大了，這個問題常常發生在 developer 想要快速驗證自己的 application 能不能 work，而作為 admin 的我們有時會給予太大的權限，等到該專案開展到一定程度的時候，其實需要使用到的權限應該是穩定下來了，但又難以找每個專案負責人慢慢 review 權限，這樣一來，其實違反了 least privilege 的原則，也就是只給於需要的權限就好。</p><h2 id="IAM-access-advisor-API"><a href="#IAM-access-advisor-API" class="headerlink" title="IAM access advisor API"></a>IAM access advisor API</h2><p>AWS 其實有推出一組用來分析 IAM 權限管理的 API，而 AWS 官方的 <a href="https://aws.amazon.com/blogs/security/automate-analyzing-permissions-using-iam-access-advisor/" target="_blank" rel="noopener">blog</a> 也有幾篇介紹，完全可以符合我們的需求，把一些用不到的權限限縮。</p><ul><li><code>generate-service-last-accessed-details</code> 針對 IAM ser, role, group, or policy 產生最後存取 (last accessed data) 的資訊，呼叫這個 API 後會拿到一組 <code>JobId</code>，接著要等待一陣子，才能透過 <code>get-service-last-accessed-details</code> 得到資料。</li><li><code>get-service-last-accessed-details</code> 透過這個 API 輸入 JobId 去得到 last accessed 的資料</li><li><code>get-service-last-accessed-details-with-entities</code> 其實跟上面的 API 很類似，只是可以指定 –service-namespaces 去看特定的 service</li><li><code>list-policies-granting-service-access</code> 可以看到這個權限（針對 service) 是從哪個 policy 來的</li></ul><p>有了以上這幾組 API 我們就可以實作一個簡單的 script 去掃出是否有權限太大的 IAM entity。 </p><h2 id="Simple-Example"><a href="#Simple-Example" class="headerlink" title="Simple Example"></a>Simple Example</h2><p>這個範例很大一部分是參考 trek10inc 的 <a href="https://github.com/trek10inc/config-excess-access-exorcism/blob/734fecde2f02dd448e0439f366d5400d4413a6d0/IAM_ALLOWS_UNUSED_SERVICES/iam_rule_helpers.py" target="_blank" rel="noopener">config-excess-access-exorcism</a> 來的，不過有做一些簡單的修改，有了這個程式可以幫我們快速定位，那個 IAM role 開的權限太大，而這個 repo 其實想做到的事情更潮，是將其設定為 AWS config 的 rule，由此一來就可以讓 AWS 幫我們定期去掃 IAM entities。</p><p>先透過下面這個 function 拿到該 IAM entity 所有的 service 權限，這邊要注意的是要把 paginate 的資料也拿回來，因為有些權限太多需要好幾個 API call 才拿得齊。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_iam_last_access_details</span><span class="params">(iam, arn)</span>:</span></span><br><span class="line">    job = iam.generate_service_last_accessed_details(Arn=arn)</span><br><span class="line">    job_id = job[<span class="string">'JobId'</span>]</span><br><span class="line">    service_results = []</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        result = iam.get_service_last_accessed_details(JobId=job_id)</span><br><span class="line">        <span class="keyword">if</span> result[<span class="string">'JobStatus'</span>] == <span class="string">'IN_PROGRESS'</span>:</span><br><span class="line">            print(<span class="string">"Awaiting job"</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">elif</span> result[<span class="string">'JobStatus'</span>] == <span class="string">'FAILED'</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">f"Could not get access information for <span class="subst">&#123;arn&#125;</span>"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            service_results.extend(paginate_access_details(job_id, result))</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        time.sleep(<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">return</span> service_results</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">paginate_access_details</span><span class="params">(job_id, result)</span>:</span></span><br><span class="line">    more_data, marker = result[<span class="string">'IsTruncated'</span>], result.get(<span class="string">'Marker'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> more_data:</span><br><span class="line">        <span class="keyword">return</span> result[<span class="string">'ServicesLastAccessed'</span>]</span><br><span class="line"></span><br><span class="line">    all_service_info = result[<span class="string">'ServicesLastAccessed'</span>][:]</span><br><span class="line">    <span class="keyword">while</span> more_data:</span><br><span class="line">        page = iam.get_service_last_accessed_details(JobId=job_id, Marker=marker)</span><br><span class="line">        more_data, marker = page[<span class="string">'IsTruncated'</span>], page[<span class="string">'Marker'</span>]</span><br><span class="line">        all_service_info.extend(page[<span class="string">'ServicesLastAccessed'</span>])</span><br><span class="line">    <span class="keyword">return</span> all_service_info</span><br></pre></td></tr></table></figure></p><p>來個簡單的測試<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">detail = get_iam_last_access_details(<span class="name">iam</span>, <span class="string">"arn:aws:iam::AWS_ACCOUNT:role/service-role/AmazonEC2RunCommandRoleForManagedInstances"</span>)</span><br><span class="line">pprint(<span class="name">detail</span>)</span><br></pre></td></tr></table></figure></p><p>Output 會長得像這樣:<br><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[&#123;   <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'Amazon</span> CloudWatch',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'cloudwatch</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;   <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'AWS</span> Directory Service',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'ds</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;   <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'Amazon</span> EC2',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'ec2</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">0</span>&#125;,</span><br><span class="line">    &#123;   <span class="symbol">'LastAuthenticated</span><span class="symbol">':</span> datetime.datetime(<span class="name">2019</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">41</span>, tzinfo=tzutc()),</span><br><span class="line">        <span class="symbol">'LastAuthenticatedEntity</span><span class="symbol">':</span> <span class="symbol">'arn:aws:iam::774915305292:role/service-role/AmazonEC2RunCommandRoleForManagedInstances</span>',</span><br><span class="line">        <span class="symbol">'ServiceName</span><span class="symbol">':</span> <span class="symbol">'Amazon</span> Message Delivery Service',</span><br><span class="line">        <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span> <span class="symbol">'ec2messages</span>',</span><br><span class="line">        <span class="symbol">'TotalAuthenticatedEntities</span><span class="symbol">':</span> <span class="number">1</span>&#125;,</span><br><span class="line">        ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><p>有了這個 output 我們就可以來開心的來分析啦，主要就是看 <code>LastAuthenticated</code> 這個欄位，如果沒有這個欄位就代表根本沒使用過，這個權限就該被剷除，另外也可以檢查是否這個使用的日期是不是在 180 天前，太久沒用也代表可能不需要了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">never_accessed_services_check</span><span class="params">(iam, arn)</span>:</span></span><br><span class="line">    service_results = get_iam_last_access_details(iam, arn)</span><br><span class="line">    never_accessed = [</span><br><span class="line">        x <span class="keyword">for</span> x <span class="keyword">in</span> service_results <span class="keyword">if</span> <span class="string">'LastAuthenticated'</span> <span class="keyword">not</span> <span class="keyword">in</span> x</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">if</span> len(never_accessed) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            <span class="string">'NON_COMPLIANT'</span>,</span><br><span class="line">            <span class="string">"Services"</span> + <span class="string">','</span>.join(<span class="string">f"'<span class="subst">&#123;x[<span class="string">'ServiceNamespace'</span>]&#125;</span>'"</span> <span class="keyword">for</span> x <span class="keyword">in</span> never_accessed) + <span class="string">"have never been accessed"</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'COMPLIANT'</span>, <span class="string">'IAM entity has accessed all allowed services'</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">no_access_in_180_days_check</span><span class="params">(iam, arn)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pytz</span><br><span class="line"></span><br><span class="line">    service_results = get_iam_last_access_details(iam, arn)</span><br><span class="line"></span><br><span class="line">    pp = pprint.PrettyPrinter(indent=<span class="number">4</span>)</span><br><span class="line">    pp.pprint(service_results)</span><br><span class="line"></span><br><span class="line">    utc_now = datetime.datetime.utcnow().replace(tzinfo=pytz.UTC)</span><br><span class="line"></span><br><span class="line">    older_than_180_days = [</span><br><span class="line">        x <span class="keyword">for</span> x <span class="keyword">in</span> service_results</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'LastAuthenticated'</span> <span class="keyword">in</span> x <span class="keyword">and</span> (utc_now - x[<span class="string">'LastAuthenticated'</span>]) &gt; datetime.timedelta(days=<span class="number">180</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">if</span> len(older_than_180_days) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> (</span><br><span class="line">            <span class="string">'NON_COMPLIANT'</span>,</span><br><span class="line">            <span class="string">"Services"</span> + <span class="string">','</span>.join(<span class="string">f"'<span class="subst">&#123;x[<span class="string">'ServiceNamespace'</span>]&#125;</span>'"</span> <span class="keyword">for</span> x <span class="keyword">in</span> older_than_180_days) + <span class="string">"have not been accessed in the last 180 days"</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'COMPLIANT'</span>, <span class="string">'IAM entity has accessed all allowed services in the last 180 days'</span></span><br></pre></td></tr></table></figure><p>在知道是哪個 service 有問題後，還可以用 <code>aws iam list-policies-granting-service-access --arn arn:aws:iam::AWS_ACCOUNT:role/service-role/AmazonEC2RunCommandRoleForManagedInstances --service-namespaces s3</code> 去看這個 service 的權限是從哪個 policy 來的。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"PoliciesGrantingServiceAccess"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"ServiceNamespace"</span>: <span class="string">"s3"</span>,</span><br><span class="line">            <span class="attr">"Policies"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">"PolicyName"</span>: <span class="string">"AmazonEC2RoleforSSM"</span>,</span><br><span class="line">                    <span class="attr">"PolicyType"</span>: <span class="string">"MANAGED"</span>,</span><br><span class="line">                    <span class="attr">"PolicyArn"</span>: <span class="string">"arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM"</span></span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"IsTruncated"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>sample code 可以用下列的程式碼</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def get_policies(iam, arn, service_namespace_list):</span><br><span class="line">    policies = []</span><br><span class="line">    <span class="built_in">result</span> = iam.list_policies_granting_service_access(Arn=arn, ServiceNamespaces=service_namespace_list)</span><br><span class="line">    policies.extend(paginate_policies(arn, service_namespace_list, <span class="built_in">result</span>))</span><br><span class="line">    <span class="literal">return</span> policies</span><br><span class="line"></span><br><span class="line">def paginate_policies(arn, service_namespace_list, <span class="built_in">result</span>):</span><br><span class="line">    more_data, marker = <span class="built_in">result</span>[<span class="string">'IsTruncated'</span>], <span class="built_in">result</span>.<span class="built_in">get</span>(<span class="string">'Marker'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> more_data:</span><br><span class="line">        <span class="literal">return</span> <span class="built_in">result</span>[<span class="string">'PoliciesGrantingServiceAccess'</span>]</span><br><span class="line"></span><br><span class="line">    all_service_info = <span class="built_in">result</span>[<span class="string">'PoliciesGrantingServiceAccess'</span>][:]</span><br><span class="line">    <span class="keyword">while</span> more_data:</span><br><span class="line">        page = iam.list_policies_granting_service_access(Arn=arn, ServiceNamespaces=service_namespace_list, Marker=marker)</span><br><span class="line">        more_data, marker = page[<span class="string">'IsTruncated'</span>], page[<span class="string">'Marker'</span>]</span><br><span class="line">        all_service_info.extend(page[<span class="string">'PoliciesGrantingServiceAccess'</span>])</span><br><span class="line">    <span class="literal">return</span> all_service_info</span><br></pre></td></tr></table></figure><p>就可以找出需要修正的 policy 像是這樣</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">   &#123;  </span><br><span class="line">      <span class="symbol">'ServiceNamespace</span><span class="symbol">':</span><span class="symbol">'s3</span>',</span><br><span class="line">      <span class="symbol">'Policies</span><span class="symbol">':</span>[</span><br><span class="line">         &#123;  </span><br><span class="line">            <span class="symbol">'PolicyName</span><span class="symbol">':</span><span class="symbol">'AmazonEC2RoleforSSM</span>',</span><br><span class="line">            <span class="symbol">'PolicyType</span><span class="symbol">':</span><span class="symbol">'MANAGED</span>',</span><br><span class="line">            <span class="symbol">'PolicyArn</span><span class="symbol">':</span><span class="symbol">'arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM</span>'</span><br><span class="line">         &#125;</span><br><span class="line">      ]</span><br><span class="line">   &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="心得"><a href="# 心得" class="headerlink" title="心得"></a>心得 </h2><p> 管理 IAM 其實需要相當的心力，透過一些 AWS 的 cli 加上 python boto lib，可以讓我們事倍功半，很推薦大家多試試看這些 API 掃掃看，我也有蠻多意外的發現 XD</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.trek10.com/blog/excess-access-exorcism-with-aws-config/" target="_blank" rel="noopener">https://www.trek10.com/blog/excess-access-exorcism-with-aws-config/</a></li><li><a href="https://aws.amazon.com/blogs/security/remove-unnecessary-permissions-in-your-iam-policies-by-using-service-last-accessed-data/" target="_blank" rel="noopener">remove unnecessary permissions in your iam policies by using service last accessed data</a></li><li><p><a href="https://aws.amazon.com/blogs/security/automate-analyzing-permissions-using-iam-access-advisor/" target="_blank" rel="noopener">automate-analyzing-permissions-using-iam-access-advisor</a></p></li><li><p>header image credit<a style="background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px" href="https://unsplash.com/@jbriscoe?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge" target="_blank" rel="noopener noreferrer" title="Download free do whatever you want high-resolution photos from Jason Briscoe"><span style="display:inline-block;padding:2px 3px"><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewbox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"/></svg></span><span style="display:inline-block;padding:2px 3px">Jason Briscoe</span></a></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;p&gt;隨著組織慢慢變大，在 AWS 上面常常會遇到一個問題就是，我的 IAM entity 的 permi
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="IAM" scheme="http://kkc.github.io/tags/IAM/"/>
    
  </entry>
  
  <entry>
    <title>透過 loop invariant 學習怎麼寫正確的 binary search</title>
    <link href="http://kkc.github.io/2019/03/28/learn-loop-invariant-from-binary-search/"/>
    <id>http://kkc.github.io/2019/03/28/learn-loop-invariant-from-binary-search/</id>
    <published>2019-03-28T09:12:32.000Z</published>
    <updated>2019-04-01T16:08:54.556Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>Binary search 記得是我剛入門寫程式的時候，前幾個回家作業，當時寫出來時，覺得整個程式就很直覺，對這個也不太有什麼疑問，直到最近看到 Programming Pearls 這本書裡面，有寫到大概 90% 的 binary search 都是錯誤的，甚至第一版的 binary search (1946 的版本)，直到 1962 年才發現有 Bug。</p><blockquote><p>I’ve assigned this problem in courses at Bell Labs and IBM.  Professional programmers had a couple of hours to convert the above description into a program in the language of their choice; a high-level pseudocode was fine.  At the end of the specified time, almost all the programmers reported that they had correct code for the task.  We would then take thirty minutes to examine their code, which the programmers did with test cases.  In several classes and with over a hundred programmers, the results varied little: ninety percent of the programmers found bugs in their programs (and I wasn’t always convinced of the correctness of the code in which no bugs were found).</p></blockquote><blockquote><p>I was amazed: given ample time, only about ten percent of professional programmers were able to get this small program right.  But they aren’t the only ones to find this task difficult: in the history in Section 6.2.1 of his Sorting and Searching, Knuth points out that while the first binary search was published in 1946, the first published binary search without bugs did not appear until 1962.</p></blockquote><p>其實 google 也有一篇 <a href="https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html" target="_blank" rel="noopener"> 文章 </a> 在探討 binary search，先來看下面這個 binary search 的程式。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(input_arr []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    s := <span class="number">0</span></span><br><span class="line">    e := <span class="built_in">len</span>(input_arr) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> s &lt;= e &#123;</span><br><span class="line">        m := (s + e) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> input_arr[m] &lt; target &#123;</span><br><span class="line">            s = m</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            e = m - <span class="number">1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>這個範例明眼人一看就知道 <code>m := (s + e) / 2</code> 會有溢位的問題，而通常會有兩種改法:</p><ol><li><code>m := s + (e - s)/2</code></li><li><code>m := int(uint(s+e) &gt;&gt; 1)</code></li></ol><p>但是除了這個之外，其實我寫的這個例子還有其他問題，最主要的就是 <a href="https://en.wikipedia.org/wiki/Off-by-one_error" target="_blank" rel="noopener">Off-by-one errors</a> 這個問題，如果把 [1,2,3,4] 當作 input，然後 target 為 3 的情況，其實會跑進無窮迴圈：</p><ol><li>s=0, e=3, m=1 且 input_arr[1] = 2 &lt; 3，所以 s = m</li><li>s=1, e=3, m=2 且 input_arr[2] = 3 &gt;= 3 ， 所以 e = m - 1</li><li>s=1, e=1, m=1 此時這個程式，因為一直維持 s &lt;= e 就會跑進無窮迴圈</li></ol><p>而這個邊界條件，就是要調整 +1, -1 的問題，非常的難搞，這裡有好幾個地方要配合才行</p><ol><li>e 的邊界是 <code>len(input_arr)</code> or <code>len(input_arr) - 1</code></li><li>s &lt;= e or s &lt; e</li><li>s = m or s = m + 1</li><li>e = m or e = m - 1</li></ol><p>網路上甚至可以找到範本，專門拿來對付 leetcode 上面的問題，雖然也是有人講可以直接在迴圈中判斷 if input_arr[m] == target 做跳出就行了，但是這樣的寫法顯然無法解決從找出 sorted array 中找出 lower_bound or upper_bound，這就讓我想知道是否有更科學的方法可以幫助我們。</p><h2 id="Loop-invariant-to-the-rescue"><a href="#Loop-invariant-to-the-rescue" class="headerlink" title="Loop invariant to the rescue"></a>Loop invariant to the rescue</h2><p>很幸運的，在網路上找到幾篇文章 (都列在 reference 了) 幫助我理解怎麼使用 loop invariant 去解決這個問題，我也查了下 Introduction to Algorithm 裡面的 loop invariant 定義:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">We <span class="keyword">use</span> <span class="keyword">loop</span> invariants <span class="keyword">to</span> <span class="keyword">help</span> us understand why an algorithm <span class="keyword">is</span> correct. We must <span class="keyword">show</span> three things about a <span class="keyword">loop</span> invariant:</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> Initialization: It <span class="keyword">is</span> <span class="literal">true</span> <span class="keyword">prior</span> <span class="keyword">to</span> the <span class="keyword">first</span> iteration <span class="keyword">of</span> the loop.</span><br><span class="line"><span class="number">2.</span> Maintenance: <span class="keyword">If</span> it <span class="keyword">is</span> <span class="literal">true</span> <span class="keyword">before</span> an iteration <span class="keyword">of</span> the <span class="keyword">loop</span>, it remains <span class="literal">true</span> <span class="keyword">before</span> the <span class="keyword">next</span> iteration.</span><br><span class="line"><span class="number">3.</span> Termination: <span class="keyword">When</span> the <span class="keyword">loop</span> terminates, the invariant gives us a useful property that helps <span class="keyword">show</span> that the algorithm <span class="keyword">is</span> correct.</span><br></pre></td></tr></table></figure><p>整個看下來有點歸納法的意味，就是定義一個性質，在 loop 開始前，執行完一次 loop interation，和結束時都可以保證這個性質成立，這樣就可以得到正確的程式結果。</p><p>先看看下面這個簡單的例子</p><figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">find_max</span><span class="params">(a []int)</span></span> &#123;</span><br><span class="line">    <span class="built_in">max</span> = -<span class="type">INF</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i:=<span class="number">0</span>; i &lt; len(a); i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (a[i] &gt; <span class="built_in">max</span>)</span><br><span class="line">            <span class="built_in">max</span> = a[i]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以這個例子來說，我們的 loop invariant condition 可以設定為 max 總是在給予的 a array 前 i 個元素中，然後去驗證每次跑迴圈的時候，都符合這個條件，就可以確定這個演算法是正確的。</p><h2 id="透過 -loop-invariant- 寫 -binary-search"><a href="# 透過 -loop-invariant- 寫 -binary-search" class="headerlink" title="透過 loop invariant 寫 binary search"></a>透過 loop invariant 寫 binary search</h2><p>前面提的那個例子，大家一定會覺得有點太簡單，實在不知道對我們寫程式有什麼幫助，接下來透過 binary search 的例子，相信大家可以有更不一樣的感受。</p><p>首先要來定義我們的問題:</p><ul><li><p>Pre condition:<br>在 binary search 中，我們會有一個 sorted list，然後從中找到 target。</p><p>sorted list = [3, 5, 6, 13, 18, 21, 23]<br>target = 18</p></li><li><p>Post condition:<br>找出 key 是否在 list 中</p></li></ul><p>而定義 list 的區間其實有四種方法<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. A<span class="string">[low]</span> &lt;  A<span class="string">[i]</span> &lt;  A<span class="string">[high]</span></span><br><span class="line"><span class="number">2</span>. A<span class="string">[low]</span> &lt;= A<span class="string">[i]</span> &lt;  A<span class="string">[high]</span></span><br><span class="line"><span class="number">3</span>. A<span class="string">[low]</span> &lt;  A<span class="string">[i]</span> &lt;= A<span class="string">[high]</span></span><br><span class="line"><span class="number">4</span>. A<span class="string">[low]</span> &lt;= A<span class="string">[i]</span> &lt;= A<span class="string">[high]</span></span><br></pre></td></tr></table></figure></p><p>看過許多資料後了解方法二是比較好的選擇， <code>i ∈ [low,high)</code>，也就是左閉右開這個方法，也就是右邊的值並沒有包含在這個區間內，其實也是最直覺的方法，這邊很推薦大家看這份知乎的文章: <a href="https://www.zhihu.com/question/36132386" target="_blank" rel="noopener">二分找查有幾種寫法?</a>去了解為什麼要取這個區間，其實我以下很多內容也是看這篇文章而通透的。</p><p>而選擇了這個區間後，我們先來個基本版的 binary search 實做，才容易解釋 loop invaraint<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(input_arr []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    low := <span class="number">0</span></span><br><span class="line">    high := <span class="built_in">len</span>(input_arr)  <span class="comment">// 符合 i ∈ [low,high)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> low &lt; high &#123;</span><br><span class="line">        mid := low + (high - low) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> input_arr[mid] == target &#123;</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> input_arr[mid] &lt; target &#123;  <span class="comment">// target 在 mid 右側</span></span><br><span class="line">            low = mid + <span class="number">1</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                           <span class="comment">// target 在 mid 左側</span></span><br><span class="line">            high = mid</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我們這裡設定的 loop invariant 性質，跟區間很有關係</p><ol><li>搜索區間 <code>[low, high)</code> 不為空的話，low &lt; high 才會成立，反之為空的話，low == high 會離開迴圈</li><li>找出來的 sub range 搜索區間都是 <code>[low, high)</code></li></ol><p>有了這些條件後，我們可以分析下迴圈結束的 boundary condition，來先個比較小的測資，來模擬測試區間變小的情況。</p><h3 id="範例 -1"><a href="# 範例 -1" class="headerlink" title="範例 1"></a>範例 1</h3><p>如果我們有個 array 裡面只有一個元素 [0]，然後我們要找的 target 為 1 時，透過以下的 step</p><ol><li>我們的初始搜索區間為 [0, 1)，low = 0, high = 1, mid = 0</li><li>因為 input_arr[mid] = 0 &lt; 1，所以 low = mid + 1 ，此時 high &amp; low 皆為 1 且重合，搜索區間為空集合，離開迴圈。</li><li>回傳 -1 代表這個 array 沒有我們要的值 </li></ol><p>已上面這個例子，我們可以得知，如果把跳出的條件寫成 <code>low &lt;= high</code> 或是 low 寫成 mid 都會出問題，因為會不符合 loop invaraint ，這邊要理解的就是搜索區間變成空集合在這個程式中，是怎麼表示才是正確的。 </p><h3 id="範例 -2"><a href="# 範例 -2" class="headerlink" title="範例 2"></a>範例 2</h3><p>在了解怎麼離開迴圈後，讓我們再看看比較長的測資，[3, 5, 6, 13, 18, 21, 23]，從中間找 18 這個值</p><div style="width: 300px; margin: auto"><img src="./binary_search_1.png" alt="example"></div><p>從這個過程中我們可以看到，不管是找右區間還是左區間，我們的 L &amp; H 的移動法則都是要保持搜索區間為 [L, H)，然後慢慢把搜索區間變小。</p><div style="width: 300px; margin: auto"><img src="./binary_search_2.png" alt="example"></div><p>再看一下這個例子，如果我把 18 改成 19，一樣是搜索 18 這個值，會發現結束時，我們的 low == high 並且跳出回圈回傳 1，就跟範例 1 的情況一樣，這時我們的 [low, high) 就成為空集合了。</p><h2 id="透過 -loop-invariant- 寫 -lower-bound"><a href="# 透過 -loop-invariant- 寫 -lower-bound" class="headerlink" title="透過 loop invariant 寫 lower bound"></a>透過 loop invariant 寫 lower bound</h2><p>以上我們的 binary search 的例子，只能找出 target 是否在 sorted array 或是不在 sorted array，但是如果要找 lower bound or upper bound 就無法使用了，下面給個例子什麼是 lower bound &amp; upper bound。</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">            upper bound</span><br><span class="line">                +</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">       ^</span><br><span class="line">       lower bound</span><br></pre></td></tr></table></figure><p>如果要找 lower bound 其實就是稍微改寫下我們的 binary search </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Search</span><span class="params">(input_arr []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    low := <span class="number">0</span></span><br><span class="line">    high := <span class="built_in">len</span>(input_arr)  <span class="comment">// 符合 i ∈ [low,high)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> low &lt; high &#123;</span><br><span class="line">        mid := low + (high - low) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> input_arr[mid] &lt; target &#123;  </span><br><span class="line">            low = mid + <span class="number">1</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                     </span><br><span class="line">            high = mid</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> low</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>這邊的 loop invariant 跟之前的很相似，不過有些小變形</p><ol><li>搜索區間 <code>[low, high)</code> 不為空的話，low &lt; high 才會成立，反之為空的話，low == high 會離開迴圈</li><li>找出來的 sub range 搜索區間都是 <code>[low, high)</code><ul><li>右邊的區間 <code>[high&#39;, high)</code> 都是 &gt;= target 的值</li><li>左邊的區間 <code>[low, low&#39;)</code> 都是 &lt; target 的值</li></ul></li></ol><p>接著直接看圖說故事:</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_3.png" alt="example"></div><br>一樣維持搜索區間為 [L, H) (藍色)</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_4.png" alt="example"></div><br>因為 array[mid] &gt;= target，所以走到 H = mid，這裡其實產生了右邊的區間 <code>[high&#39;, high)</code> (粉色)，我們可以知道這個區間其實有著 &gt;= target 的特性，所以 target 也有可能落在這個區間內，到最後要找答案的時候這個區間很重要。</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_5.png" alt="example"></div><br>接著看到 array[mid] &lt; target，這代表了 <code>[low, mid]</code> 的這個區間都是小於 target 的，所以我們選擇讓 L = mid + 1，這樣產生出來的 <code>[low, low&#39;）</code>的區間 (綠色) 才符合我們所定義的特性，但是可以發現藍色區間還是 <code>[Low&#39;, high&#39;)</code>，我們的目標是要讓藍色區間縮小到不見，並保持 loop invariant。</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_6.png" alt="example"></div></p><p><div style="width: 400px; margin: auto"><img src="./binary_search_7.png" alt="example"></div><br>因為 array[mid] == target 所以繼續拓展右邊的區間，記得這個區間內的值都是 &gt;= target 的</p><p><div style="width: 400px; margin: auto"><img src="./binary_search_8.png" alt="example"></div><br>結束時跟之前的例子一樣 L=H 會重合，這邊我們要的答案其實不管回傳 L 或是 H 的 index 都是一樣的結果，但是其實可以想成是取出粉紅色的第一個值，就會是我們要找的 lower bound。</p><h2 id="心得"><a href="# 心得" class="headerlink" title="心得"></a>心得 </h2><p> 其實 binary search 的變化真的很多，但是只要了解自己要搜索的區間長怎麼樣，就比較不會卡來卡去在那邊 +1, -1, 而最後寫的 lower bound 的方法其實也適用於一般的 binary search，可說是比較簡單又不容易錯的版本，不過要了解這個 loop invariant 怎麼定義區間，怎麼移動 low, high 去產生新的搜索區間，我還是建議大家用紙筆自己畫畫看，其實會比較有感覺，也可以拿 <code>A[low] &lt;= A[i] &lt;= A[high]</code> 這個為例子看看程式要怎麼寫才對，這篇文章的圖文寫得比較快，如果有不清楚或是錯誤的地方在請大家指正 :)</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://www.eecs.yorku.ca/course_archive/2013-14/W/2011/lectures/09%20Loop%20Invariants%20and%20Binary%20Search.pdf" target="_blank" rel="noopener">binary search and loop invariant</a></li><li><a href="https://zhu45.org/posts/2018/Jan/12/how-to-write-binary-search-correctly/" target="_blank" rel="noopener">How to write binary search correctly</a></li><li><a href="https://www.zhihu.com/question/36132386" target="_blank" rel="noopener">https://www.zhihu.com/question/36132386</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;p&gt;Binary search 記得是我剛入門寫程式的時候，前幾個回家作業，當時寫出來時，覺得整個程式就
      
    
    </summary>
    
    
      <category term="algorithm" scheme="http://kkc.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>AWS Shuffle Sharding</title>
    <link href="http://kkc.github.io/2019/03/04/AWS-Shuffle-Sharding/"/>
    <id>http://kkc.github.io/2019/03/04/AWS-Shuffle-Sharding/</id>
    <published>2019-03-04T01:37:42.000Z</published>
    <updated>2019-03-04T15:37:25.722Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>Colm MacCárthaigh 是 AWS 的 Senior Principal Engineer，如果常在追他的 Twitter <a href="https://twitter.com/colmmacc" target="_blank" rel="noopener">帳號 </a> 會看到很多有趣的 AWS 內部的 architecture 設計，像是最近有人在 og-aws.slack.com 的討論區問到為什麼 AWS 的 <a href="https://status.aws.amazon.com/" target="_blank" rel="noopener">status alert</a> 不一定會影響到該 region 的全部 customer 呢? 我隨機找了一個 alert 的內容:</p><blockquote><p>Beginning at 11:54 AM PST some Amazon Aurora clusters experienced increased database create times and cluster unavailability in the AP-SOUTHEAST-2 Region. Elevated create times were resolved at 2:27 PM PST, at which point some existing clusters continued to experience availability issues. As of 5:35 PM PST both issues have been resolved and the service is operating normally. In total, the event impacted a little less than <code>3%</code> of the Aurora databases in the region.</p></blockquote><p>可以看得出來，這個問題只影響了 3% 的 Aurora database，然後 AWS 這邊會建議每個用戶使用 Personal Health Dashboard 去看是否真的有受影響，這邊就讓很多人好奇 AWS 的底層，到底是怎麼去做 isolation 且提供 multi-tenancy 的服務，不讓一些故障的 servers 影響到全部人，而我這篇文章就是從 Colm MacCárthaigh 的 tweet 展開，有興趣的人也可以直接去看他的 tweet。</p><p><blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">It&#39;s no good sharing everything if a single &quot;noisy neighbor&quot; can cause everyone to have a bad experience. We want the opposite!  At AWS we are super into compartmentalization and isolation, and mature remediation procedures. Shuffle Sharding is one of our best techniques. O.k. ..</p>&mdash; Colm MacCárthaigh (@colmmacc) <a href="https://twitter.com/colmmacc/status/1034494834172604416?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">August 28, 2018</a></blockquote></p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><h1 id="Shuffle-Sharding"><a href="#Shuffle-Sharding" class="headerlink" title="Shuffle Sharding"></a>Shuffle Sharding</h1><p>其實 Colm MacCarthaigh 早在 2014 年的時候，就在 <a href="https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/" target="_blank" rel="noopener">AWS architecture blog</a> 上面揭露過 Shuffle Sharding 這個概念，而下面的例子我是從 reinvent 2018 的 <a href="https://www.slideshare.net/AmazonWebServices/how-aws-minimizes-the-blast-radius-of-failures-arc338-aws-reinvent-2018" target="_blank" rel="noopener">slides</a> 裡面擷取出來的。</p><h2 id="Basic-architecture"><a href="#Basic-architecture" class="headerlink" title="Basic architecture"></a>Basic architecture</h2><p>假設你有一組 service，裡面共有八個 nodes，這些 nodes 都接在一組 LB 後面，此時有八組不同的 customer 上門， 如果 Diamond 這個 request 進到系統後，因為某些原因，也許是剛好碰到系統的某個 Bug 或是某種 workload 不小心把一組 node 打垮了，又好巧不巧的，它因為沒有接受到想要的回應，不斷的 retry 也把其他的 nodes 也打垮了，這時候我們要討論的 Term 叫做 <code>Blast Radius</code>，也就是針對 customers 的爆炸範圍，以我們這個例子來看 </p><p><img src="./0.png" alt="0.png"><br><img src="./1.png" alt="1.png"></p><p>也就是全部的 customer 都被炸翻了！ 這也是最糟糕的狀況，AWS 在建構它們的服務時極力的避免這種情況。</p><h2 id="Cell-based-architecture"><a href="#Cell-based-architecture" class="headerlink" title="Cell-based architecture"></a>Cell-based architecture</h2><p>為了避免 Diamond 直接把全部 nodes 都弄爛，其實簡單一點的方法可以直接把 nodes 分組，切成不同的 cell，兩兩成群，而針對不同的 cells，我們也會分配兩個 customer，這樣 Diamond 頂多把其中兩台給弄掛掉，而以這個例子來看頂多愛心這個倒霉的 customer 一起中招，這樣一來針對 <code>Blast Radis</code> 就可以得到 4x 的改進，從 100% 下降到 25%，也就是只有 25% 的 customer 受到影響。</p><p><img src="./2.png" alt="2.png"></p><p>這個方法在 AWS 內部稱作 <code>cellularization</code>，其實套用在很多不同的服務上面，像是 isolated regions 還有 availability zones。</p><h2 id="Shuffle-Sharding-1"><a href="#Shuffle-Sharding-1" class="headerlink" title="Shuffle Sharding"></a>Shuffle Sharding</h2><p>有了以上概念後，可以再回到 Shuffle Sharding，其實非常的簡單，我們不一定要讓 customer 在固定的 cell 裡面，其實目標只是要分配 customer 的 requests 到不同的兩個 node 上面，而通過 random 的分配不同的 nodes 上面，透過下面這張圖我們可以發現，這個方法的威力真的很大，Diamond 雖然也是讓兩個 nodes 直接掛掉，但是在上面的 customer 其實分別是愛心和梅花，而他們的 request 還有其他的 node 可以服務，所以愛心和梅花，還是可以通過 retry 去達到 fault tolerance，所以整體的 Blast Radius 降低到只影響一個 customer。</p><p><img src="./3.png" alt="3.png"></p><p>這個圖是比較簡化的，其實 8 個 的 nodes 去隨機選出 2 個 node 的 combination 是 28 組，也就是有 28 種分配方式，而 Blast Radius 的算法是像下面這樣去考慮某一組 combination 壞掉的機率:</p><p>slides 中也提供了一個 table 告訴我們，採取了 Suffle sharding 會讓 % customer impacted 降到 3% ! 這也是為什麼 AWS 的 service 有問題時，會推薦你看 personal health dashboard ，因為爆炸範圍真的沒那麼廣。</p><table><thead><tr><th>Overlap</th><th>% customer impacted</th></tr></thead><tbody><tr><td>0</td><td>53.6%</td></tr><tr><td>1</td><td>42.8%</td></tr><tr><td>2</td><td>3.6%</td></tr></tbody></table><p>講到這邊，其實已經覺得很厲害了，不過 AWS 因為客戶非常的多，所以還是無法容忍這麼高的影響率，所以 AWS 設計了 100 個 Nodes，shard size 為 5 的架構，這邊再來算個數學</p><table><thead><tr><th>Overlap</th><th>% customer impacted</th></tr></thead><tbody><tr><td>0</td><td>77%</td></tr><tr><td>1</td><td>21%</td></tr><tr><td>2</td><td>1.8%</td></tr><tr><td>3</td><td>0.06%</td></tr><tr><td>4</td><td>0.0006%</td></tr><tr><td>5</td><td>0.0000013%</td></tr></tbody></table><p>整體的數字下降到 <code>0.0000013%</code>!</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>在使用 Shuffle Sharding 中，Client 端的 retry 也是很重要的，然後可以透過數學知道 Node &amp; Shard 的數量產生的機率，再去設計你的架構，從 Shuffle Sharding 再來看 AWS 怎麼處理自身內部的 deployment，就變得異常合理和安全，AWS 的部署方式是先從某個 region 中的一個 AZ 來部署，如果 monitoring 的結果都沒問題，在慢慢 rollout 到不同 AZ 接著到不同的 region，這樣一但有問題，受到影響的 customer 數量也是極少，透過瞭解 AWS 底層也可以讓我們了解，為什麼 Multi-AZ 的部署那麼重要，因為透過 AWS 底層的這種技術，再加上 application 有做到良好的 retry，其實是可以提昇整體 service 的 reliability 的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.youtube.com/watch?v=swQbA4zub20" target="_blank" rel="noopener">AWS re:Invent 2018: How AWS Minimizes the Blast Radius of Failures (ARC338)</a></li><li><a href="https://www.slideshare.net/AmazonWebServices/how-aws-minimizes-the-blast-radius-of-failures-arc338-aws-reinvent-2018" target="_blank" rel="noopener">https://www.slideshare.net/AmazonWebServices/how-aws-minimizes-the-blast-radius-of-failures-arc338-aws-reinvent-2018</a></li><li><a href="https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;Colm MacCárthaigh 是 AWS 的 Senior Principal Enginee
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="Operation" scheme="http://kkc.github.io/tags/Operation/"/>
    
  </entry>
  
  <entry>
    <title>利用 Helm 在 EKS 上安裝 Prometheus</title>
    <link href="http://kkc.github.io/2019/02/25/install-prometheus-on-EKS/"/>
    <id>http://kkc.github.io/2019/02/25/install-prometheus-on-EKS/</id>
    <published>2019-02-25T08:39:36.000Z</published>
    <updated>2019-02-25T14:11:02.180Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>最近把玩了 EKS 一陣子，基本上 EKS 就是 AWS 提供的 Managed Kubernetes，主要是幫你管理 Kubernetes 的 master node，我們只需要管理 worker node 就好了，所以很多的服務還是可以用原本的 helm chart 裝起來，這篇文章會介紹怎麼在 EKS 上面利用 helm 安裝 Prometheus 相關的套件，還有一些簡單的設定。</p><p>這篇文章會包含以下內容</p><ul><li>利用 helm 安裝 Prometheus-operator 再透過 Operator 去部署 prometheus &amp; alertmanager</li><li>如何設定 helm value 去避免一些 EKS 上面的錯誤問題</li><li>Troubleshooting 的一些 tips</li></ul><h1 id="利用 -helm- 安裝 -prometheus"><a href="# 利用 -helm- 安裝 -prometheus" class="headerlink" title="利用 helm 安裝 prometheus"></a>利用 helm 安裝 prometheus</h1><p>因為 <code>coreos/prometheus-operator</code> 的 helm chart 已經被 deprecated 掉了，所以我們這邊會使用 <code>stable/prometheus-operator</code> 去做安裝，而這包 chart 其實有包含蠻多 components 像是 <code>prometheus</code> &amp; <code>alertmanager</code> ，還會幫你裝好 prometheus 需要監控用的 <code>node-exporter</code> 等等東西，所以非常大一包，很建議大家裝好後，可以回過頭來看看到底被安裝了哪些東西。</p><h2 id="確認 -stable-prometheus-operator- 版本"><a href="# 確認 -stable-prometheus-operator- 版本" class="headerlink" title="確認 stable/prometheus-operator 版本"></a>確認 stable/prometheus-operator 版本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm search -l stable/prometheus-operator</span></span><br></pre></td></tr></table></figure><p>可以看到目前最新的 Chart 版本是 <code>4.0.0</code><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                             CHART VERSION   APP VERSION     DESCRIPTION</span><br><span class="line">stable/prometheus-operator      <span class="number">4.0</span><span class="number">.0</span>           <span class="number">0.29</span><span class="number">.0</span>          Provides easy monitoring definitions for Kubernetes servi...</span><br><span class="line">stable/prometheus-operator      <span class="number">3.0</span><span class="number">.0</span>           <span class="number">0.29</span><span class="number">.0</span>          Provides easy monitoring definitions for Kubernetes servi...</span><br><span class="line">stable/prometheus-operator      <span class="number">2.6</span><span class="number">.0</span>           <span class="number">0.27</span><span class="number">.0</span>          Provides easy monitoring definitions for Kubernetes servi...</span><br></pre></td></tr></table></figure></p><p>安裝，這邊我們把安裝的名字取作 <code>prom-op</code><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install --name prom-op --<span class="keyword">namespace</span> monitoring stable/prometheus-<span class="keyword">operator</span></span><br></pre></td></tr></table></figure></p><p>透過以下的指令可以得知安裝了些什麼東西<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl --<span class="keyword">namespace</span> monitoring <span class="keyword">get</span> pods</span><br></pre></td></tr></table></figure></p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">NAME                                                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">alertmanager-prom-op-prometheus-operato-alertmanager<span class="number">-0</span>   <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">1</span>m</span><br><span class="line">prom-op-grafana<span class="number">-5</span>c59ddfb9d-zqfqt                         <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-kube-<span class="section">state</span>-metrics<span class="number">-76786</span>cc9b4<span class="number">-8</span>q4bj              <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter<span class="number">-6</span>jclc                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter-bxr49                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter-mxtht                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-node-exporter-xd54m                   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prom-op-prometheus-operato-operator<span class="number">-6</span>cbf5d5cfd-z6fz4     <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m</span><br><span class="line">prometheus-prom-op-prometheus-operato-prometheus<span class="number">-0</span>       <span class="number">3</span>/<span class="number">3</span>     Running   <span class="number">1</span>          <span class="number">1</span>m</span><br></pre></td></tr></table></figure><p>因為我這台 k8s cluster 有起了 4 個 node，所以會安裝 4 個 node operator，然後還會安裝 prometheus-operator, alertmanager, grafana 和 kube-state-metrics。</p><h2 id="Customizing-the-Chart"><a href="#Customizing-the-Chart" class="headerlink" title="Customizing the Chart"></a>Customizing the Chart</h2><p>透過 port forward 讀取 localhost:9090 可以看到 prometheus 裡面的資訊<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl port-forward svc/prom-op-prometheus-operato-prometheus -n monitoring 9090</span></span><br></pre></td></tr></table></figure></p><p>其中我們會看到以下這些錯誤<br><img src="./prometheus-error.png" alt="prometheus-error"><br><img src="./prometheus-error-2.png" alt="prometheus-error-2"></p><p>因為我們無法監控到 EKS 的 master node，所以關於 master 上面的 services 像是 etcd, kube-apiserver, controller-manager, kube-schedule 都會在 prometheus 中發生錯誤，這也是為什麼我們需要客製化我們的 chart file。<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">cp</span> http<span class="variable">s:</span>//raw.githubusercontent.<span class="keyword">com</span>/helm/charts/master/stable/prometheus-operator/<span class="built_in">values</span>.yaml <span class="built_in">values</span>.yaml</span><br></pre></td></tr></table></figure></p><p>修改完後可以使用以下指令去覆寫<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm<span class="built_in"> upgrade </span>--install prom-op stable/prometheus-operator --namespace monitoring -f values.yaml</span><br></pre></td></tr></table></figure></p><p>這邊筆記下我有更改的部分，master 上面的 services 像是 etcd, kube-apiserver, controller-manager, kube-schedule 等等的 monitoring 機制需要被關閉<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kubeApiServer</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubeControllerManager</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubeEtcd</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="string">kubeScheduler</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></p><p>kubelet 的話根據這個 <a href="https://github.com/coreos/prometheus-operator/issues/926" target="_blank" rel="noopener">issue</a>，在 EKS 上面使用的話，我們需要把 https 的部分 enable 起來</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kubelet:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  serviceMonitor:</span></span><br><span class="line"><span class="attr">    https:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>EKS 上面的 coreDns 的 label 有點怪，還是用 k8s-app:kube-dns 而不是 coredns<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">coreDns:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  service:</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">9153</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="number">9153</span></span><br><span class="line"><span class="attr">    selector:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">kube-dns</span></span><br></pre></td></tr></table></figure></p><p>還有一些 resource 的部分記得要調整下</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">resources:</span></span><br><span class="line"><span class="symbol">  requests:</span></span><br><span class="line"><span class="symbol">    memory:</span> <span class="number">400</span>Mi</span><br></pre></td></tr></table></figure><h1 id="設定 -addtional-scrape-config"><a href="# 設定 -addtional-scrape-config" class="headerlink" title="設定 addtional scrape config"></a>設定 addtional scrape config</h1><p>Prometheus 除了可以用來 monitor Kubernetes 內部的 service 外，其實也有提供一些方法去 scrape 外面的 service，像是有一些程式跑在既有的 EC2 上面，我們可以透過相對應的 EC2 service discovery 的方法去拉取資料，要達成相關的任務，則需要去設定 addtional config。</p><p>方法很簡單，需要先在 chart 的 value 中把原本的 additionalScrapeConfigs</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">additionalScrapeConfigs: <span class="string">[]</span></span><br></pre></td></tr></table></figure><p>改寫為需要另外掛上去的 config</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">additionalScrapeConfigs</span>:</span><br><span class="line">  - <span class="attribute">job_name</span>: placeholder</span><br><span class="line">    <span class="attribute">metrics_path</span>: /probe</span><br><span class="line">    <span class="attribute">params</span>:</span><br><span class="line">    <span class="attribute">module</span>: [http_2xx]</span><br><span class="line">    <span class="attribute">static_configs</span>:</span><br><span class="line">      - <span class="attribute">targets</span>:</span><br><span class="line">        - <span class="attribute">https</span>:<span class="comment">//sentry.umbocv.com/_health/?full</span></span><br></pre></td></tr></table></figure><p>但是這種做法需要一直更改 helm chart 的 value，而這邊也提供另外一種方法可以直接更改 config，讓 prometheus config reloader 去讀取，使用<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="builtin-name">get</span><span class="built_in"> secret </span>-n monitoring</span><br></pre></td></tr></table></figure></p><p>會看到有</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                                          <span class="built_in"> TYPE </span>                                 DATA   AGE</span><br><span class="line">prom-op-prometheus-scrape-confg                Opaque                                1      30s</span><br></pre></td></tr></table></figure><p>我們可以透過直接更改這個 secret 的內容而改動 addtional-scrape-config，而以下這個 addtional-scrape-configs.yaml 以上面的例子會長成這樣</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- job_name:</span> <span class="string">placeholder</span></span><br><span class="line"><span class="attr">  metrics_path:</span> <span class="string">/probe</span></span><br><span class="line"><span class="attr">  params:</span></span><br><span class="line"><span class="attr">  module:</span> <span class="string">[http_2xx]</span></span><br><span class="line"><span class="attr">  static_configs:</span></span><br><span class="line"><span class="attr">    - targets:</span></span><br><span class="line"><span class="attr">      - https:</span><span class="string">//sentry.umbocv.com/_health/?full</span></span><br></pre></td></tr></table></figure><p>接著透過這行指令把這個 <code>addtional-scrape-configs.yaml</code> 轉成 k8s 認得的 secret yaml，在 apply 上去<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create<span class="built_in"> secret </span>generic prom-op-prometheus-scrape-confg <span class="attribute">--from-file</span>=additional-scrape-configs.yaml --dry-<span class="builtin-name">run</span> -oyaml &gt; prometheus-additional-scrape-configs.yaml</span><br><span class="line">$ kubectl apply -f prometheus-additional-scrape-configs.yaml -n monitoring</span><br></pre></td></tr></table></figure></p><h1 id="設定 -alert-manager-template"><a href="# 設定 -alert-manager-template" class="headerlink" title="設定 alert manager template"></a>設定 alert manager template</h1><p>在使用完 prometheus-operator 的 helm 部署完後，其實可以從 UI 中的 status -&gt; rules 中看到許多內建好的 prometheus 的 rule，而如果想要把這個警告發到 slack 上面還需要設定 alertmanager 的 route config，而內建的 config 其實沒做任何事情，都是導到 null 而已</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">config</span>:</span><br><span class="line">  <span class="attribute">global</span>:</span><br><span class="line">    <span class="attribute">resolve_timeout</span>: <span class="number">5</span>m</span><br><span class="line">  <span class="attribute">route</span>:</span><br><span class="line">    <span class="attribute">group_by</span>: [<span class="string">'job'</span>]</span><br><span class="line">    <span class="attribute">group_wait</span>: <span class="number">30s</span></span><br><span class="line">    <span class="attribute">group_interval</span>: <span class="number">5</span>m</span><br><span class="line">    <span class="attribute">repeat_interval</span>: <span class="number">12</span>h</span><br><span class="line">    <span class="attribute">receiver</span>: <span class="string">'null'</span></span><br><span class="line">    <span class="attribute">routes</span>:</span><br><span class="line">    - <span class="attribute">match</span>:</span><br><span class="line">        <span class="attribute">alertname</span>: Watchdog</span><br><span class="line">      <span class="attribute">receiver</span>: <span class="string">'null'</span></span><br><span class="line">  <span class="attribute">receivers</span>:</span><br><span class="line">  - <span class="attribute">name</span>: <span class="string">'null'</span></span><br></pre></td></tr></table></figure><p>而這邊我們可以參考 Monza 的 <a href="https://gist.github.com/milesbxf/e2744fc90e9c41b47aa47925f8ff6512" target="_blank" rel="noopener">alertmanager slack template</a> ，這個 template 的好處就是可以幫 alert 都合併為一個發出來，然後也有吃內建的 rule 的 format，舉個例子像下面的這個 rule，裡面用到的 labels 是 <code>serverity: critical</code>，然後 annotations 裡面是 <code>message</code> &amp; <code>runbook_url</code></p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">alert</span>: KubeAPIDown</span><br><span class="line"><span class="attribute">expr</span>: absent(up&#123;job=<span class="string">"apiserver"</span>&#125;</span><br><span class="line">  == <span class="number">1</span>)</span><br><span class="line"><span class="attribute">for</span>: <span class="number">15</span>m</span><br><span class="line"><span class="attribute">labels</span>:</span><br><span class="line">  <span class="attribute">severity</span>: critical</span><br><span class="line"><span class="attribute">annotations</span>:</span><br><span class="line">  <span class="attribute">message</span>: KubeAPI has disappeared from Prometheus target discovery.</span><br><span class="line">  <span class="attribute">runbook_url</span>: <span class="attribute">https</span>:<span class="comment">//github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown</span></span><br></pre></td></tr></table></figure><p>而透過 Monza 的 template 我們可以先設定 alertmanager 的 endpoint</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">receivers:</span><br><span class="line">###################################################</span><br><span class="line">## Slack Receivers</span><br><span class="line">- name: slack-<span class="keyword">code</span>-owners</span><br><span class="line">  slack_configs:</span><br><span class="line">  - channel: <span class="string">'#&#123;&#123;- template"slack.monzo.code_owner_channel". -&#125;&#125;'</span></span><br><span class="line">    send_resolved: true</span><br><span class="line">    title: <span class="string">'&#123;&#123; template"slack.monzo.title". &#125;&#125;'</span></span><br><span class="line">    icon_emoji: <span class="string">'&#123;&#123; template"slack.monzo.icon_emoji". &#125;&#125;'</span></span><br><span class="line">    color: <span class="string">'&#123;&#123; template"slack.monzo.color". &#125;&#125;'</span></span><br><span class="line">    text: <span class="string">'&#123;&#123; template"slack.monzo.text". &#125;&#125;'</span></span><br><span class="line">    actions:</span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Runbook :green_book:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; (index .Alerts 0).Annotations.runbook_url &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Query :mag:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; (index .Alerts 0).GeneratorURL &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Dashboard :grafana:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; (index .Alerts 0).Annotations.dashboard &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'Silence :no_bell:'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; template"__alert_silence_link". &#125;&#125;'</span></span><br><span class="line">    - type: button</span><br><span class="line">      text: <span class="string">'&#123;&#123; template"slack.monzo.link_button_text". &#125;&#125;'</span></span><br><span class="line">      url: <span class="string">'&#123;&#123; .CommonAnnotations.link_url &#125;&#125;'</span></span><br></pre></td></tr></table></figure><p>在透過定義好的 template 中，我們可以看到已經有確認收到的警告是 <code>.Annotations.message</code> 會被顯示出來，這樣一來就可以把相關的 rule alert 打到 slack 上了。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This builds the silence URL.  We exclude the alertname in the range</span></span><br><span class="line"><span class="comment"># to avoid the issue of having trailing comma separator (%2C) at the end</span></span><br><span class="line"><span class="comment"># of the generated URL</span></span><br><span class="line">&#123;&#123; define <span class="string">"__alert_silence_link"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; .ExternalURL &#125;&#125;/<span class="comment">#/silences/new?filter=%7B</span></span><br><span class="line">    &#123;&#123;- range .CommonLabels.SortedPairs -&#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">if</span> ne .Name <span class="string">"alertname"</span> -&#125;&#125;</span><br><span class="line">            &#123;&#123;- .Name &#125;&#125;%<span class="number">3</span>D<span class="string">"&#123;&#123;- .Value -&#125;&#125;"</span>%<span class="number">2</span>C%<span class="number">20</span></span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    alertname%<span class="number">3</span>D<span class="string">"&#123;&#123; .CommonLabels.alertname &#125;&#125;"</span>%<span class="number">7</span>D</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">"__alert_severity_prefix"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> ne .Status <span class="string">"firing"</span> -&#125;&#125;</span><br><span class="line">    :lgtm:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .Labels.severity <span class="string">"critical"</span> -&#125;&#125;</span><br><span class="line">    :fire:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .Labels.severity <span class="string">"warning"</span> -&#125;&#125;</span><br><span class="line">    :warning:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">    :question:</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">"__alert_severity_prefix_title"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> ne .Status <span class="string">"firing"</span> -&#125;&#125;</span><br><span class="line">    :lgtm:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"critical"</span> -&#125;&#125;</span><br><span class="line">    :fire:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"warning"</span> -&#125;&#125;</span><br><span class="line">    :warning:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"info"</span> -&#125;&#125;</span><br><span class="line">    :information_source:</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">    :question:</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;/* First line <span class="keyword">of</span> Slack alerts */&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.title"</span> -&#125;&#125;</span><br><span class="line">    [&#123;&#123; .Status | toUpper -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> eq .Status <span class="string">"firing"</span> &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    ] &#123;&#123; template <span class="string">"__alert_severity_prefix_title"</span> . &#125;&#125; &#123;&#123; .CommonLabels.alertname &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Color <span class="keyword">of</span> Slack attachment (appears <span class="keyword">as</span> line next <span class="keyword">to</span> alert )*/&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.color"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">if</span> eq .Status <span class="string">"firing"</span> -&#125;&#125;</span><br><span class="line">        &#123;&#123; <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"warning"</span> -&#125;&#125;</span><br><span class="line">            warning</span><br><span class="line">        &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq .CommonLabels.severity <span class="string">"critical"</span> -&#125;&#125;</span><br><span class="line">            danger</span><br><span class="line">        &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">            <span class="comment">#439FE0</span></span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">    good</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Emoji <span class="keyword">to</span> display <span class="keyword">as</span> user icon (custom emoji supported!) */&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.icon_emoji"</span> &#125;&#125;:prometheus:&#123;&#123; <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* The test <span class="keyword">to</span> display <span class="keyword">in</span> <span class="keyword">the</span> alert */&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.text"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123; range .Alerts &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">if</span> .Annotations.message &#125;&#125;</span><br><span class="line">            &#123;&#123; .Annotations.message &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">if</span> .Annotations.description &#125;&#125;</span><br><span class="line">            &#123;&#123; .Annotations.description &#125;&#125;</span><br><span class="line">        &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;&#123;- /* If none <span class="keyword">of</span> <span class="keyword">the</span> <span class="keyword">below</span> matches, send <span class="keyword">to</span> <span class="comment">#monitoring-no-owner, and we </span></span><br><span class="line">can <span class="keyword">then</span> assign <span class="keyword">the</span> expected code_owner <span class="keyword">to</span> <span class="keyword">the</span> alert <span class="keyword">or</span> map <span class="keyword">the</span> code_owner</span><br><span class="line"><span class="keyword">to</span> <span class="keyword">the</span> correct channel */ -&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"__get_channel_for_code_owner"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">if</span> eq . <span class="string">"platform-team"</span> -&#125;&#125;</span><br><span class="line">        platform-alerts</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> <span class="keyword">if</span> eq . <span class="string">"security-team"</span> -&#125;&#125;</span><br><span class="line">        security-alerts</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">        monitoring-no-owner</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;- /* Select <span class="keyword">the</span> channel based <span class="keyword">on</span> <span class="keyword">the</span> code_owner. We only expect <span class="keyword">to</span> <span class="keyword">get</span></span><br><span class="line"><span class="keyword">into</span> this template function <span class="keyword">if</span> <span class="keyword">the</span> code_owners label <span class="keyword">is</span> present <span class="keyword">on</span> an alert.</span><br><span class="line">This <span class="keyword">is</span> <span class="keyword">to</span> defend <span class="keyword">against</span> us accidentally breaking <span class="keyword">the</span> routing logic. */ -&#125;&#125;</span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.code_owner_channel"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">if</span> .CommonLabels.code_owner &#125;&#125;</span><br><span class="line">        &#123;&#123; template <span class="string">"__get_channel_for_code_owner"</span> .CommonLabels.code_owner &#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">        monitoring</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">"slack.monzo.link_button_text"</span> -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">if</span> .CommonAnnotations.link_text -&#125;&#125;</span><br><span class="line">        &#123;&#123;- .CommonAnnotations.link_text -&#125;&#125;</span><br><span class="line">    &#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">        Link</span><br><span class="line">    &#123;&#123;- <span class="keyword">end</span> &#125;&#125; :link:</span><br><span class="line">&#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br></pre></td></tr></table></figure><p>這邊還有一個很重要的步驟，讓我卡了蠻久的，其實 template 也是一樣定義在 prometheus-operator 的 helm chart value.yaml 裡面，在定義完 template 後，一定要加上<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">templates:</span></span><br><span class="line">    - <span class="string">'/etc/alertmanager/config/*.tmpl'</span></span><br></pre></td></tr></table></figure></p><p>大概的範例長得像這樣</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">config</span><br><span class="line">  <span class="keyword">global</span>:</span><br><span class="line">    resolve_timeout: <span class="number">5</span>m</span><br><span class="line">  ... 略</span><br><span class="line"></span><br><span class="line">templates:</span><br><span class="line">  - '/etc/alertmanager/config/*.tmpl'</span><br><span class="line">   </span><br><span class="line">templateFiles:</span><br><span class="line">    template_monzo.tmpl: |-</span><br><span class="line"></span><br><span class="line">       &#123;&#123; <span class="keyword">define</span> <span class="string">"__alert_silence_link"</span> -&#125;&#125;</span><br><span class="line">          &#123;&#123; .ExternalURL &#125;&#125;/#/silences/new?<span class="keyword">filter</span>=<span class="symbol">%7</span>B</span><br><span class="line">          &#123;&#123;- range .CommonLabels.SortedPairs -&#125;&#125;</span><br><span class="line">              &#123;&#123;- if <span class="keyword">ne</span> .Name <span class="string">"alertname"</span> -&#125;&#125;</span><br><span class="line">                  &#123;&#123;- .Name &#125;&#125;<span class="symbol">%3</span>D<span class="string">"&#123;&#123;- .Value -&#125;&#125;"</span><span class="symbol">%2</span>C<span class="symbol">%20</span></span><br><span class="line">              &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">          &#123;&#123;- <span class="keyword">end</span> -&#125;&#125;</span><br><span class="line">          alertname<span class="symbol">%3</span>D<span class="string">"&#123;&#123; .CommonLabels.alertname &#125;&#125;"</span><span class="symbol">%7</span>D</span><br><span class="line">      &#123;&#123;- <span class="keyword">end</span> &#125;&#125;</span><br><span class="line">      ... 略</span><br></pre></td></tr></table></figure><h1 id="Troubleshoot"><a href="#Troubleshoot" class="headerlink" title="Troubleshoot"></a>Troubleshoot</h1><ol><li><p>如果一直沒收到 alert 的話，有可能是 alertmanager 的 template 寫錯，可以透過 <code>kubectl logs -f po/&lt;alertmanager_pod_name&gt; -n monitoring -c alertmanager</code> 去確認下是不是有產生一些 error log。</p></li><li><p>想要確認 alertmanager template 的語法的話，可以使用下面這個 script 去測試，主要是從這個 <a href="https://gist.github.com/cherti/61ec48deaaab7d288c9fcf17e700853a" target="_blank" rel="noopener">gist</a> 看來的，這樣就可以邊改 template 邊驗證，不用真的去產生一些錯誤條件出來。</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">name=<span class="formula">$RANDOM</span></span><br><span class="line"><span class="formula">url='http://localhost:9093/api/v1/alerts'</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo "firing up alert $</span>name" </span><br><span class="line"></span><br><span class="line"># change url o</span><br><span class="line">curl -XPOST <span class="formula">$url -d "[&#123; </span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>status<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>firing<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>labels<span class="tag">\<span class="name">"</span></span>: &#123;</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>alertname<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>$</span>name<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>service<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>my-service<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>severity<span class="tag">\<span class="name">"</span></span>:<span class="tag">\<span class="name">"</span></span>warning<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>instance<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span><span class="formula">$name.example.net<span class="tag">\<span class="name">"</span></span></span></span><br><span class="line"><span class="formula">&#125;,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>annotations<span class="tag">\<span class="name">"</span></span>: &#123;</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>summary<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>High latency is high!<span class="tag">\<span class="name">"</span></span></span></span><br><span class="line"><span class="formula">&#125;,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>generatorURL<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>http://prometheus.int.example.net/&lt;generating_expression&gt;<span class="tag">\<span class="name">"</span></span></span></span><br><span class="line"><span class="formula">&#125;]"</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo ""</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo"press enter to resolve alert"</span></span><br><span class="line"><span class="formula">read</span></span><br><span class="line"><span class="formula"></span></span><br><span class="line"><span class="formula">echo"sending resolve"</span></span><br><span class="line"><span class="formula">curl -XPOST $</span>url -d"[&#123; </span><br><span class="line"><span class="tag">\<span class="name">"</span></span>status<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>resolved<span class="tag">\<span class="name">"</span></span>,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>labels<span class="tag">\<span class="name">"</span></span>: &#123;</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>alertname<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span><span class="formula">$name<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>service<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>my-service<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>severity<span class="tag">\<span class="name">"</span></span>:<span class="tag">\<span class="name">"</span></span>warning<span class="tag">\<span class="name">"</span></span>,</span></span><br><span class="line"><span class="formula"><span class="tag">\<span class="name">"</span></span>instance<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>$</span>name.example.net<span class="tag">\<span class="name">"</span></span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>annotations<span class="tag">\<span class="name">"</span></span>: &#123;</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>summary<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>High latency is high!<span class="tag">\<span class="name">"</span></span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="tag">\<span class="name">"</span></span>generatorURL<span class="tag">\<span class="name">"</span></span>: <span class="tag">\<span class="name">"</span></span>http://prometheus.int.example.net/&lt;generating_expression&gt;<span class="tag">\<span class="name">"</span></span></span><br><span class="line">&#125;]"</span><br></pre></td></tr></table></figure></li></ol><p>或是用</p>  <figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">alerts='[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">"labels"</span>: &#123;</span><br><span class="line">       <span class="string">"alertname"</span>: <span class="string">"instance_down"</span>,</span><br><span class="line">       <span class="string">"instance"</span>: <span class="string">"example1"</span></span><br><span class="line">     &#125;,</span><br><span class="line">     <span class="string">"annotations"</span>: &#123;</span><br><span class="line">        <span class="string">"info"</span>: <span class="string">"The instance example1 is down"</span>,</span><br><span class="line">        <span class="string">"summary"</span>: <span class="string">"instance example1 is down"</span></span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">]'</span><br><span class="line"></span><br><span class="line">URL=<span class="string">"https://alertmanager.mydomain.com"</span></span><br><span class="line"></span><br><span class="line">curl -XPOST -d<span class="string">"$alerts"</span> $URL/api/v1/alerts</span><br></pre></td></tr></table></figure><ol start="3"><li><p>可以使用看看是否自己的 secret 內容是正確的</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="builtin-name">get</span><span class="built_in"> secret </span>-n monitoring alertmanager-prom-op-alertmanager -o <span class="attribute">go-template</span>=<span class="string">'&#123;&#123; index .data"alertmanager.yaml"&#125;&#125;'</span> | base64</span><br></pre></td></tr></table></figure></li></ol><h1 id="完整移除 -prometheus-operator"><a href="# 完整移除 -prometheus-operator" class="headerlink" title="完整移除 prometheus-operator"></a>完整移除 prometheus-operator</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ helm delete --purge &lt;name&gt;</span><br><span class="line">$ kubectl delete crd prometheuses<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br><span class="line">$ kubectl delete crd prometheusrules<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br><span class="line">$ kubectl delete crd servicemonitors<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br><span class="line">$ kubectl delete crd alertmanagers<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure><h1 id="後記"><a href="# 後記" class="headerlink" title="後記"></a>後記 </h1><p> 原本使用 prometheus-operator 其實還有個雷就是 servicemonitor 需要打上 <code>release: &lt;deploy_name&gt;</code>，這樣 operator 才真的會去吃這個 service monitor，但是隨著 4.0.0 的更新也把這個惱人的東西修掉了，所以建議大家常常去看下到底更新了什麼，其實 prometheus &amp; alertmanager 的版本也是一直推進很快的，而接下來有想到什麼更多的內容，還會繼續更新這篇。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/helm/charts/tree/master/stable/prometheus-operator" target="_blank" rel="noopener">https://github.com/helm/charts/tree/master/stable/prometheus-operator</a></li><li><a href="https://github.com/prometheus/alertmanager/issues/437" target="_blank" rel="noopener">https://github.com/prometheus/alertmanager/issues/437</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;最近把玩了 EKS 一陣子，基本上 EKS 就是 AWS 提供的 Managed Kubernete
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="EKS" scheme="http://kkc.github.io/tags/EKS/"/>
    
      <category term="prometheus" scheme="http://kkc.github.io/tags/prometheus/"/>
    
      <category term="monitoring" scheme="http://kkc.github.io/tags/monitoring/"/>
    
      <category term="kubernetes" scheme="http://kkc.github.io/tags/kubernetes/"/>
    
      <category term="helm" scheme="http://kkc.github.io/tags/helm/"/>
    
  </entry>
  
  <entry>
    <title>Deploy Prometheus Operator With Thanos</title>
    <link href="http://kkc.github.io/2019/02/10/prometheus-operator-with-thanos/"/>
    <id>http://kkc.github.io/2019/02/10/prometheus-operator-with-thanos/</id>
    <published>2019-02-10T13:53:12.000Z</published>
    <updated>2019-02-11T03:41:45.893Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>Prometheus is widely adopted as a standard monitoring tool with Kubernetes because it provides many useful features such as dynamic service discovery, powerful queries, and seamless alert notification integration. There are many applications and client libraries support Prometheus which makes the operation’s life easier. Although things are going pretty well with prometheus, the original prometheus deployment is not able to easily achieve High Availablity and long term storage.</p><h1 id="Thanos-comes-to-the-rescue"><a href="#Thanos-comes-to-the-rescue" class="headerlink" title="Thanos comes to the rescue"></a>Thanos comes to the rescue</h1><p><img src="./thanos.jpeg" alt="Thanos"></p><p>Thanos is developed by <a href="https://github.com/improbable-eng" target="_blank" rel="noopener">improbable</a> which can be integrated with prometheus transparently and solve HA and long term storage issues without hurting performance. The idea of Thanos is to run sidecar component of prometheus, therefore meaning that sidecar components can interact with prometheus to upload or query metrics. Also, prometheus operator supports thanos natively which make us easier to deploy our promtheus cluster along with thanos. This solution seems pretty elegant when you choose prometheus operator to provision prometheus cluster.</p><p>This article includes the following contents</p><ul><li>How to deploy the prometheus operator on the kubernetes</li><li>How to deploy the thanos sidecar w/ prometheus.</li><li>Achieve HA: using thanos querier</li><li>Query historical data: thanos store</li><li>Reduce data size: thanos compactor</li></ul><h1 id="Install-Prometheus-through-Prometheus-operator"><a href="#Install-Prometheus-through-Prometheus-operator" class="headerlink" title="Install Prometheus through Prometheus operator"></a>Install Prometheus through Prometheus operator</h1><p>There are tons of article introducing why we need to adopt prometheus-operator to provision prometheus. I recommend you read the following references[2] if you are not familiar with prometheus-operator.</p><h2 id="1-Install-Helm-in-your-environment"><a href="#1-Install-Helm-in-your-environment" class="headerlink" title="1. Install Helm in your environment"></a>1. Install Helm in your environment</h2><ul><li>MacOS: <code>brew install kubernetes-helm</code></li><li>Linux: <code>sudo snap install helm</code></li></ul><h2 id="2-Initialize-helm-and-install-tiller"><a href="#2-Initialize-helm-and-install-tiller" class="headerlink" title="2. Initialize helm and install tiller"></a>2. Initialize helm and install tiller</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm init</span></span><br></pre></td></tr></table></figure><h2 id="3-Install-coreos-prometheus-operator"><a href="#3-Install-coreos-prometheus-operator" class="headerlink" title="3. Install coreos prometheus operator"></a>3. Install coreos prometheus operator</h2><p>Note that we are using <code>stable/prometheus-operator</code> because <code>coreos/prometheus-operator</code> helm is going to be deprecated. We later need to modify chart value to provision prometheus cluster along with thanos sidecar. To install a stable helm chart with custom value, you need to download <code>values.yaml</code> from <a href="https://github.com/helm/charts/blob/master/stable/prometheus-operator/values.yaml" target="_blank" rel="noopener">github repo</a>.</p><p>In this example, we named our prometheus operator as <code>prom-op</code> and install it under <code>monitoring</code> namespace.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm<span class="built_in"> upgrade </span>--install prom-op stable/prometheus-operator --namespace monitoring -f values.yaml</span><br></pre></td></tr></table></figure><p>Use the following command to verify if prometheus-operator is provisioning successfully.</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl --<span class="keyword">namespace</span> monitoring <span class="keyword">get</span> pods -l <span class="string">"release=prom-op"</span></span><br></pre></td></tr></table></figure><h1 id="Thanos-Deployment"><a href="#Thanos-Deployment" class="headerlink" title="Thanos Deployment"></a>Thanos Deployment</h1><p><strong>NEED TO KNOW </strong><br>prometheus-operator should be greater than 0.28.0 to support Thanos 2.0</p><h2 id="Thanos-Architecture"><a href="#Thanos-Architecture" class="headerlink" title="Thanos Architecture"></a>Thanos Architecture</h2><p>Official Architecture of Thanos<br><img src="https://raw.githubusercontent.com/improbable-eng/thanos/master/docs/img/arch.jpg" alt="arch"></p><p>Our deployment steps<br><img src="https://user-images.githubusercontent.com/17483589/45601152-096aba80-ba11-11e8-8d46-20f666583386.jpg" alt="arch"></p><p>According to the above picture, there are several components of thanos:</p><ul><li>Sidecar</li><li>Querier</li><li>Store</li><li>Compactor</li></ul><p>The deployment steps:</p><ol><li>Prometheus should be deployed with thanos <code>Sidecar</code>.</li><li>Deploy Thanos <code>Querier</code> which is able to talks to prometheus <code>Sidecar</code> through gossip protocol.</li><li>Make sure Thanos <code>Sidecar</code> is able to upload prometheus metrics to the given S3 bucket.</li><li>Establish the Thanos <code>Store</code> for retrieving long term storage. </li><li>Set up the <code>Compactor</code> to shrink historical data.</li></ol><h2 id="Install-Thanos-sidecar"><a href="#Install-Thanos-sidecar" class="headerlink" title="Install Thanos sidecar"></a>Install Thanos sidecar</h2><p>To install Thanos sidecar along with prometheus-operator, we should specify thanos sidecar in the chart value as following:</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">thanos</span>:</span><br><span class="line">    <span class="attribute">baseImage</span>: improbable/thanos</span><br><span class="line">    <span class="attribute">version</span>: v0.<span class="number">2.1</span></span><br><span class="line">    <span class="attribute">peers</span>: thanos-peers.monitoring.<span class="attribute">svc</span>:<span class="number">10900</span></span><br><span class="line">    <span class="attribute">objectStorageConfig</span>:</span><br><span class="line">      <span class="attribute">key</span>: thanos.yaml</span><br><span class="line">      <span class="attribute">name</span>: thanos-objstore-config</span><br></pre></td></tr></table></figure><p><code>objectStorageConfig</code> can be configured through configuration file <code>thanos.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">type:</span> <span class="string">s3</span></span><br><span class="line"><span class="attr">config:</span></span><br><span class="line"><span class="attr">  bucket:</span> <span class="string">test-prometheus-thanos</span></span><br><span class="line"><span class="attr">  endpoint:</span> <span class="string">s3.us-west-2.amazonaws.com</span></span><br><span class="line"><span class="attr">  encryptsse:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>Creating the kubernetes secret by applying following command</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n monitoring create<span class="built_in"> secret </span>generic thanos-objstore-config <span class="attribute">--from-file</span>=thanos.yaml=/tmp/thanos-config.yaml</span><br></pre></td></tr></table></figure><p><strong>Warn</strong>: <code>endpoint</code> needs to be set in order to specify bucket located in which region.</p><h2 id="Verify-Thanos-Sidecar"><a href="#Verify-Thanos-Sidecar" class="headerlink" title="Verify Thanos Sidecar"></a>Verify Thanos Sidecar</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span> po -n monitoring</span><br></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">describe</span> po/prometheus-prom-<span class="built_in">op</span>-prometheus-<span class="number">0</span> -n monitoring</span><br></pre></td></tr></table></figure><p>If everything goes well, we could find out there is thanos-sidecar in the prometheus pod</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">thanos-<span class="string">sidecar:</span></span><br><span class="line">  Container <span class="string">ID:</span>  <span class="string">docker:</span><span class="comment">//e52df9fda7b0c43eea297d273169cf33e4aa49780fd8d5192c23f497c78b2007</span></span><br><span class="line"><span class="symbol">  Image:</span>         improbable/<span class="string">thanos:</span>v0<span class="number">.2</span><span class="number">.1</span></span><br><span class="line">  Image <span class="string">ID:</span>      docker-<span class="string">pullable:</span><span class="comment">//improbable/thanos@sha256:4ee0774316a5d57f78d243fe4afb10e9e889670d3facfdda70aae76f7165a16b</span></span><br><span class="line"><span class="symbol">  Ports:</span>         <span class="number">10902</span><span class="regexp">/TCP, 10901/</span>TCP, <span class="number">10900</span>/TCP</span><br><span class="line">  Host <span class="string">Ports:</span>    <span class="number">0</span><span class="regexp">/TCP, 0/</span>TCP, <span class="number">0</span>/TCP</span><br><span class="line"><span class="symbol">  Args:</span></span><br><span class="line">    sidecar</span><br><span class="line">    --prometheus.url=<span class="string">http:</span><span class="comment">//127.0.0.1:9090</span></span><br><span class="line">    --tsdb.path=/prometheus</span><br><span class="line">    --cluster.address=[$(POD_IP)]:<span class="number">10900</span></span><br><span class="line">    --grpc-address=[$(POD_IP)]:<span class="number">10901</span></span><br><span class="line">    --cluster.peers=thanos-peers.monitoring.svc.cluster.<span class="string">local:</span><span class="number">10900</span></span><br><span class="line"><span class="symbol">  State:</span>          Running</span><br><span class="line"><span class="symbol">    Started:</span>      Fri, <span class="number">01</span> Feb <span class="number">2019</span> <span class="number">12</span>:<span class="number">24</span>:<span class="number">38</span> +<span class="number">0800</span></span><br><span class="line"><span class="symbol">  Ready:</span>          True</span><br><span class="line">  Restart <span class="string">Count:</span>  <span class="number">0</span></span><br><span class="line"><span class="symbol">  Environment:</span></span><br><span class="line"><span class="symbol">    POD_IP:</span>   (<span class="string">v1:</span>status.podIP)</span><br><span class="line"><span class="symbol">  Mounts:</span></span><br><span class="line">    /prometheus from prometheus-prom-op-prometheus-db (rw)</span><br><span class="line">    <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io/serviceaccount from prom-op-prometheus-token<span class="number">-7</span>gvcp (ro)</span><br></pre></td></tr></table></figure><p>and if you check the log of sidecar, you will see following messages.<br><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">log</span> -f  po/prometheus-prom-op-prometheus-<span class="number">0</span> -<span class="built_in">n</span> monitoring -c thanos-sidecar</span><br></pre></td></tr></table></figure></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:15.173007261Z <span class="attribute">caller</span>=flags.go:90 <span class="attribute">msg</span>=<span class="string">"StoreAPI address that will be propagated through gossip"</span> <span class="attribute">address</span>=10.11.29.191:10901</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.178094001Z <span class="attribute">caller</span>=main.go:256 <span class="attribute">component</span>=sidecar <span class="attribute">msg</span>=<span class="string">"disabled TLS, key and cert must be set to enable"</span></span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.178211091Z <span class="attribute">caller</span>=factory.go:39 <span class="attribute">msg</span>=<span class="string">"loading bucket configuration"</span></span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.17855779Z <span class="attribute">caller</span>=sidecar.go:280 <span class="attribute">msg</span>=<span class="string">"starting sidecar"</span> peer=</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.179145313Z <span class="attribute">caller</span>=sidecar.go:220 <span class="attribute">component</span>=sidecar <span class="attribute">msg</span>=<span class="string">"Listening for StoreAPI gRPC"</span> address=[10.11.29.191]:10901</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T09:33:20.179187469Z <span class="attribute">caller</span>=main.go:308 <span class="attribute">msg</span>=<span class="string">"Listening for metrics"</span> <span class="attribute">address</span>=0.0.0.0:10902</span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2019-02-01T12:33:50.282222532Z <span class="attribute">caller</span>=shipper.go:201 <span class="attribute">msg</span>=<span class="string">"upload new block"</span> <span class="attribute">id</span>=01D2MGSADK1860F4APSD7CFZ7C</span><br></pre></td></tr></table></figure><h2 id="Install-Thanos-Querier"><a href="#Install-Thanos-Querier" class="headerlink" title="Install Thanos Querier"></a>Install Thanos Querier</h2><p>Thanos Querier Layer provides the ability to retrieve metrics from all prometheus instances at once. It’s fully compatible with original prometheus PromQL and HTTP APIs so that it can be used along with Grafana.</p><p>Since there are too many yaml files, I put everything in my <a href="https://github.com/kkc/prometheus-thanos" target="_blank" rel="noopener">github repo</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> thanos</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f querier-deployment.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f querier-service.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f querier-service-monitor.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-peers-svc.yaml</span></span><br></pre></td></tr></table></figure><h2 id="Install-Thanos-Store"><a href="#Install-Thanos-Store" class="headerlink" title="Install Thanos Store"></a>Install Thanos Store</h2><p>Thanos Store collaborates with <code>querier</code> for retrieving historical data from the given bucket. It will join the Thanos cluster on setup. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-store.yaml</span></span><br></pre></td></tr></table></figure><h2 id="Install-Thanos-Compactor"><a href="#Install-Thanos-Compactor" class="headerlink" title="Install Thanos Compactor"></a>Install Thanos Compactor</h2><p>Thanos Compactor will do downsampling for your all historical data. It’s a really useful component which can reduce file size. Recommend everyone read this well explained <a href="https://improbable.io/games/blog/thanos-prometheus-at-scale" target="_blank" rel="noopener">article</a>. </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-compactor.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-compactor-service.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-compactor-service-monitor.yaml</span></span><br></pre></td></tr></table></figure><h1 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h1><h2 id="Peering-service-didn’t-set-up-properly"><a href="#Peering-service-didn’t-set-up-properly" class="headerlink" title="Peering service didn’t set up properly"></a>Peering service didn’t set up properly</h2><p>you will see this kind of message of thanos component<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">level</span>=error <span class="attribute">ts</span>=2019-02-01T05:11:40.805153721Z <span class="attribute">caller</span>=cluster.go:269 <span class="attribute">component</span>=cluster <span class="attribute">msg</span>=<span class="string">"Refreshing memberlist"</span> <span class="attribute">err</span>=<span class="string">"join peers thanos-peers.monitoring.svc.cluster.local:10900 : 1 error occurred:\n\t* Failed to resolve thanos-peers.monitoring.svc.cluster.local:10900: lookup thanos-peers.monitoring.svc.cluster.local on 172.20.0.10:53: no such host\n\n"</span></span><br></pre></td></tr></table></figure></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f thanos-peers-svc.yaml</span></span><br></pre></td></tr></table></figure><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li><a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md</a></li><li><a href="https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3/" target="_blank" rel="noopener">https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3/</a></li><li><a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/alerting.md" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/alerting.md</a></li><li><a href="https://fosdem.org/2019/schedule/event/thanos_transforming_prometheus_to_a_global_scale_in_a_seven_simple_steps/attachments/slides/3178/export/events/attachments/thanos_transforming_prometheus_to_a_global_scale_in_a_seven_simple_steps/slides/3178/Thanos___Transforming_Prometheus_to_a_Global_Scale_in_a_Seven_Simple_Steps_(FOSDEM" target="_blank" rel="noopener">Thanos___Transforming_Prometheus_to_a_Global_Scale_in_a_Seven_Simple_Steps_(FOSDEM).pdf</a>.pdf)</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;Prometheus is widely adopted as a standard monitor
      
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://kkc.github.io/tags/Kubernetes/"/>
    
      <category term="Prometheus" scheme="http://kkc.github.io/tags/Prometheus/"/>
    
      <category term="Thanos" scheme="http://kkc.github.io/tags/Thanos/"/>
    
  </entry>
  
  <entry>
    <title>FFmpeg libav decode 筆記</title>
    <link href="http://kkc.github.io/2019/01/12/ffmpeg-libav-decode-note/"/>
    <id>http://kkc.github.io/2019/01/12/ffmpeg-libav-decode-note/</id>
    <published>2019-01-12T03:24:06.000Z</published>
    <updated>2019-01-13T10:12:38.644Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>身處在一間做 Surveillance 的公司，一定要熟悉下 FFmpeg 怎麼使用，FFmpeg 真的是蠻偉大的，應該全世界大部分需要處理影音的公司都對他不陌生，FFmpeg 是一個跨平台免費又開源的影音處理方案，採用 LGPL 或是 GPL 的 License，單純使用 ffmpeg 或是 ffprobe command 就可以做到很多加解碼轉檔等等的事情，非常的方便！</p><p>FFmpeg 也有提供 library 給開發者呼叫並且整合在自己的程式中，這篇筆記基本上記錄了下怎麼使用它來做基本的解碼，FFmpeg 包含以下幾個 lib (只列了幾個我常用的)</p><p>Libavcodec: encode/decode 的 framework 包含很多影音的加解碼器<br>Libavformat: 對 video 的封裝<br>Libswscale: 圖像縮放，顏色空間轉換</p><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>基本上這篇心得，很多來自這篇文章 <a href="https://github.com/leandromoreira/ffmpeg-libav-tutorial" target="_blank" rel="noopener">https://github.com/leandromoreira/ffmpeg-libav-tutorial</a> 的內容，非常推薦想要學 FFmpeg 的同學作為參考，算是我找過網路上寫的最平易近人的說明。而這篇文章主要會紀錄 video 相關的心得，因為我對音訊還沒那麼熟。</p><h1 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h1><p>Video 其實可以視為一堆圖片的集合，小時候都有玩過一種東西，就是一本書上面有很多圖，在快速翻動的時候，就能感覺到上面的東西在移動。</p><h1 id="Codec"><a href="#Codec" class="headerlink" title="Codec"></a>Codec</h1><p>Codec 的工作就是把資料縮小，這邊給個概念，如果我們把數以百萬計的圖片放進一個電影檔裡面，那這個檔案勢必非常的大，來做個簡單的數學：</p><p>讓我們拿個高清的影片，解析度為 1080 x 1920，然後每個 pixel 都用 3 bytes 去記錄他的顏色資訊 (24 bit color，這裡可以表達 16,777,216 不同的顏色，我們的眼睛好厲害)，這個影片是 24 fps (frame per second)，然後長度為 30 分鐘，我們做個簡單的數學計算:</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">toppf = <span class="number">1080</span> * <span class="number">1920</span> <span class="comment">//total_of_pixels_per_frame</span></span><br><span class="line">cpp = <span class="number">3</span>             <span class="comment">//cost_per_pixel</span></span><br><span class="line">tis = <span class="number">30</span> * <span class="number">60</span>       <span class="comment">//time_in_seconds</span></span><br><span class="line">fps = <span class="number">24</span>            <span class="comment">//frames_per_second</span></span><br></pre></td></tr></table></figure><p>需要的儲存空間 = <code>tis * fps * toppf * cpp</code></p><p>簡單的計算後發現，這個電影檔居然要花我們 <code>250.28GB</code> 的空間，還有 <code>1.11Gpbs</code> 的流量，這也是為什麼我們需要 codec 來幫助我們壓縮檔案。</p><h1 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h1><p>Container 可以視為一個 wrapper，裡面包含了不同的 stream (通常是 video 和 audio)，然後這個 container 通常也提供了 Metadata 像是 video title , resolution 之類的資訊，</p><p>這邊加點我個人的筆記，mp4 和 mpeg4 video data，就是一種 container 和 stream 的概念，也是瓶子和內容物，mp4 這個瓶子一般來說都是裝 standard mpeg4 video codec 的資料，但是如果硬拿來裝其他的東西也可以，只是應該沒人會這樣做。</p><h1 id="FFmpeg-Libav-Architecture"><a href="#FFmpeg-Libav-Architecture" class="headerlink" title="FFmpeg Libav Architecture"></a>FFmpeg Libav Architecture</h1><p>要知道怎麼 encode/decode 得先了解下 libav 的 architecture</p><p><img src="flow.png" alt="img"></p><ol><li>讀取 media file 到 <code>AVFormatContext</code> 這個 compoenent 裡面，基本上這個動作其實只會讀取檔案的 header 而已，而經由這個 header 我們可以知道這包 container 裡面有多少 stream 。</li><li>如果我們要讀取 Container 裡面的 stream 的話，libav 會把它封裝在 <code>AVStream</code> 這個 component 內，我們就可以經由這個 component 讀取到 stream 的資料。</li><li>假設我們的 Container 裡面有兩個 stream ，一個是 video (encoded by H264 CODEC) 另外一個是 audio (encoded by AAC CODEC)，我們可以從中讀取一小段資料進 <code>AVPacket</code> 這個 Compoenent。</li><li>資料在 <code>AVPacket</code> 中還是被 <em>encode</em> 的狀態，這時候我們會需要 <code>AVCodec</code> 的幫忙，將 packet 裡面的資料 decode 出來到 <code>AVFrame</code> 中，我們就可以拿到 uncompressed frame。</li></ol><h2 id="Detailed-Decoding-Flow"><a href="#Detailed-Decoding-Flow" class="headerlink" title="Detailed Decoding Flow"></a>Detailed Decoding Flow</h2><p>主要的範例程式可以參考<a href="https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/0_hello_world.c" target="_blank" rel="noopener">hello_world.c</a>，接下來我會對其中比較重要的幾個 step 做個簡單的筆記。</p><ol><li><p>一開始要先對 <code>AVFormatContext</code> 這個結構配置記憶體，經由這個結構我們才能得到 container 的 format。</p> <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AVFormatContext *pFormatContext = avformat_alloc_context()<span class="comment">;</span></span><br></pre></td></tr></table></figure></li><li><p>接著使用 <code>avformat_open_input</code> 去將檔案讀進到我們之前配置好的 <code>AVFormatContext</code>，這個 function 最後有兩個 arguments，第一個是 <code>AVInputFormat</code>，傳入 <code>NULL</code> 他會自動猜測格式，第二個是 <code>AVDictionary</code> 通常是拿來配置 demuxer 的參數。</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">avformat_open_input(&amp;pFormatContext,</span> <span class="string">filename,</span> <span class="literal">NULL</span><span class="string">,</span> <span class="literal">NULL</span><span class="string">);</span></span><br></pre></td></tr></table></figure></li><li><p>讀進 <code>AVFormatContext</code> 後，可以印出 container 的 format 和 duration。 </p> <figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">printf</span>("Format %s, duration %lld us", pFormatContext-&gt;</span><span class="function"><span class="title">iformat</span>-&gt;</span><span class="function"><span class="title">long_name</span>, pFormatContext-&gt;</span>duration);</span><br></pre></td></tr></table></figure></li><li><p>使用 <code>avformat_find_stream_info</code> 拿來讀取 media file 裡面的 data ， 在呼叫完 <code>avformat_find_stream_info(pFormatContext,  NULL);</code> 這個方法後， 才能從 <code>pFormatContext-&gt;nb_streams</code> 裡面得到 context 有多少個 stream，接著可以用 pFormatContext-&gt;streams[i] 得到不同的 stream (<code>AVStream</code>)。</p> <figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; pFormatContext-&gt;nb_streams; i++)</span><br><span class="line">&#123;</span><br><span class="line">  /<span class="regexp">/ pFormatContext-&gt;streams[i]</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>因為每個 stream 都有可能是用不同的 codec 壓縮的，我們可以經由 <code>AVCodecParameters *pLocalCodecParameters = pFormatContext-&gt;streams[i]-&gt;codecpar;</code> 從每個 stream 中取得對應的 <code>AVCodecParameters</code></p></li><li><p>利用剛剛取得的 parameter 和 <code>avcodec_find_decoder</code> function 找到對應的 <code>AVCodec</code></p> <figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AVCodec *pCodec = avcodec_find_decoder(<span class="name">pLocalCodecParameters-&gt;codec_id</span>)<span class="comment">;</span></span><br></pre></td></tr></table></figure></li><li><p>取得 Codec 後，我們需要配置記憶體給 <code>AVCodecContext</code>，這個結構是等等要拿來 encode/decode 用的，我們另外還需要將 codec 的 parameter 也複製到這個 context 中，在我們配置好 codec 的 context 後，還需要使用 <code>avcodec_open2</code> 才能真的在之後使用這個 context。 </p> <figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">AVCodecContext *pCodecContext = avcodec_alloc_context3(<span class="name">pCodec</span>)<span class="comment">;</span></span><br><span class="line">avcodec_parameters_to_context(<span class="name">pCodecContext</span>, pCodecParameters)<span class="comment">;</span></span><br><span class="line">avcodec_open2(<span class="name">pCodecContext</span>, pCodec, NULL)<span class="comment">;</span></span><br></pre></td></tr></table></figure></li><li><p>我們需要把 packet (<code>AVPacket</code>) 從 stream 讀出來後，然後 decode 成一張張的 frame (<code>AVFrame</code>)</p> <figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置記憶體</span></span><br><span class="line">AVPacket *pPacket = av_packet_alloc<span class="comment">()</span>;</span><br><span class="line">AVFrame *pFrame = av_frame_alloc<span class="comment">()</span>;</span><br></pre></td></tr></table></figure><p> 這邊我們要使用 <code>av_read_frame</code> 這個 function 將 video_streaming 的資料從 <code>AVFormatContext</code> 中讀出來到 packet 中</p> <figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">while</span> (av_read_frame(pFormatContext, pPacket) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="selector-tag">avcodec_send_packet</span>(pCodecContext, pPacket);</span><br><span class="line">    <span class="selector-tag">avcodec_receive_frame</span>(pCodecContext, pFrame)</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 接著將 raw packet (compressed frame) 送進 decoder，然後把 raw data frame (uncompressed frame) 取出來，這兩組 API <code>avcodec_send_packet</code> &amp; <code>avcodec_receive_frame</code> 需要互相搭配使用，使用 <code>avcodec_send_packet</code> 將 packet 送到 <code>AVCodecContext</code> 中，然後透過 <code>avcodec_receive_frame</code> 將解碼後的 frame 拿出來，然後要注意一點是 <code>avcodec_send_packet</code> 和 <code>avcodec_receive_frame</code> 並不一定是一對一的關係，有時候需要多送幾個 packet 讓 <code>AVCodecContext</code> 緩存幾張 frame 的 data，而這邊拿到的 <code>pFrame-&gt;data</code> 的格式是 (YCbCr)[<a href="https://en.wikipedia.org/wiki/YCbCr]，如果想要轉成" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/YCbCr]，如果想要轉成</a> RGB 的話還需要使用到 <code>SwsContext</code> 之類的方法。</p></li><li><p>接著我們就可以印出取得的資訓像是 frame_number 或是 pts 等等印出來驗證摟</p> <figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">printf(</span><br><span class="line">    <span class="string">"Frame %c (%d) pts %d dts %d key_frame %d [coded_picture_number %d, display_picture_number %d]"</span>,</span><br><span class="line">    <span class="function"><span class="title">av_get_picture_type_char</span>(pFrame-&gt;</span>pict_type),</span><br><span class="line">    <span class="function"><span class="title">pCodecContext</span>-&gt;</span>frame_number,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>pts,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>pkt_dts,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>key_frame,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>coded_picture_number,</span><br><span class="line">    <span class="function"><span class="title">pFrame</span>-&gt;</span>display_picture_number</span><br><span class="line">);</span><br></pre></td></tr></table></figure></li></ol><p>針對 AVPacket 和 AVFrame，我另外畫了一張流程圖</p><p><img src="./flow2.png" alt="flow2"></p><h1 id="心得"><a href="# 心得" class="headerlink" title="心得"></a>心得</h1><p>ffmpeg 經過多次改版，API 和文件其實變得比較人性化一點，網路上也不像之前資料那麼少了，經由這次的練習也找到了不少有用的資料，都列在底下的 Reference 供大家參考，如果有哪邊寫錯的，還請大家指正了。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://slhck.info/ffmpeg-encoding-course/" target="_blank" rel="noopener">ffmpeg-encoding-course</a></li><li><a href="https://github.com/leandromoreira/ffmpeg-libav-tutorial" target="_blank" rel="noopener">https://github.com/leandromoreira/ffmpeg-libav-tutorial</a></li><li><a href="http://leixiaohua1020.github.io/#ffmpeg-development-examples" target="_blank" rel="noopener">http://leixiaohua1020.github.io/#ffmpeg-development-examples</a></li><li><a href="https://ffmpeg.org/doxygen/4.0/group__lavf__decoding.html#details" target="_blank" rel="noopener">https://ffmpeg.org/doxygen/4.0/group__lavf__decoding.html#details</a></li><li><a href="https://ffmpeg.org/doxygen/4.0/group__lavc__decoding.html" target="_blank" rel="noopener">https://ffmpeg.org/doxygen/4.0/group__lavc__decoding.html</a> </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h1&gt;&lt;p&gt;身處在一間做 Surveillance 的公司，一定要熟悉下 FFmpeg 怎麼使用，FFmpeg 
      
    
    </summary>
    
    
      <category term="ffmpeg" scheme="http://kkc.github.io/tags/ffmpeg/"/>
    
  </entry>
  
  <entry>
    <title>EKS 的一些筆記</title>
    <link href="http://kkc.github.io/2018/10/04/EKS-notes/"/>
    <id>http://kkc.github.io/2018/10/04/EKS-notes/</id>
    <published>2018-10-04T15:34:12.000Z</published>
    <updated>2018-10-04T17:10:43.182Z</updated>
    
    <content type="html"><![CDATA[<p><img src="eks.png" alt="eks"></p><h2 id="前言"><a href="# 前言" class="headerlink" title="前言"></a>前言 </h2><p> 最近大量使用了 AWS 的 EKS ，並且也 migrate 了一些 workload 到 EKS 上面，為了更深入了解 EKS 也找了些文章和影片來看，所以就有了這篇筆記。相關的影片和文章我會列在下面的 Reference。</p><h2 id="為什麼需要 -EKS"><a href="# 為什麼需要 -EKS" class="headerlink" title="為什麼需要 EKS"></a>為什麼需要 EKS</h2><p>最主要是為了改善維護及升級 k8s cluster 的困難度，一般來說，自己維護的 k8s cluster 必需要很注意 master 的穩定性，而其他痛苦的地方像是升級 kubernetes version (master node)，etcd 的升級，etcd 的備份和還原，另外還有些問題像是有些人忘了更新 certificate ，超過了過期時間後，連不進 master node 的意外。所以在沒有一定大小程度的 kubernetes operation 團隊下，其實蠻推薦大家使用 managed k8s 像是 EKS, GKE, AKS 等等的 solution ，減少其心智負擔。</p><h2 id="使用 -EKS- 的好處"><a href="# 使用 -EKS- 的好處" class="headerlink" title="使用 EKS 的好處"></a>使用 EKS 的好處</h2><ul><li>EKS master node HA</li><li>自動升級 Kubernetes 版本</li><li>整合了 IAM user &amp; IAM role w/ kubernetes RBAC，基本上可以控管每個 AWS 的 IAM user 的權限，規範 kubernetes 裡面的那些 namespace 或是 operation 可以被使用</li><li>原生使用 AWS VPC CNI 改善了 flannel 網路的效能，另外 AWS VPC flowlog 才能夠有作用，看得懂 packet 的流向</li><li>可以使用 EC2 IAM role ，解決了跟 AWS managed service 的整合問題</li><li>EKS 會自動備份監控 etcd</li><li>可以使用 Cloudtrail audit EKS API</li></ul><h2 id="一些技術細節"><a href="# 一些技術細節" class="headerlink" title="一些技術細節"></a>一些技術細節</h2><ul><li>Master node 會被啟在 AWS 自己特殊的 VPC 內，且受 AWS 控制，所以不會佔用我們的 IP 數量</li><li>Master node 和 worker node 之間用 private link 連結，走的是內部網路，所以效率上面不太需要擔心，Master node 前面有 Loadbalacer，猜想後面的 Master node 有問題或是需要 scale 的時候，使用的是 AWS 自己的 scale 方法，增加 Master node 的穩定度。</li></ul><h3 id="AWS-VPC-CNI"><a href="#AWS-VPC-CNI" class="headerlink" title="AWS VPC CNI"></a>AWS VPC CNI</h3><p><img src="cni.jpg" alt="cni"></p><p>這算是蠻重要的一環，原本的 kubernetes 的網路架構使用的是 flannel ，但是其實 packet 在流動的過程中，被轉址了很多次，而 AWS VPC CNI 就是為了解決 network performance 的問題。</p><ul><li>每個 ENI 可以有數個 IP addresses，AWS VPC CNI 會負責 collect 這些 IP 將其分配到 ENI 上面</li><li>可以從 EC2 上面看到 2nd IP 的數量會增加</li><li>一個 pod 會佔用一組 IP</li><li>每個 Instance family 可以使用的 IP 數量有限，這點需要注意，有聽到人先遇到了 IP 數量不足的問題，而不是先遇到 CPU or Mem 不足。</li></ul><h3 id="iptable- 問題"><a href="#iptable- 問題" class="headerlink" title="iptable 問題"></a>iptable 問題</h3><ul><li>處理 5000 services == 40000 rules 需要 11mins</li><li>處理 20000 services == 160000 rules == 5 hours</li></ul><p>在跑大量 service 時會有問題<br>1.11 後會有 IPVS mode，不過還是要考量一下是否要使用，基本上 iptable 的功能還是比較強大</p><h3 id="ingress"><a href="#ingress" class="headerlink" title="ingress"></a>ingress</h3><ul><li>可以使用 annotations 配置 ELB &amp; NLB</li><li>可以設定的東西有<ul><li>Draining</li><li>Logging</li><li>SSL Certs</li><li>Tagging</li><li>Security Groups</li><li>Health Checks</li></ul></li><li>ALB ingress 需要另外安裝</li></ul><h3 id="Network-policy"><a href="#Network-policy" class="headerlink" title="Network policy"></a>Network policy</h3><ul><li>pod 與 pod 之間的 network 可以使用 Calico 的 Network Policy 去配置</li></ul><h3 id="Auto-scaling"><a href="#Auto-scaling" class="headerlink" title="Auto scaling"></a>Auto scaling</h3><ul><li>最新版的 eks.2 已經有支援 Horizontal Pod Autoscaler</li><li>Worker Node scale 可以使用 Auto scaling group 來做</li><li>Master Node 由 AWS 負責</li></ul><h2 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h2><ul><li>目前只有三個 region 有支援 US west (Oregon) &amp; Virginia &amp; Ireland</li></ul><h2 id="Troubleshooting"><a href="#Troubleshooting" class="headerlink" title="Troubleshooting"></a>Troubleshooting</h2><ul><li><p>需要注意 security group 是否設定正確</p><ul><li>master node <-> worker node</-></li><li>worker node <-> worker node</-></li><li>LB <-> worker node</-></li><li>worker node <-> other EC2 instances or managed services</-></li></ul></li><li><p>VPC 內的 ip 數量是否足夠</p></li><li>ENI 的 ip 數量是不是已經達到上限</li><li>worker node 上面的 IAM role 的權限是否充足</li></ul><h2 id="Pricing"><a href="#Pricing" class="headerlink" title="Pricing"></a>Pricing</h2><ul><li>$0.20 per hour per cluster ($144 per month)</li><li>worker node resource 都跟 AWS 原本的價錢一樣</li></ul><h2 id="推薦的安裝方式"><a href="# 推薦的安裝方式" class="headerlink" title="推薦的安裝方式"></a>推薦的安裝方式 </h2><p> 除了使用 <a href="https://github.com/weaveworks/eksctl" target="_blank" rel="noopener">eksctl</a> 來建立 EKS 外，也可以使用 <a href="https://twitter.com/pahudnet" target="_blank" rel="noopener">Pahud</a> 大寫的 <a href="https://github.com/pahud/amazon-eks-workshop" target="_blank" rel="noopener">https://github.com/pahud/amazon-eks-workshop</a> 來創建和操作 EKS，而 Pahud 大的 workshop 還包含了許多其他的東西像是 ingress 和 HPA 的創建，非常值得大家一讀。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://aws.amazon.com/blogs/opensource/networking-foundation-eks-aws-cni-calico/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/opensource/networking-foundation-eks-aws-cni-calico/</a></li><li><a href="https://www.youtube.com/watch?v=4ClszrpJQq8&amp;t=1631s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=4ClszrpJQq8&amp;t=1631s</a></li><li><a href="https://www.slideshare.net/sriram_rajan/elastic-kubernetes-services-eks?qid=e09780e3-f5b4-478c-90fd-9b74bcf02c6d&amp;v=&amp;b=&amp;from_search=6" target="_blank" rel="noopener">https://www.slideshare.net/sriram_rajan/elastic-kubernetes-services-eks?qid=e09780e3-f5b4-478c-90fd-9b74bcf02c6d&amp;v=&amp;b=&amp;from_search=6</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;eks.png&quot; alt=&quot;eks&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;# 前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言 &lt;/h2&gt;&lt;p&gt; 最近大量使用了 AWS 的 EKS ，並且也 migrate
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://kkc.github.io/tags/AWS/"/>
    
      <category term="Kubernetes" scheme="http://kkc.github.io/tags/Kubernetes/"/>
    
      <category term="EKS" scheme="http://kkc.github.io/tags/EKS/"/>
    
  </entry>
  
</feed>
